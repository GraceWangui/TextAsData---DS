{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GraceWangui/TextAsData---DS/blob/main/Text_As_Data_Introduction%2C_Python_revision_%26_Regular_Expressions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text as Data Lab 0: Introduction, Python revision & Regular Expressions\n",
        "\n",
        "The aims of the lab are to:\n",
        " - Introduce you to Colab, verify that you're set up with the correct python packages\n",
        " - Load textual data from Reddit as a JSON file\n",
        " - Explore the data to learn a bit about it\n",
        " - Review salient Python features, such as Counter and list comprehensions\n",
        " - Introduce regular expressions, a common tool for text matching and processing\n",
        "\n",
        "**Before you start, save a copy of this lab to your drive using \"File > Save a Copy in Drive\".** If you skip this step, you may lose progress that you have made (e.g., if you close the browser tab or your computer crashes)."
      ],
      "metadata": {
        "id": "ZlyN2JKWAxbL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Colab Introduction\n",
        "\n",
        "\n",
        "Colab is a cloud-based Jupyter Notebook.  It is used internally by engineers and researchers at Google and companies worldwide to prototype and share data science and ML results in an easy-to-use way.\n",
        "\n",
        "It supports:\n",
        "\n",
        "1. Text Cells with [Markdown](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet) formatting\n",
        "2. Code Cells\n",
        "3. Notebook stores code, output, and execution order\n",
        "4. Tab and Tab + Tab Autocomplete\n",
        "5. IPython Help Features\n",
        "6. [IPython Magics (`%%`)](https://ipython.readthedocs.io/en/stable/interactive/magics.html) (such as [%%timeit](https://ipython.readthedocs.io/en/stable/interactive/magics.html#magic-timeit) to time the execution of a cell)\n",
        "\n",
        "### Additional Features\n",
        "\n",
        "- collaborative editing\n",
        "- history\n",
        "- comments\n",
        "- executed code history\n",
        "- Shift+click multiple cell selection\n",
        "- searchable code snippets + table of contents\n",
        "- scratchpad (⌘/Ctrl + Alt + N)\n",
        "\n",
        "### Keyboard Shortcuts\n",
        "| Command | Action |\n",
        "| ---- | ----: |\n",
        "|⌘/Ctrl+Enter | Run Selected Cell |\n",
        "|Shift+Enter| Run Cell and Select Next |\n",
        "|Alt+Enter| Run cell and insert new cell|\n",
        "|⌘/Ctrl+M I | Interrupt Execution |\n",
        "\n",
        "- You can open the command Palette to see all shortcuts by going to Tools --> Command palette.\n",
        "\n",
        "### Summary of tips\n",
        "- Use TAB to autocomplete an expression.\n",
        "- You can also execute the code with a ? to get the documentation (e.g. `?sum`)\n",
        "- In Jupyter / Colab you can execute shell commands using `!`, example: `!ls` to list the current files.\n",
        "\n",
        "*Note:* Occasionally Colab may hang or crash (due to cloud flakiness or bad code).  You can control the execution using the Runtime menu to reboot and start fresh.  To resume where you left off you can click \"Run before\" and it will run all cells before the one currently selected.\n"
      ],
      "metadata": {
        "id": "mAt5xuDsLBpN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Downloading\n",
        "\n",
        "Let's start by downloading a file containing data scraped from the online forum platform [Reddit](https://www.reddit.com/). This should take at most a few seconds to run."
      ],
      "metadata": {
        "id": "yI5XsjPanCeL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GoqbvVVMAvaX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac8ccc96-a9d3-4123-c131-8f7e5d559d2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-01-17 14:32:21--  https://gla-my.sharepoint.com/:u:/g/personal/jake_lever_glasgow_ac_uk/EY_R8Y7DkrxMqXGe-zlgeNkBdJU5ZNTf8FYrN2pqDwddMA?download=1\n",
            "Resolving gla-my.sharepoint.com (gla-my.sharepoint.com)... 13.107.136.10, 13.107.138.10, 2620:1ec:8f8::10, ...\n",
            "Connecting to gla-my.sharepoint.com (gla-my.sharepoint.com)|13.107.136.10|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://gla-my.sharepoint.com/personal/jake_lever_glasgow_ac_uk/_layouts/15/download.aspx?UniqueId=8ef1d18f92c34cbca9719efb396078d9 [following]\n",
            "--2025-01-17 14:32:22--  https://gla-my.sharepoint.com/personal/jake_lever_glasgow_ac_uk/_layouts/15/download.aspx?UniqueId=8ef1d18f92c34cbca9719efb396078d9\n",
            "Reusing existing connection to gla-my.sharepoint.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1279064 (1.2M) [application/json]\n",
            "Saving to: ‘reddit_posts.json’\n",
            "\n",
            "reddit_posts.json   100%[===================>]   1.22M   892KB/s    in 1.4s    \n",
            "\n",
            "2025-01-17 14:32:23 (892 KB/s) - ‘reddit_posts.json’ saved [1279064/1279064]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Download data\n",
        "!wget -O reddit_posts.json https://gla-my.sharepoint.com/:u:/g/personal/jake_lever_glasgow_ac_uk/EY_R8Y7DkrxMqXGe-zlgeNkBdJU5ZNTf8FYrN2pqDwddMA?download=1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Exploration\n",
        "\n",
        "If we take a look at the contents of the data file, we see that it is encoded as an array of objects in [JSON](https://en.wikipedia.org/wiki/JSON). There are a variety of other formats used for sharing text data (e.g., [XML](https://en.wikipedia.org/wiki/XML), [Protocol Buffers](https://en.wikipedia.org/wiki/Protocol_Buffers), etc.), but JSON is among the most common these days."
      ],
      "metadata": {
        "id": "A2NGM0ZDnp65"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Look at the first 20 lines of the file - note the exclamation mark which tells Colab to run a terminal command instead of Python\n",
        "!head -n 20 reddit_posts.json"
      ],
      "metadata": {
        "id": "d7homfd9ndq-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27543765-6263-4647-b117-60510b88d7b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\r\n",
            "  {\r\n",
            "    \"subreddit\": \"Soda\",\r\n",
            "    \"title\": \"Anyone tried Irn Bru?\",\r\n",
            "    \"score\": 8,\r\n",
            "    \"id\": \"ou5yp1\",\r\n",
            "    \"author\": \"jackibhoy\",\r\n",
            "    \"body\": \"It\\u2019s a Scottish drink and it\\u2019s banned some countries and I was wondering if anyone here has tried it. It has quite a unique taste and it\\u2019s not something you\\u2019d forget quickly. You either love it or hate it I think.\"\r\n",
            "  },\r\n",
            "  {\r\n",
            "    \"subreddit\": \"Soda\",\r\n",
            "    \"title\": \"What is the worst or some of the worst sodas you have drunk\",\r\n",
            "    \"score\": 3,\r\n",
            "    \"id\": \"nt40i4\",\r\n",
            "    \"author\": \"EpicEllis2004\",\r\n",
            "    \"body\": \"The absolute worst soda ive ever had that i can remember is probaly the new mystery fanta or watermelon+strawberry tango some other ones include mango coke, sugar free irn bru (but xtra is nice)\"\r\n",
            "  },\r\n",
            "  {\r\n",
            "    \"subreddit\": \"tea\",\r\n",
            "    \"title\": \"I once had a box of tea that I believe was Scottish Highland black tea. Can anyone recommend me a tea along those lines?\",\r\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data provided by online APIs, such as the [Reddit API](https://www.reddit.com/dev/api/), are usually available in JSON. For this lab, we use a simplified version of the Reddit data, aggregating posts across several subreddits (i.e., sub-forums) and using just a handful of salient fields for each post. The data file consists of some metadata about the posts (`subreddit`, `score`, `id`, and `author`) and two fields with the text of the posts (`title` and `body`)."
      ],
      "metadata": {
        "id": "BuBN2-KoGuep"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's load the data into Python so we can work with it. The [json](https://docs.python.org/3/library/json.html) package in the Python standard library makes loading the data very easy."
      ],
      "metadata": {
        "id": "RcydjzEdGx_Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data into Python\n",
        "import json\n",
        "with open('reddit_posts.json', 'rt') as fin:\n",
        "  reddit_posts = json.load(fin)"
      ],
      "metadata": {
        "id": "iRz19a-7A4iv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Python's JSON parser provides the data as a `list` of `dict` objects. You should already be familiar with these classes; if not, you can refer to [Python's data structures documentation](https://docs.python.org/3/tutorial/datastructures.html).\n",
        "\n",
        "Let's look at the types of data available provided and some basic information."
      ],
      "metadata": {
        "id": "GKe3TU9HHnrt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Investigate the structure of the data\n",
        "print('type(reddit_posts) =', type(reddit_posts))\n",
        "print('len(reddit_posts) =', len(reddit_posts))\n",
        "print('type(reddit_posts[0]) =', type(reddit_posts[0]))\n",
        "print('reddit_posts[0].keys() =', reddit_posts[0].keys())\n",
        "print('reddit_posts[0][\"title\"] =', reddit_posts[0][\"title\"])"
      ],
      "metadata": {
        "id": "xinvnfVGBKoL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3eb3a8c-4a83-415e-a0fd-fc615c6e8580"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "type(reddit_posts) = <class 'list'>\n",
            "len(reddit_posts) = 2000\n",
            "type(reddit_posts[0]) = <class 'dict'>\n",
            "reddit_posts[0].keys() = dict_keys(['subreddit', 'title', 'score', 'id', 'author', 'body'])\n",
            "reddit_posts[0][\"title\"] = Anyone tried Irn Bru?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see that there are 2000 posts in the dataset. It's always important to understand the data you're working with, so let's see which subreddits these posts are from.\n",
        "\n",
        "We could write code to loop through each of the posts and keep a running count of the number of posts in each subreddit:\n",
        "\n",
        "```python\n",
        "# The code that uses Counter below essentially does this:\n",
        "subreddit_counts = {}\n",
        "for post in reddit_posts:\n",
        "  subreddit = post['subreddit']\n",
        "  if subreddit not in subreddit_counts:\n",
        "    subreddit_counts[subreddit] = 0\n",
        "  subreddit_counts[subreddit] += 1\n",
        "subreddit_counts\n",
        "```\n",
        "\n",
        "Python provides a convenient [`Counter`](https://docs.python.org/3/library/collections.html#collections.Counter) class to count values like this, so we'll use that instead. We can use a [Generator Expression](https://docs.python.org/3/reference/expressions.html#generator-expressions) to get the subreddit from each post and let `Counter` count how many times each subreddit appears."
      ],
      "metadata": {
        "id": "ku6Iri8SKikQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the number of times each subreddit appears in this dataset\n",
        "from collections import Counter\n",
        "Counter(post['subreddit'] for post in reddit_posts)"
      ],
      "metadata": {
        "id": "o8_WlxMrKNWr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e27c9efa-b40a-4ac8-a6ec-c32fbb8c7e15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'Soda': 174,\n",
              "         'tea': 236,\n",
              "         'xbox': 213,\n",
              "         'antiMLM': 226,\n",
              "         'HydroHomies': 210,\n",
              "         'pcgaming': 225,\n",
              "         'NintendoSwitch': 249,\n",
              "         'Coffee': 234,\n",
              "         'PS4': 233})"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see that there are 9 subreddits covered by the dataset, mostly about beverages and gaming. The Soda subreddit is the least common (174 posts) and the NintendoSwitch subreddit is the most common (249 posts).\n",
        "\n",
        "**Exercise:** Can you find the user with the most posts and how many posts they have? (Hint: `Counter` provides a function that will help you find the item with the highest count, without needing to look through all the counts manually. You can find this in the [documentation](https://docs.python.org/3/library/collections.html#collections.Counter).)"
      ],
      "metadata": {
        "id": "PZmd8evUNxmf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your answer here\n",
        "Counter(post[\"author\"] for post in reddit_posts).most_common(2)"
      ],
      "metadata": {
        "id": "b9imZr5MK3nT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d36c6ce5-720a-46df-c1f3-aaa795eb136f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('AutoModerator', 5), ('DrinkClorox14', 4)]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You should find that AutoModerator has the most number of posts, with 5.\n",
        "\n",
        "AutoModerator sounds like it may not be a human user, so let's take a look at their posts. There are several ways to do this filtering. One of the most concise is to use a [List Comprehension](https://docs.python.org/3/tutorial/datastructures.html#list-comprehensions), so we'll do that here:"
      ],
      "metadata": {
        "id": "nujmWnKnPHUe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "[ post for post in reddit_posts if post['author'] == 'AutoModerator' ]"
      ],
      "metadata": {
        "id": "83yPQ-tPPSms",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a712fb2e-95b2-4e73-82ae-e4b6f9c0bc00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'subreddit': 'NintendoSwitch',\n",
              "  'title': \"/r/NintendoSwitch's Friend Request Weekend! (01/07/2022)\",\n",
              "  'score': 11,\n",
              "  'id': 'ry4xft',\n",
              "  'author': 'AutoModerator',\n",
              "  'body': \"Hi everybody! \\nIt's time for Friend Request Weekend! Use this thread to exchange Friend Codes and Nintendo Accounts, find new friends and set up gaming sessions! Feel free to share local Switch subreddits as well. You can find current local/regional Switch subreddits [here](https://www.reddit.com/r/NintendoSwitch/wiki/relatedsubs). If you would like to have yours added, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2FNintendoSwitch).\\n\\u200b\\nYou can also check out /r/NintendoFriends or /r/SwitchFCSwap for exchanging accounts and making friends. You can also setup a profile via our Mecha Bowser bot in our [Discord server](https://discord.gg/switch). Use the `!profile edit` command in the `#command-central` channel to get started.\\n\\u200b\\nYou can see previous posts [here](https://www.reddit.com/r/NintendoSwitch/search?q=Friend+Request+Weekend&restrict_sr=on&sort=new&t=all).\\nThank you and have a great weekend!\"},\n",
              " {'subreddit': 'NintendoSwitch',\n",
              "  'title': \"/r/NintendoSwitch's Friend Request Weekend! (10/29/2021)\",\n",
              "  'score': 2,\n",
              "  'id': 'qi9cmz',\n",
              "  'author': 'AutoModerator',\n",
              "  'body': \"Hi everybody! \\nIt's time for Friend Request Weekend! Use this thread to exchange Friend Codes and Nintendo Accounts, find new friends and set up gaming sessions! Feel free to share local Switch subreddits as well. You can find current local/regional Switch subreddits [here](https://www.reddit.com/r/NintendoSwitch/wiki/relatedsubs). If you would like to have yours added, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2FNintendoSwitch).\\n\\u200b\\nYou can also check out /r/NintendoFriends or /r/SwitchFCSwap for exchanging accounts and making friends. You can also setup a profile via our Mecha Bowser bot in our [Discord server](https://discord.gg/switch). Use the `!profile edit` command in the `#command-central` channel to get started.\\n\\u200b\\nYou can see previous posts [here](https://www.reddit.com/r/NintendoSwitch/search?q=Friend+Request+Weekend&restrict_sr=on&sort=new&t=all).\\nThank you and have a great weekend!\"},\n",
              " {'subreddit': 'pcgaming',\n",
              "  'title': 'Monthly /r/PCgaming Discussion - What have you been playing, and what do you think of it? (February 2016)',\n",
              "  'score': 28,\n",
              "  'id': '44pzsi',\n",
              "  'author': 'AutoModerator',\n",
              "  'body': \"Monthly Discussion Thread (Previous what have you been playing threads) \\n\\nUse this thread to discuss whatever you've been playing lately (old or new, AAA or indie).  Don't just list the names of games as your entire post, make sure to elaborate with your thoughts on the games.\\n\\nmake sure to use spoiler tags if you're posting anything about a game's plot that might significantly hurt the experience of others that haven't played the game yet (no matter how old or new the game is).\\n\"},\n",
              " {'subreddit': 'pcgaming',\n",
              "  'title': 'Monthly /r/PCgaming Discussion - What have you been playing, and what do you think of it? (January 2016)',\n",
              "  'score': 40,\n",
              "  'id': '40ft81',\n",
              "  'author': 'AutoModerator',\n",
              "  'body': \"Monthly Discussion Thread (Previous what have you been playing threads) \\n\\nUse this thread to discuss whatever you've been playing lately (old or new, AAA or indie).  Don't just list the names of games as your entire post, make sure to elaborate with your thoughts on the games.\\n\\nmake sure to use spoiler tags if you're posting anything about a game's plot that might significantly hurt the experience of others that haven't played the game yet (no matter how old or new the game is).\\n\"},\n",
              " {'subreddit': 'pcgaming',\n",
              "  'title': 'Suggest-A-Game Weekend Thread - August 10, 2019',\n",
              "  'score': 19,\n",
              "  'id': 'coduxu',\n",
              "  'author': 'AutoModerator',\n",
              "  'body': 'Previous Threads \\n\\nLost in your backlog and not sure where to turn? Get help from fellow gamers who can point you toward the good games.\\nOr did you find the next awesomely addictive time sink? Share it with us!'}]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Indeed, through qualitatively inspecting of AutoModerator's posts, they appear to be automatically generated.\n",
        "\n",
        "Depending on your application, you may want to filter out such posts. For instance, if you were trying to measure public sentiment about a product, you are probably only interested in human users. You could filter out auto-generated posts by manually checking each post, but this becomes impractical as the size of your collection grows. Later in this course we will cover text classification techniques, which could be used to automatically label a large number of posts given manually-labeled training data.\n",
        "\n"
      ],
      "metadata": {
        "id": "iS6VaixxH2MZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Can you find out anything else interesting from the dataset by inspecting the data?"
      ],
      "metadata": {
        "id": "d2m3Fua5J9aA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use this cell to explore the dataset. (Feel free to make other cells as well.)"
      ],
      "metadata": {
        "id": "czSDK1yUKFst"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Regular Expressions\n",
        "\n",
        "[Regular Expressions](https://en.wikipedia.org/wiki/Regular_expression) (often abbreviated as regex or regexp) are a common tool for pattern matching in text. Python provides regular expressions in the [`re`](https://docs.python.org/3/library/re.html) package.\n",
        "\n",
        "Regular expressions can get very complicated, but it is valuable to be familiar with them. This portion of the lab provides a basic introduction to regex and provides links to further details if you want to learn more."
      ],
      "metadata": {
        "id": "6ZZNGQhoVDqc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Motivating Example\n",
        "\n",
        "Let's say you want to find all posts that mention [Irn-Bru](https://en.wikipedia.org/wiki/Irn-Bru). One option would be to use the string contains operator (`in`):"
      ],
      "metadata": {
        "id": "W7NC0yTaWKvi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "[ p for p in reddit_posts if 'Irn-Bru' in p['title'] or 'Irn-Bru' in p['body'] ]"
      ],
      "metadata": {
        "id": "IB5M4O4ITQ6y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30feb776-690b-4950-d6c3-44c4e740f0dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hmm, nothing matches? Didn't we see the first post mentioned Irn-Bru?"
      ],
      "metadata": {
        "id": "qFHHlZktYNON"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reddit_posts[0]"
      ],
      "metadata": {
        "id": "uqtxBz8PYMmL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2069b1b-c94f-4c13-d719-4cbc53070052"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'subreddit': 'Soda',\n",
              " 'title': 'Anyone tried Irn Bru?',\n",
              " 'score': 8,\n",
              " 'id': 'ou5yp1',\n",
              " 'author': 'jackibhoy',\n",
              " 'body': 'It’s a Scottish drink and it’s banned some countries and I was wondering if anyone here has tried it. It has quite a unique taste and it’s not something you’d forget quickly. You either love it or hate it I think.'}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Indeed so, but they stylized it as \"Irn Bru\" rather than \"Irn-Bru\". There's probably other ways people might write it too, like IrnBru, Irnbru, etc. We could come up with a list of possibilities and control for different casing (like the code below), but we still might miss some. There's a simpler way using regular expressions.\n",
        "\n",
        "```python\n",
        "match_strings = ['irn-bru', 'irn bru', 'irnbru']\n",
        "[ p for p in reddit_posts if any(m in p['title'].lower() or m in p['body'].lower() for m in match_strings) ]\n",
        "```\n",
        "\n",
        "### Filtering with Regular Expressions\n",
        "\n",
        "A regular expression defines a pattern to match in text as a string. Most characters (letters, numbers) in a pattern match themselves. Some perform special functions, like making the previous character optional or allowing multiple characters to match. For instances:\n",
        " - \"`.`\" matches any character.\n",
        " - \"`?`\" makes the previous character optional.\n",
        "\n",
        "With this, we can define the regular expression `\"irn.?bru\"`, which will match `irn` and `bru` with any character (or no character) between them. An option allows case insensitive matching.\n",
        "\n",
        "We can use regular expressions in python by first importing the `re` package and then compiling our pattern."
      ],
      "metadata": {
        "id": "7WTMGfb8Yazn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "pattern = re.compile(r'irn.?bru', re.I) # re.I makes the pattern case insensitive"
      ],
      "metadata": {
        "id": "zdwtfULaY0ax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that the string with the regular expression has an `r` before. What's that about? That denotes that it is a raw string literal. It means that any [escape sequences](https://docs.python.org/3/reference/lexical_analysis.html#escape-sequences) (e.g. `\\t` for a tab or `\\\\` for a backslash) are ignored. It's often a good idea to use raw string literals (i.e. putting an `r` before the string) for regular expressions. Regular expressions use a lot of backslashes, and it's annoying to have to escape them repeatedly (i.e. having to write `\\\\` instead of `\\` every time).\n",
        "\n",
        "The pattern object can do all sorts of things. Most commonly, you will use the `search` function, which finds and returns the first place that the pattern matches a string."
      ],
      "metadata": {
        "id": "HdPqbd3niIzi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "match = pattern.search(\"Anyone tried Irn Bru?\")\n",
        "match"
      ],
      "metadata": {
        "id": "IAnKSfq5iN4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5946c02-2f0f-4d59-ad7d-1dab02e02e9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(13, 20), match='Irn Bru'>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The match object gives the character offsets of the match (`match.span`) and the text itself that matches (`match.group(0)`).\n",
        "\n",
        "If no match is found, `search` returns `None`, which evaluates as `False` when it's used in an `if` statement. This allows it to be easily used for filtering data. Using regular expressions, we find 6 posts about Irn-Bru."
      ],
      "metadata": {
        "id": "tYbnVJPXiglC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "[ p for p in reddit_posts if pattern.search(p['title']) or pattern.search(p['body']) ]"
      ],
      "metadata": {
        "id": "PlxoWsLShHwx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9f6c173-19a1-4c37-f8aa-e925775e97a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'subreddit': 'Soda',\n",
              "  'title': 'Anyone tried Irn Bru?',\n",
              "  'score': 8,\n",
              "  'id': 'ou5yp1',\n",
              "  'author': 'jackibhoy',\n",
              "  'body': 'It’s a Scottish drink and it’s banned some countries and I was wondering if anyone here has tried it. It has quite a unique taste and it’s not something you’d forget quickly. You either love it or hate it I think.'},\n",
              " {'subreddit': 'Soda',\n",
              "  'title': 'What is the worst or some of the worst sodas you have drunk',\n",
              "  'score': 3,\n",
              "  'id': 'nt40i4',\n",
              "  'author': 'EpicEllis2004',\n",
              "  'body': 'The absolute worst soda ive ever had that i can remember is probaly the new mystery fanta or watermelon+strawberry tango some other ones include mango coke, sugar free irn bru (but xtra is nice)'},\n",
              " {'subreddit': 'Soda',\n",
              "  'title': 'Why is creme soda flavor so common?',\n",
              "  'score': 0,\n",
              "  'id': 'ryn22l',\n",
              "  'author': 'Saracenanator',\n",
              "  'body': \"Typically this flavor of soda is sold with different colors but same flavor. I have tried Pakola, Inca Kola, Irn Bru etc and they all taste same. I'm wondering why so many countries make the same flavor?\"},\n",
              " {'subreddit': 'Soda',\n",
              "  'title': 'IRN-BRU @ Amazon for $7.26/month No shipping?',\n",
              "  'score': 1,\n",
              "  'id': 'nvlf0',\n",
              "  'author': 'AmantisAsoko',\n",
              "  'body': \"So I recently got a $25 gift card to Amazon.com and decided I'd get some of my FAVORITE imported soda from scotland, IRN-BRU.  As I was checking out I noticed this option:\\nSave an extra 15% with Subscribe & Save: Sign up to have this item delivered at a regular interval of your choice,\\n and the current price drops to $7.26 ($0.07 / oz) .\\n\\nShipping is always free. No fees, no risks, no obligations. See details\\n\\nHas anyone tried this? Usually shipping this stuff from Scotland is outrageous!\\nIf not, I've signed up for the monthly, and I'll let you know :D\\nEdit: I searched r/Soda, not a single Irn Bru discussion, feel free to have one of those here\"},\n",
              " {'subreddit': 'Soda',\n",
              "  'title': 'Anyone in the US tried Irn Bru?',\n",
              "  'score': 7,\n",
              "  'id': '1c0m8r',\n",
              "  'author': 'RedlineFan',\n",
              "  'body': \"I'm fortunate enough to live about 15 miles away from the famed Jungle Jim's International Market in Eastgate, Ohio.  I had heard some members of a British forum I frequent raving about the taste of a soda called Irn Bru.  I decided to get a can and find out what it tasted like for myself.\\nIt was...interesting.  The soda was amber in flavor, and very sweet.  I'm tempted to say it had a bit of a fruity tinge to it, but I couldn't specify which fruit.  A very hard to describe taste, to say the least.  The sweetness, however, made me decide that it really wasn't worth the $1.79 I spent on one can.\\nAnyone else tried Irn Bru?\"},\n",
              " {'subreddit': 'Soda',\n",
              "  'title': 'Able to get bottles of IRN BRU limited edition spiced ginger, cans of fanta fruit twist or any other uk soda,looking to trade for gatorade, arizona, and crystal lights sachets.',\n",
              "  'score': 3,\n",
              "  'id': 'g22n67',\n",
              "  'author': 'BringbackDreamBars',\n",
              "  'body': 'Its £20 shipping for me for 2kgs, so happy to negotiate on values.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that there are a variety of ways that people express Irn-Bru.\n",
        "\n",
        "**Exercise:** Can you write code that finds all the ways people express Irn-Bru in the dataset (e.g., \"Irn-Bru\", \"IRN BRU\", etc.)? Hint: you probably need to use the [`findall` function](https://docs.python.org/3/library/re.html#re.findall) with the `pattern` already defined above."
      ],
      "metadata": {
        "id": "QNcswjeikHz0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your answer here\n",
        "matches = []\n",
        "for p in reddit_posts:\n",
        "    if \"title\" in p:\n",
        "        matches.extend(re.findall(pattern, p[\"title\"]))\n",
        "    if \"body\" in p:\n",
        "        matches.extend(re.findall(pattern, p[\"body\"]))\n",
        "\n",
        "# Print the results\n",
        "print(\"Matches found:\", matches)\n",
        "\n"
      ],
      "metadata": {
        "id": "J8-GabEslnMW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea2f33aa-9369-48fc-abb6-29cd23c318c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matches found: ['Irn Bru', 'irn bru', 'Irn Bru', 'IRN-BRU', 'IRN-BRU', 'Irn Bru', 'Irn Bru', 'Irn Bru', 'Irn Bru', 'IRN BRU']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Irn Bru', 6), ('IRN-BRU', 2)]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(You should find that \"Irn Bru\" appears 6 times, \"IRN-BRU\" appears twice, \"IRN BRU\" once, and \"irn bru\" once.)"
      ],
      "metadata": {
        "id": "6Bq4NihLnRqL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's try to find some years mentioned in the text of the documents. you'll need to define a new pattern. You might find that a [regular expressions cheatsheet](https://cheatography.com/davechild/cheat-sheets/regular-expressions/) is helpful so you can look up the pattern for `digit`.\n",
        "\n",
        "**Exercise:** Find all 21st-century years (4 digit numbers starting with '20') in the title and bodies of the posts. What is the most common?"
      ],
      "metadata": {
        "id": "fUClndGDdg0G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your answer here\n",
        "new_pattern = r'\\b20[0-9]{2}\\b'\n",
        "matches = []\n",
        "for p in reddit_posts:\n",
        "    if \"title\" in p:\n",
        "        matches.extend(re.findall(new_pattern, p[\"title\"]))\n",
        "    if \"body\" in p:\n",
        "        matches.extend(re.findall(new_pattern, p[\"body\"]))\n",
        "\n",
        "# Print the results\n",
        "print(\"Matches found:\", matches)\n",
        "Counter(matches).most_common(2)"
      ],
      "metadata": {
        "id": "NCJ8HvwMdhrK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dccc4182-9596-4a1d-ea37-561eb533a983"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matches found: ['2017', '2013', '2016', '2022', '2015', '2000', '2014', '2022', '2015', '2016', '2018', '2018', '2022', '2017', '2013', '2013', '2016', '2017', '2021', '2021', '2018', '2018', '2018', '2018', '2012', '2012', '2077', '2080', '2080', '2080', '2080', '2080', '2020', '2021', '2019', '2015', '2019', '2020', '2020', '2007', '2019', '2006', '2009', '2017', '2018', '2019', '2013', '2013', '2018', '2017', '2013', '2013', '2021', '2019', '2018', '2015', '2015', '2019', '2011', '2015', '2013', '2005', '2020', '2021', '2016', '2021', '2012', '2013', '2014', '2015', '2016', '2014', '2017', '2007', '2015', '2000', '2042', '2012', '2016', '2008', '2017', '2018', '2018', '2018', '2019', '2015', '2010', '2014', '2016', '2009', '2016', '2015', '2006', '2015', '2014', '2015', '2016', '2016', '2017', '2016', '2015', '2042', '2020', '2006', '2010', '2018', '2019', '2017', '2019', '2020', '2021', '2012', '2012', '2012', '2015', '2015', '2021', '2019', '2017', '2017', '2020', '2020', '2022', '2022', '2019', '2077', '2012', '2020', '2020', '2020', '2020', '2020', '2060', '2080', '2070', '2060', '2017', '2016', '2018', '2020']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('2015', 15), ('2018', 14)]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[ p['title'] for p in reddit_posts if re.search(r'^(.).*\\1$', p['title']) ]"
      ],
      "metadata": {
        "id": "b5QaCDanvV-u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ffda730-1663-4164-8baf-0b1fe7fc56d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['r/HydroHomies Community Fundraiser',\n",
              " 'I just finished Dragon Quest XI',\n",
              " \"It's time for a new UI\",\n",
              " 'The HUNger Games - Building false engagement for PROF$T',\n",
              " 'My Fiancee wants to join an MLM',\n",
              " 'My coworker is into MLM',\n",
              " 'Should I Wait for Series X or Get Series S',\n",
              " 'r/why for',\n",
              " 'SO MANY FEELINGS',\n",
              " '\"Oh, we did Amyway once.\"']"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git init\n",
        "!git remote add origin https://github.com/GraceWangui/TextAsData---DS.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcRc06HXXFoF",
        "outputId": "8c77e21e-e91f-41f9-9e01-15d54957bd2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reinitialized existing Git repository in /content/.git/\n",
            "error: remote origin already exists.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git branch -M main\n",
        "!git branch -a\n",
        "!git checkout -b lab1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mq9sosHXXcyj",
        "outputId": "95a79daf-c6c1-41f7-afd9-b1811d46e3c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "* \u001b[32mmain\u001b[m\n",
            "Switched to a new branch 'lab1'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git branch -a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0Ll2Yf-X3_k",
        "outputId": "f6f7ab30-d353-4c65-8df3-dadde7970b2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "* \u001b[32mlab1\u001b[m\n",
            "  main\u001b[m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd ..\n"
      ],
      "metadata": {
        "id": "y--IdWL3bdKh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "agKxwIACbkZR",
        "outputId": "cc749102-3037-40bc-9f36-7f4d34fc3cf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!git config --global user.email \"quigrace99@gmail.com\"\n",
        "!git config --global user.name \"GraceWangui\"\n",
        "!git push -u origin lab1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODpHUOH-X9_5",
        "outputId": "b06ef2c2-4462-4854-a99e-c27385df9408"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: could not read Username for 'https://github.com': No such device or address\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nkp7If8mYbst",
        "outputId": "b1b58774-337f-4344-e4df-93458028648c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: could not read Username for 'https://github.com': No such device or address\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You should find that the digits `2016` appears 35 times across the posts.\n",
        "\n",
        "Now, a question: do you think all of those 4 digit numbers are actually years in the text. Could they be anything else?"
      ],
      "metadata": {
        "id": "93uo_7WHeZX7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Additional Resources\n",
        "\n",
        "These examples only scratch the surface of the capacities of regular expressions. We refer you to these resources for further details.\n",
        "\n",
        " - [RegExr](https://regexr.com/) -- Interactively build and evaluate regular expressions in a GUI. This can be helpful when trying to build a tricky regex or figure out why it's not matching what you want it to.\n",
        " - [RegexOne](https://regexone.com/) -- A detailed and interactive regular expression tutorial\n",
        " - [Python's `re` documentation](https://docs.python.org/3/library/re.html) -- Provides details about both regex syntax and Python's regex API"
      ],
      "metadata": {
        "id": "a5e4crdKVFSa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## End\n",
        "\n",
        "This is the end of Lab 0. Let us know if you encounter any issues! Remember we are here to help!\n",
        "\n",
        "In this lab, you...\n",
        "- started using Colab\n",
        "- loaded textual data from Reddit as a JSON file\n",
        "- explored the data to learn a bit about it\n",
        "- reviewed salient Python features, such as Counter and list comprehensions\n",
        "- explored using regular expressions in Python\n",
        "\n",
        "**Please remember to submit your completed lab and feedback form on Moodle.**\n"
      ],
      "metadata": {
        "id": "hIeO1UeINAjL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optional Extras\n",
        "\n",
        "The [cheatsheet](https://cheatography.com/davechild/cheat-sheets/regular-expressions/) may be handy for some of these. See if you can come up with a single regular expression for each problem.\n",
        "\n",
        "- Count how many Reddit posts in our dataset have titles that start with a digit followed by any character that isn't a digit (e.g. \"1A\" or \"7-\").\n",
        "- Count how many Reddit posts in our dataset have two 4-digit numbers in the body of the post? What about 4-digit numbers that are not part of larger bits of text (e.g. are properly separated - you could use `\\b` to indicate a [word boundary](https://www.regular-expressions.info/wordboundaries.html)).\n",
        "- Find Reddit posts where the title starts and ends with the same character. You likely need to use [backreferences](https://www.regular-expressions.info/backref.html) in the regular expression.\n",
        "- Write a regex that matches to [British postcodes](https://ideal-postcodes.co.uk/guides/uk-postcode-format) (e.g. G12 8RZ) and is agnostic if there is a space in the middle. You can make it fairly general or try to be more specific to the intricacies of the postcode standards. See if there are any matches in the Reddit posts. Are they actually postcodes?\n",
        "- Write a regex using the [re.sub function](https://docs.python.org/3/library/re.html#re.sub) that swaps the first part (the outcode) and second part (the incode) of a postcode (G128RZ -> 8RZG12). You could use backreferences as mentioned in the [re.sub documentation](https://docs.python.org/3/library/re.html#re.sub)."
      ],
      "metadata": {
        "id": "lQa3CLJveFMW"
      }
    }
  ]
}