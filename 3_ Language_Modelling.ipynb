{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1suGewMzIKsC"
      },
      "source": [
        "# Text as Data project 3: Language Modelling\n",
        "\n",
        "In this week's project,  explore basic techniques for language modelling.\n",
        "\n",
        "The aims of this project are:\n",
        "*   Model the probability of generating language\n",
        "*   Evaluating the quality of language model using perplexity\n",
        "*   Understand and address issues of sparsity in language modelling\n",
        "*   Learn applications of language models in understanding text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzZNFlTLit6R"
      },
      "source": [
        "**Before you start, save a copy of this project to your drive using \"File > Save a Copy in Drive\".** If you skip this step, you may lose progress that you have made (e.g., if you close the browser tab or your computer crashes)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSGmYYvKhzYN"
      },
      "source": [
        "**Note:** Colab may hide some of this project by collapsing a section. You'd see something that says \"X cells hidden\" (like below). Click on it to expand that section of the project."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwNJI8gYhzxa"
      },
      "source": [
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aH_of5OsGuii"
      },
      "source": [
        "## Setting up the labtest function\n",
        "\n",
        "As with previous projects,  use a `labtest` function so that you can check your code. You need to install and load it with the code below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-FNU1G7Qt_v7",
        "outputId": "9f874e76-e25f-4193-a916-195563be72be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/jakelever/glasgowcs_labtest.git\n",
            "  Cloning https://github.com/jakelever/glasgowcs_labtest.git to /tmp/pip-req-build-mbnx1k5f\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/jakelever/glasgowcs_labtest.git /tmp/pip-req-build-mbnx1k5f\n",
            "  Resolved https://github.com/jakelever/glasgowcs_labtest.git to commit 38b7b69854e507a4609e0fd1a6d933bff4542063\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: glasgowcs_labtest\n",
            "  Building wheel for glasgowcs_labtest (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for glasgowcs_labtest: filename=glasgowcs_labtest-1.1.6-py3-none-any.whl size=30007 sha256=a068acfb24da9c2ec7d269e888b4fe5ed2721b13fd8e6cd80b0398daac207ab5\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-bnkhts_7/wheels/d8/27/59/a0aa2eb4007eb0f2ca7228c1eb406ba1d7fbfd5412b56452af\n",
            "Successfully built glasgowcs_labtest\n",
            "Installing collected packages: glasgowcs_labtest\n",
            "Successfully installed glasgowcs_labtest-1.1.6\n"
          ]
        }
      ],
      "source": [
        "# Installs the labtest system and loads the tests for this specific project\n",
        "\n",
        "!pip install -U git+https://github.com/jakelever/glasgowcs_labtest.git\n",
        "from glasgowcs_labtest.textasdata.lab3 import labtest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "napJywoXLO7u"
      },
      "source": [
        "## Loading the Reddit data\n",
        "\n",
        " be using the same Reddit data from the previous projects. I will download it and tokenize it with [spaCy](https://spacy.io/) for later use.\n",
        "\n",
        "**This time, I are going to tokenize it a little differently.**\n",
        "\n",
        "First, let's download it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ax-gRXfWIcVq",
        "outputId": "9a7b17c5-fccc-4db2-c716-893c06f26d3f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-01-31 17:04:45--  https://gla-my.sharepoint.com/:u:/g/personal/jake_lever_glasgow_ac_uk/EY_R8Y7DkrxMqXGe-zlgeNkBdJU5ZNTf8FYrN2pqDwddMA?download=1\n",
            "Resolving gla-my.sharepoint.com (gla-my.sharepoint.com)... 13.107.136.10, 13.107.138.10, 2620:1ec:8f8::10, ...\n",
            "Connecting to gla-my.sharepoint.com (gla-my.sharepoint.com)|13.107.136.10|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://gla-my.sharepoint.com/personal/jake_lever_glasgow_ac_uk/_layouts/15/download.aspx?UniqueId=8ef1d18f92c34cbca9719efb396078d9 [following]\n",
            "--2025-01-31 17:04:46--  https://gla-my.sharepoint.com/personal/jake_lever_glasgow_ac_uk/_layouts/15/download.aspx?UniqueId=8ef1d18f92c34cbca9719efb396078d9\n",
            "Reusing existing connection to gla-my.sharepoint.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1279064 (1.2M) [application/json]\n",
            "Saving to: ‘reddit_posts.json’\n",
            "\n",
            "reddit_posts.json   100%[===================>]   1.22M  1.88MB/s    in 0.6s    \n",
            "\n",
            "2025-01-31 17:04:47 (1.88 MB/s) - ‘reddit_posts.json’ saved [1279064/1279064]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget -O reddit_posts.json https://gla-my.sharepoint.com/:u:/g/personal/jake_lever_glasgow_ac_uk/EY_R8Y7DkrxMqXGe-zlgeNkBdJU5ZNTf8FYrN2pqDwddMA?download=1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lziRq9bixzuj"
      },
      "source": [
        "Let's load in the posts:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fe7eLDpzImYF",
        "outputId": "1c8a7438-f91d-458d-f0f5-7b6c49297150"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2000"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "with open('reddit_posts.json') as f:\n",
        "    posts = json.load(f)\n",
        "\n",
        "len(posts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rqH8dC6x050"
      },
      "source": [
        "A reminder of what a post looks like:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5zzUtTSgcqT",
        "outputId": "073a4003-3483-47df-d1cc-412bab6738a4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'subreddit': 'Soda',\n",
              " 'title': 'Anyone tried Irn Bru?',\n",
              " 'score': 8,\n",
              " 'id': 'ou5yp1',\n",
              " 'author': 'jackibhoy',\n",
              " 'body': 'It’s a Scottish drink and it’s banned some countries and I was wondering if anyone here has tried it. It has quite a unique taste and it’s not something you’d forget quickly. You either love it or hate it I think.'}"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "posts[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDEaWotax3Ju"
      },
      "source": [
        "### Alternative parsing\n",
        "\n",
        " going to do a few things differently this time.\n",
        "\n",
        "1.  going to use a slimmed down version of spaCy. This is to show that you can turn off bits of spaCy and make it **a lot** faster.\n",
        "2.  going to keep stopwords this time\n",
        "3.  not going to lemmatize, but I will still use the lowercase version of the token text\n",
        "\n",
        "I want to split the text into its tokens and not do anything special to them.\n",
        "\n",
        "Let's load in a slimmed down version of spaCy with a few things (e.g. tagger, parser, NER) turned off."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gB1SEq_B1jYc",
        "outputId": "d8adee0b-cafc-465e-9e10-4d24166fa9fb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('lemmatizer', <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x7bf2b7028390>)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import spacy\n",
        "\n",
        "# Load the small english model.\n",
        "# Disable the advanced NLP features in the pipeline for efficiency.\n",
        "nlp = spacy.load('en_core_web_sm', disable=['ner'])\n",
        "nlp.remove_pipe('tagger')\n",
        "nlp.remove_pipe('parser')\n",
        "nlp.remove_pipe('lemmatizer')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2LT0Y8nyeWr"
      },
      "source": [
        "And  define a modified version of the spaCy pipeline function from previous projects that doesn't throw away stopwords and gives the original text, not lemmas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pbv8yE5LyeeV"
      },
      "outputs": [],
      "source": [
        "def text_pipeline_spacy_special(text):\n",
        "  tokens = []\n",
        "  doc = nlp(text)\n",
        "  for t in doc:\n",
        "    if not t.is_punct and not t.is_space: # what I removed: \"not t.is_stop and\"\n",
        "      tokens.append(t.text.lower()) # what I changed: t.text instead of t.lemma_\n",
        "  return tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAV7cr_qywdy"
      },
      "source": [
        "Now if I tokenize everything, it is much faster."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kl4nh7eKfe9m",
        "outputId": "98c2ab2c-e5b0-47be-b30d-f33a6fa53c26"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2000/2000 [00:22<00:00, 90.68it/s]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm # This provides a nice progress bar\n",
        "\n",
        "for post in tqdm(posts):\n",
        "    post['tokens'] = text_pipeline_spacy_special(post['title'] + '\\n' + post['body'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFse93LXy8DM"
      },
      "source": [
        "### Flattening the tokens\n",
        "\n",
        "For this project, I want to deal with the whole collection of posts as a single long list of tokens.  make one list and combine each post with a special token `<START>` at the beginning of each."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivXZChNE0M3C",
        "outputId": "b2e16d08-fe1c-4d1a-ac5e-b2ff6b8bda4b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "189428"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "posts_flattened_tokens = []\n",
        "for post in posts:\n",
        "  posts_flattened_tokens += ['<START>'] + post['tokens']\n",
        "len(posts_flattened_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQsFNGH2zSH5"
      },
      "source": [
        "That's quite a few tokens!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smF8x1ODzNcn"
      },
      "source": [
        "And again,  make a little mini corpus of sentences and create the same flattened list of tokens with the `<START>` special token before each sentence. This will be useful for a few places later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGXrr37Ohw3F",
        "outputId": "695cbc0e-2899-46ee-9fcd-adb12aeadc34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['<START>', 'my', 'favourite', 'soft', 'drink', 'is', 'apple', 'tango', 'but', 'i', 'also', 'love', 'irn', 'bru', '<START>', 'irn', 'bru', 'is', 'a', 'great', 'drink', '<START>', 'i', 'once', 'found', 'a', 'can', 'of', 'irn', 'bru', 'in', 'st', 'petersburg', '<START>', 'irn', 'bru', 'is', 'a', 'soft', 'drink', 'launched', 'in', '1901', 'by', 'ag', 'barr', '<START>', 'irn', 'bru', 'is', 'made', 'at', 'ag', 'barr', 'in', 'cumbernauld']\n"
          ]
        }
      ],
      "source": [
        "mini_sentences = [\n",
        "    \"My favourite soft drink is Apple Tango, but I also love Irn Bru.\",\n",
        "    \"Irn Bru is a great drink.\",\n",
        "    \"I once found a can of Irn Bru in St Petersburg.\",\n",
        "    \"Irn Bru is a soft drink launched in 1901 by AG Barr.\",\n",
        "    \"IRN-BRU is made at AG Barr in Cumbernauld.\"\n",
        "]\n",
        "\n",
        "mini_flattened = []\n",
        "for x in mini_sentences:\n",
        "  mini_flattened += ['<START>'] + text_pipeline_spacy_special(x)\n",
        "\n",
        "print(mini_flattened)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78XpfWSHF9n6"
      },
      "source": [
        "## Unigram language model\n",
        "\n",
        " going to start with a unigram language model. This will provide the probability of each token occurring and has lots of uses.\n",
        "\n",
        "Recall that a unigram model treats each token independently and does not take any context (i.e. the previous tokens) into account.\n",
        "\n",
        "Before I calculate the unigram probabilities, I need to calculate the unigram counts.  use the [Counter](https://docs.python.org/3/library/collections.html#collections.Counter) class again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qno5picKWLy7"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "posts_unigram_counts = Counter(posts_flattened_tokens)\n",
        "posts_unigram_N = len(posts_flattened_tokens) # also the same as sum(posts_unigram_counts.values())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKdgmVnp01hz"
      },
      "source": [
        "I can get the number of times that 'irn' appears in the posts:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UcyYMK5M05kJ",
        "outputId": "c88a6b82-2968-4fc3-9bac-862e961ec9f7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "posts_unigram_counts['irn']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tf5-Ct4l1EOl"
      },
      "source": [
        "Now time to calculate unigram probabilities:\n",
        "\n",
        "**Exercise:** Write a function `unigram_token_prob` that given a token, the unigram counts and the total number of unigrams, returns the probability of that token\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gcg8jO3gg0qd",
        "outputId": "f5856110-026f-43f2-e3b4-3cfe4d074e37"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5.279050615537302e-05"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ANSWER\n",
        "def unigram_token_prob(next_token, unigram_counts, unigram_N):\n",
        "  return unigram_counts[next_token] / unigram_N\n",
        "\n",
        "unigram_token_prob('irn', posts_unigram_counts, posts_unigram_N)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nh7ZUQN1mBx"
      },
      "source": [
        "Check that your function returns a probability of zero for a new unseen token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEUWJjvS1lQL",
        "outputId": "a2888a05-9e25-4671-f550-02eb71332902"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "unigram_token_prob('totallynotatoken', posts_unigram_counts, posts_unigram_N)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwsD6NUi1xMp"
      },
      "source": [
        "And now you can run the labtest function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lr7FBJFI1DdO",
        "outputId": "06a062c8-27f0-48ed-ddc8-6f6ced1df1a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------\n",
            "LABTEST: Running 5 testcases\n",
            "----------------------------\n",
            "Input: ('cup', {'cup': 2, 'spoon': 2, 'glass': 6, 'fork': 1}, 11). Running... \n",
            "Output: 0.18182\n",
            "OK.\n",
            "\n",
            "Input: ('plate', {'plate': 2, 'cup': 2, 'fork': 5, 'spoon': 5}, 14). Running... \n",
            "Output: 0.14286\n",
            "OK.\n",
            "\n",
            "Input: ('fork', {'bowl': 4, 'fork': 5, 'plate': 3, 'cup': 1}, 13). Running... \n",
            "Output: 0.38462\n",
            "OK.\n",
            "\n",
            "Input: ('cup', {'plate': 2, 'glass': 3, 'fork': 1, 'cup': 1}, 7). Running... \n",
            "Output: 0.14286\n",
            "OK.\n",
            "\n",
            "Input: ('glass', {'glass': 5, 'spoon': 3}, 8). Running... \n",
            "Output: 0.625\n",
            "OK.\n",
            "\n",
            "----------------------------\n",
            "5 testcases PASSED\n",
            "----------------------------\n"
          ]
        }
      ],
      "source": [
        "labtest(unigram_token_prob)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQFdSOO01-Co"
      },
      "source": [
        "Now I can use the individual token probabilities to calculate the probability of a whole sequence. Remember that the unigram probability of a sequence treats each token independently:\n",
        "\n",
        "$$ P(w_1, ... w_N) = \\prod_{i=1}^N \\hat{p}(w_i) $$\n",
        "\n",
        "**Exercise:** Write a function `unigram_sequence_prob` that given a sequence of tokens (and the unigram data), calculates the probability of the sequence.\n",
        "\n",
        "Remember that if a sequence contains a token that doesn't exist in the corpus, the probability of the sequence should be zero."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lUuyQjMWl7j",
        "outputId": "eb3b6dce-d97f-485f-ef87-e5011a247472"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5.810905251121602e-13"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ANSWER\n",
        "\n",
        "def unigram_sequence_prob(sequence, unigram_counts, unigram_N):\n",
        "  prob = 1\n",
        "  for t in sequence:\n",
        "    prob *= unigram_token_prob(t, unigram_counts, unigram_N)\n",
        "\n",
        "  return prob\n",
        "\n",
        "unigram_sequence_prob(['i', 'like', 'irn', 'bru'], posts_unigram_counts, posts_unigram_N)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6UfEUYoC3ObO",
        "outputId": "bbc613d5-d449-4ba7-a6b9-330485609d5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------\n",
            "LABTEST: Running 5 testcases\n",
            "----------------------------\n",
            "Input: (['glass', 'glass', 'glass', 'cup', 'cup'], {'cup': 2, 'spoon': 2, 'glass': 6, 'fork': 1}, 11). Running... \n",
            "Output: 0.00536\n",
            "OK.\n",
            "\n",
            "Input: (['spoon', 'spoon', 'fork'], {'fork': 1, 'spoon': 5}, 6). Running... \n",
            "Output: 0.11574\n",
            "OK.\n",
            "\n",
            "Input: (['fork', 'fork', 'cup', 'fork'], {'fork': 2, 'glass': 6, 'cup': 4}, 12). Running... \n",
            "Output: 0.00154\n",
            "OK.\n",
            "\n",
            "Input: (['glass', 'cup', 'fork', 'cup', 'cup'], {'cup': 5, 'glass': 3, 'fork': 1}, 9). Running... \n",
            "Output: 0.00635\n",
            "OK.\n",
            "\n",
            "Input: (['spoon', 'spoon', 'spoon', 'glass'], {'fork': 1, 'glass': 1, 'bowl': 6, 'spoon': 2}, 10). Running... \n",
            "Output: 0.0008\n",
            "OK.\n",
            "\n",
            "----------------------------\n",
            "5 testcases PASSED\n",
            "----------------------------\n"
          ]
        }
      ],
      "source": [
        "labtest(unigram_sequence_prob)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubeEHwkk2yUD"
      },
      "source": [
        "For long sequences, I start multiplying by very small numbers. This is a very bad idea computationally. Computers only have a limited number of bits for a number and precision problems start happening when multiplying by lots of small numbers.\n",
        "\n",
        "A better idea is to do everything with logarithms.  work with log base 2 here. The above equation becomes:\n",
        "\n",
        "$$ LogP(w_1, ... w_N) = \\sum_{i=1}^N \\log_2 \\hat{p}(w_i) $$\n",
        "\n",
        "**Exercise:** Write a function `unigram_sequence_logprob` which is equivalent to the `unigram_sequence_prob` method but using log2 and summation as in the equation above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IY3hnAVYXbc3",
        "outputId": "8cd116b0-6405-456a-a13c-4085b4e21c1b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "-40.64630230233775"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ANSWER\n",
        "\n",
        "import math\n",
        "\n",
        "def unigram_sequence_logprob(sequence, unigram_counts, unigram_N):\n",
        "  logprob = 0\n",
        "  for t in sequence:\n",
        "    logprob += math.log2(unigram_token_prob(t, unigram_counts, unigram_N))\n",
        "\n",
        "  return logprob\n",
        "\n",
        "unigram_sequence_logprob(['i', 'like', 'irn', 'bru'], posts_unigram_counts, posts_unigram_N)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Vuv6YAN4FEA"
      },
      "source": [
        "I can sanity check that it's working by taking the log2 of the original function and seeing if I get the same result."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DXv003LXlvF",
        "outputId": "eaf91326-b53a-4b97-8084-1fbed9e4c21d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "-40.64630230233775"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "math.log2(unigram_sequence_prob(['i', 'like', 'irn', 'bru'], posts_unigram_counts, posts_unigram_N))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Nt2z8XZ4DSG",
        "outputId": "daa129b3-7f45-4e18-fbb7-987638f93b0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------\n",
            "LABTEST: Running 5 testcases\n",
            "----------------------------\n",
            "Input: (['glass', 'glass', 'glass', 'cup', 'cup'], {'cup': 2, 'spoon': 2, 'glass': 6, 'fork': 1}, 11). Running... \n",
            "Output: -7.54227\n",
            "OK.\n",
            "\n",
            "Input: (['spoon', 'spoon', 'fork'], {'fork': 1, 'spoon': 5}, 6). Running... \n",
            "Output: -3.11103\n",
            "OK.\n",
            "\n",
            "Input: (['fork', 'fork', 'cup', 'fork'], {'fork': 2, 'glass': 6, 'cup': 4}, 12). Running... \n",
            "Output: -9.33985\n",
            "OK.\n",
            "\n",
            "Input: (['glass', 'cup', 'fork', 'cup', 'cup'], {'cup': 5, 'glass': 3, 'fork': 1}, 9). Running... \n",
            "Output: -7.29888\n",
            "OK.\n",
            "\n",
            "Input: (['spoon', 'spoon', 'spoon', 'glass'], {'fork': 1, 'glass': 1, 'bowl': 6, 'spoon': 2}, 10). Running... \n",
            "Output: -10.28771\n",
            "OK.\n",
            "\n",
            "----------------------------\n",
            "5 testcases PASSED\n",
            "----------------------------\n"
          ]
        }
      ],
      "source": [
        "labtest(unigram_sequence_logprob)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZ1mMO8jxD7W"
      },
      "source": [
        "Let's try computing the unigram probabilities of a few tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MoRWLmmCwa4o",
        "outputId": "aaf8aecf-b96e-4e1f-a8fd-b35cd3cf5bd1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pr( the ): 0.0327195557151002\n",
            "Pr( game ): 0.0038114745444179318\n",
            "Pr( defenenstrate ): 0.0\n"
          ]
        }
      ],
      "source": [
        "for token in ['the','game','defenenstrate']:\n",
        "  print(\"Pr(\",token,\"):\", unigram_token_prob(token, posts_unigram_counts, posts_unigram_N))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PM6aSVrnzCOX"
      },
      "source": [
        "The probabilities should be about 3% for 'the', 0.4% for 'game' and 0 for 'defenestrate'.\n",
        "\n",
        "Now, try computing the probability of a sequence of tokens.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHIVlXHrxb9y",
        "outputId": "0cd2ce1e-1849-4258-fc3a-a0876f1e51e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.0000000000000000000010693914958728715991\n"
          ]
        }
      ],
      "source": [
        "probability = unigram_sequence_prob([\"the\", \"end\", \"of\", \"the\", \"world\", \"as\", \"I\", \"know\", \"it\"], posts_unigram_counts, posts_unigram_N)\n",
        "print('{:.40f}'.format(probability))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFnlo0cSzsLP"
      },
      "source": [
        "This is already a very small number and most of the values in these sequence are large by typical probability values. This is the reason that I usually do the probability computation in log space in practice to avoid problems of underflow."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5igWwh7t5uLx"
      },
      "source": [
        "## Application: Spelling correction\n",
        "\n",
        "I can use this simple language model to build a spelling corrector.\n",
        "\n",
        "This builds on ideas of a [spelling corrector from code by Peter Norvig](http://norvig.com/spell-correct.html), a director of research at Google."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U20bFiEg5JxX"
      },
      "source": [
        "### The objective\n",
        "\n",
        "For a given misspelled token, I want to find candidate tokens that it could be assuming that the real token is only a few edits away. With those candidate tokens, I will then calculate the most likely with the language model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QT49Ugk45zE5"
      },
      "source": [
        "### Edit distance\n",
        "\n",
        "\n",
        "What do I mean by edits? Perhaps, I transposed two letters, accidentally added a letter, or deleted a letter, etc.\n",
        "\n",
        "I need a function that can generate a list of tokens that are a single edit away. For example 'go' is one edit away from 'lo'.\n",
        "\n",
        "Here is the `generate_edits1` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VNdTveBY8Bn",
        "outputId": "dec68b7c-0fe7-45c7-d501-13192aa854c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'inr', 'irnf', 'imn', 'iyrn', 'irnk', 'iry', 'irfn', 'lirn', 'ibn', 'ibrn', 'irjn', 'irun', 'irt', 'jirn', 'irpn', 'iri', 'irl', 'irln', 'cirn', 'irrn', 'irno', 'irnd', 'hrn', 'oirn', 'irng', 'iru', 'sirn', 'igrn', 'irk', 'trn', 'icn', 'irne', 'irnq', 'qirn', 'nirn', 'inrn', 'wrn', 'irna', 'irns', 'irnc', 'irj', 'girn', 'isn', 'ird', 'in', 'ien', 'itn', 'brn', 'irqn', 'idn', 'iqrn', 'iwrn', 'lrn', 'zrn', 'vrn', 'dirn', 'ira', 'ixrn', 'frn', 'ern', 'irg', 'mrn', 'irnl', 'irdn', 'iern', 'imrn', 'ilrn', 'grn', 'irvn', 'irnw', 'ivn', 'firn', 'ifrn', 'irx', 'iyn', 'ian', 'ipn', 'airn', 'irnr', 'irkn', 'iun', 'idrn', 'iran', 'arn', 'ircn', 'irnb', 'srn', 'iorn', 'irnj', 'irnp', 'irz', 'ikn', 'rn', 'ign', 'ijn', 'zirn', 'icrn', 'irn', 'jrn', 'irnz', 'iro', 'ihrn', 'iirn', 'irnn', 'iren', 'iprn', 'ijrn', 'crn', 'irnh', 'iln', 'irnv', 'iryn', 'irv', 'ivrn', 'hirn', 'orn', 'iron', 'urn', 'iarn', 'itrn', 'irni', 'ion', 'irin', 'irwn', 'rin', 'tirn', 'uirn', 'izrn', 'irzn', 'xirn', 'iurn', 'kirn', 'irp', 'ire', 'rirn', 'qrn', 'ifn', 'ir', 'ihn', 'irb', 'virn', 'mirn', 'irxn', 'irf', 'pirn', 'ikrn', 'irnm', 'prn', 'yrn', 'irr', 'irnu', 'irtn', 'inn', 'irw', 'irgn', 'yirn', 'iqn', 'izn', 'iin', 'rrn', 'irsn', 'isrn', 'iwn', 'irhn', 'krn', 'irh', 'irny', 'xrn', 'irc', 'nrn', 'irs', 'irnt', 'drn', 'irbn', 'irm', 'irnx', 'ixn', 'wirn', 'birn', 'irmn', 'eirn', 'irq'}\n"
          ]
        }
      ],
      "source": [
        "def generate_edits1(token):\n",
        "  \"All edits that are one edit away from `token`.\"\n",
        "  letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
        "  splits     = [(token[:i], token[i:])  for i in range(len(token) + 1)]\n",
        "  deletes    = [L + R[1:]               for L, R in splits if R]\n",
        "  transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
        "  replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
        "  inserts    = [L + c + R               for L, R in splits for c in letters]\n",
        "  return set(deletes + transposes + replaces + inserts)\n",
        "\n",
        "print(generate_edits1('irn'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldsGqStOMMdr"
      },
      "source": [
        "And I may want to get tokens that are two edits away."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJylYYJoZI1v",
        "outputId": "f6dc79bf-6331-42f2-a3e2-750555485fad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'erz', 'irnfm', 'wiarn', 'irjn', 'hoirn', 'ixrnp', 'tirnr', 'iyln', 'irnbw', 'irsyn', 'parn', 'zirne', 'iadrn', 'isfrn', 'exn', 'unirn', 'irnxw', 'grnb', 'ipq', 'ired', 'itng', 'zrs', 'diron', 'fun', 'giru', 'irlny', 'isrvn', 'ccn', 'qron', 'tirf', 'ilnv', 'tirxn', 'irnnq', 'grhn', 'tign', 'frnc', 'irgsn', 'ixrnr', 'mitn', 'irns', 'srun', 'brs', 'irdxn', 'opn', 'oron', 'idurn', 'iqrk', 'dwrn', 'arrn', 'irhnx', 'jirun', 'crzn', 'virnn', 'iuan', 'ifnw', 'tinr', 'iwrn', 'ikzn', 'irnyk', 'qrk', 'ireg', 'iznc', 'irnvc', 'irqns', 'irhc', 'fkrn', 'yirwn', 'tire', 'irtln', 'itrnc', 'urun', 'kcn', 'pibrn', 'hwn', 'nirnw', 'isrsn', 'dnr', 'ibnrn', 'itron', 'wiyrn', 'ihj', 'virt', 'irncz', 'itrwn', 'zisn', 'mrnk', 'qurn', 'ain', 'icwn', 'orqn', 'qen', 'grsn', 'ixrnf', 'ieyn', 'jrnr', 'lirkn', 'fixn', 'irygn', 'irnef', 'iyn', 'uirnw', 'yirnm', 'zixn', 'irkon', 'irenp', 'lsirn', 'uxn', 'icrnb', 'ibno', 'ilrnu', 'pjrn', 'iruwn', 'tiln', 'xiqn', 'igrm', 'imrnl', 'irfwn', 'siin', 'iarnd', 'fcn', 'rwin', 'iure', 'irzp', 'rh', 'iwryn', 'timrn', 'rrhn', 'qirb', 'irxnp', 'eirg', 'dirdn', 'ecn', 'irznw', 'idrr', 'hr', 'hijrn', 'zyn', 'sirjn', 'iiyn', 'iranq', 'xry', 'iwurn', 'pirv', 'irepn', 'ixgrn', 'fivn', 'crx', 'eitrn', 'irink', 'vign', 'niro', 'iwdn', 'mrdn', 'zqirn', 'ioq', 'bivrn', 'irucn', 'irnvy', 'yro', 'iczrn', 'jirns', 'ium', 'yirnf', 'irxi', 'iuzn', 'ilnb', 'qzirn', 'jrnm', 'ijrxn', 'risrn', 'irknn', 'wirz', 'tiun', 'msn', 'ilwn', 'airnk', 'zihn', 'lsrn', 'ik', 'irpun', 'irsl', 'irnwm', 'firl', 'zirns', 'mirvn', 'firnh', 'jion', 'ial', 'eijrn', 'ibrxn', 'erxn', 'icnb', 'irmnj', 'ipnp', 'ihrng', 'iij', 'zrnl', 'eirf', 'piurn', 'ixrin', 'ixcn', 'irsc', 'imns', 'mry', 'itrl', 'irbtn', 'ctn', 'irsqn', 'jiry', 'ihnh', 'srirn', 'ixn', 'ren', 'ipjrn', 'irfnr', 'imrna', 'irmcn', 'mpn', 'srjn', 'ivl', 'ksn', 'ikln', 'din', 'ici', 'irur', 'ljrn', 'yxirn', 'iyrnz', 'piorn', 'ifyn', 'jirr', 'pirfn', 'iqzn', 'eire', 'tyrn', 'virni', 'airnc', 'diirn', 'irnqd', 'scirn', 'chn', 'eirin', 'irnuq', 'irlnm', 'wrne', 'ircq', 'ihy', 'giwrn', 'ijnrn', 'irncy', 'ernv', 'ilrv', 'mirno', 'irone', 'grng', 'fir', 'zyirn', 'urnu', 'kiun', 'ufirn', 'ijkrn', 'iprmn', 'rirnq', 'iqdn', 'irunq', 'zln', 'islrn', 'pcrn', 'irltn', 'icrx', 'icrnr', 'gkirn', 'irbnw', 'zrnd', 'irenz', 'rfn', 'fri', 'iew', 'arnt', 'virj', 'iupn', 'sin', 'iq', 'prvn', 'igin', 'sirgn', 'ierb', 'ihrno', 'gry', 'iriln', 'icrtn', 'ticn', 'irjnt', 'jiin', 'iryv', 'qirdn', 'irbnb', 'ijrnm', 'crxn', 'yirni', 'ipen', 'iim', 'cirne', 'linn', 'wrf', 'gien', 'pirna', 'irnpz', 'imhn', 'irzgn', 'qan', 'xcn', 'krnt', 'irnoi', 'ziri', 'ilra', 'ivf', 'dirpn', 'nirjn', 'ehrn', 'iad', 'sicrn', 'oidn', 'hri', 'wsn', 'ixx', 'irixn', 'gzirn', 'iirj', 'xirz', 'nkn', 'kry', 'izmn', 'wcrn', 'xrv', 'drj', 'lirnn', 'oilrn', 'girpn', 'imrno', 'iprj', 'inxr', 'diwn', 'ipnm', 'jbirn', 'imrmn', 'irntw', 'ityrn', 'idbn', 'oirnu', 'ivrd', 'rnh', 'agrn', 'hrk', 'iii', 'trmn', 'itnh', 'iuurn', 'irbfn', 'nhrn', 'mijn', 'qirnc', 'irdz', 'iqrxn', 'wrtn', 'irnba', 'wiun', 'irlhn', 'iowrn', 'zrni', 'dirnj', 'ivrw', 'lrjn', 'isrnj', 'imprn', 'rt', 'iwrwn', 'nsrn', 'irgna', 'brf', 'iurn', 'eirj', 'ibrns', 'irds', 'xirnc', 'vhirn', 'iwhn', 'hwirn', 'zirnb', 'dhn', 'brnp', 'mizrn', 'gisrn', 'urt', 'visn', 'ih', 'iqnk', 'irnqm', 'nern', 'fzirn', 'imirn', 'irsnx', 'irngq', 'iyrng', 'xrfn', 'qrxn', 'qrl', 'psirn', 'injn', 'zn', 'bgn', 'ort', 'zairn', 'innx', 'iromn', 'ilran', 'rikn', 'hirnx', 'irkpn', 'int', 'irnkc', 'cixn', 'iurrn', 'ilrwn', 'irzno', 'zprn', 'irnzb', 'tyirn', 'virny', 'krk', 'ivcn', 'lihrn', 'crhn', 'wrnz', 'nrnd', 'ijr', 'ikbn', 'xirt', 'birdn', 'igx', 'irnng', 'iring', 'dpn', 'ijrnb', 'rrnm', 'xirnb', 'idpn', 'zirw', 'iegrn', 'ifre', 'dijrn', 'irxvn', 'irnje', 'iqdrn', 'iyrnd', 'rid', 'irqjn', 'irnut', 'ilnj', 'irxnv', 'nirnp', 'fizn', 'xidrn', 'ripn', 'iojrn', 'jirvn', 'ryin', 'ulrn', 'iorg', 'iruc', 'con', 'xiorn', 'vivn', 'ipra', 'isqrn', 'kvrn', 'isrni', 'trpn', 'irdns', 'irkb', 'giyrn', 'ibg', 'gcrn', 'frfn', 'irtnj', 'ifzn', 'lzn', 'ims', 'itpn', 'iena', 'iarnh', 'deirn', 'irnck', 'oiru', 'gran', 'xdrn', 'iornv', 'girnj', 'eirnx', 'iqnv', 'iurna', 'ivnn', 'ipna', 'iwnw', 'lirvn', 'ivrq', 'ixh', 'ilrh', 'iuk', 'irnmv', 'irrr', 'kgirn', 'iox', 'isrnu', 'nirln', 'aiorn', 'irnzm', 'biun', 'hirq', 'firv', 'lirnc', 'vrne', 'irnti', 'isdrn', 'arnh', 'iroo', 'izdrn', 'iprzn', 'tidrn', 'itre', 'ironq', 'drq', 'nnrn', 'irea', 'iign', 'orl', 'irqgn', 'irnla', 'rrdn', 'orz', 'rinz', 'irup', 'vrh', 'igvrn', 'irmdn', 'oirx', 'ciwn', 'riu', 'ied', 'ierg', 'intn', 'zrnc', 'irnab', 'ilrnx', 'inrno', 'srnh', 'zjrn', 'ifrhn', 'dirnx', 'irtny', 'irjan', 'ircs', 'yprn', 'irutn', 'nru', 'irnz', 'irdnk', 'frdn', 'lrny', 'ilmrn', 'iprn', 'itrnw', 'eirnz', 'yirnu', 'lqrn', 'irngc', 'urnp', 'iyrrn', 'irino', 'pmn', 'xgirn', 'xiyn', 'hisn', 'irhln', 'ibrnh', 'ivng', 'ipan', 'ivrnk', 'zrp', 'bidrn', 'icpn', 'armn', 'idrrn', 'ijs', 'ixron', 'itna', 'xfn', 'xirw', 'iirnq', 'ingrn', 'iree', 'ril', 'grni', 'hrun', 'irvnp', 'uirnk', 'ijrnk', 'nrl', 'irlna', 'irnyg', 'itnc', 'shn', 'ixs', 'brny', 'frna', 'ircsn', 'idorn', 'aprn', 'iymn', 'igmn', 'ricn', 'mirns', 'crnj', 'igrqn', 'wirna', 'tjn', 'erw', 'ieh', 'iqjrn', 'ihrp', 'een', 'ivwrn', 'icnj', 'irnie', 'yrirn', 'qimrn', 'irphn', 'urne', 'irxnw', 'iunk', 'iqfn', 'lnn', 'cmrn', 'frq', 'iprne', 'iphrn', 'ixne', 'figrn', 'ixrp', 'ysrn', 'izg', 'irnen', 'nwn', 'iyrns', 'icrfn', 'isxn', 'irpn', 'qxn', 'jzn', 'ihu', 'xipn', 'idvn', 'ink', 'ionz', 'ionf', 'ifbrn', 'knrn', 'idi', 'irnow', 'itrxn', 'zirrn', 'niren', 'irgx', 'izern', 'irknv', 'ixnk', 'ikrng', 'inurn', 'krtn', 'ilnx', 'tirns', 'iuv', 'giln', 'ibrl', 'iprnd', 'irydn', 'irnq', 'iwnp', 'irnzv', 'erfn', 'ixrzn', 'icdrn', 'isin', 'irjdn', 'fra', 'svrn', 'irxnf', 'nrne', 'qixn', 'iarqn', 'iynp', 'ipren', 'irikn', 'irnxl', 'idrkn', 'vrv', 'obrn', 'irnny', 'iozn', 'vircn', 'virnz', 'izk', 'uirbn', 'iyk', 'iyrni', 'pro', 'iurdn', 'ircon', 'irdtn', 'ifrng', 'pxirn', 'ivry', 'icno', 'qry', 'tiprn', 'isrnx', 'jirnw', 'eign', 'irxnr', 'jrnc', 'irzd', 'vrni', 'zirzn', 'prnj', 'iip', 'xsrn', 'cgrn', 'yirng', 'irnpm', 'lrtn', 'klrn', 'irnnc', 'crtn', 'aurn', 'irww', 'wxn', 'ils', 'itxn', 'tuirn', 'sbrn', 'ibhrn', 'irrj', 'idrqn', 'irern', 'irnku', 'irhnm', 'ierz', 'ioirn', 'irnrn', 'ikorn', 'svirn', 'ichrn', 'tian', 'ias', 'ilrk', 'ogn', 'igrna', 'irnlm', 'cfrn', 'ivwn', 'birnz', 'ifln', 'fdirn', 'iyyrn', 'vitn', 'ithrn', 'iujn', 'irnoc', 'oircn', 'iuwn', 'ilrvn', 'frnu', 'iwne', 'iqrnd', 'itmn', 'sirnj', 'ilrhn', 'zrt', 'ialrn', 'qbirn', 'ilrs', 'iid', 'ijrl', 'oirnd', 'lro', 'tirnt', 'pnirn', 'irafn', 'irtx', 'mion', 'irkln', 'icrnl', 'hira', 'gizn', 'ierna', 'iklrn', 'crnx', 'irznf', 'irca', 'ihrz', 'eryn', 'ifjn', 'vien', 'ifrr', 'irxzn', 'dinn', 'iarb', 'xrj', 'ionv', 'irw', 'tisrn', 'ibvn', 'irhun', 'inp', 'rrnq', 'rrn', 'irxns', 'imrnp', 'jrzn', 'iirnh', 'irrng', 'ilnr', 'nirnd', 'firdn', 'ivrr', 'irobn', 'piqn', 'mrnb', 'pion', 'ikmn', 'vxrn', 'lirnq', 'sirnq', 'iktrn', 'imdrn', 'hirnw', 'icnf', 'viwn', 'irfjn', 'uiwn', 'drg', 'inrna', 'drnh', 'jrv', 'irhnz', 'irvnj', 'birbn', 'ivre', 'yirnt', 'igj', 'ivrnw', 'ibfn', 'oipn', 'irgp', 'ibnn', 'yri', 'oiyrn', 'ignq', 'igvn', 'dinrn', 'ignw', 'girnn', 'diqrn', 'vinr', 'ierxn', 'jpn', 'wirnq', 'girhn', 'mrh', 'oivrn', 'grvn', 'cgn', 'ivns', 'kimn', 'irntm', 'jrm', 'irro', 'ztrn', 'idna', 'inrdn', 'doirn', 'binrn', 'qrgn', 'pirnc', 'imrl', 'htrn', 'cuirn', 'irnmj', 'imrun', 'iarnt', 'ikns', 'firu', 'nrt', 'cirnt', 'iprno', 'bkrn', 'irxs', 'iyfrn', 'mqirn', 'irokn', 'rink', 'crun', 'aihn', 'giron', 'irnee', 'irpdn', 'irci', 'xun', 'ipnw', 'rixn', 'irbnv', 'qivrn', 'lirnf', 'ircyn', 'uirny', 'iyran', 'ifrsn', 'iirjn', 'drbn', 'idgrn', 'igrne', 'erny', 'pirz', 'inrnr', 'ikqrn', 'vcrn', 'ard', 'iek', 'bbrn', 'icnw', 'qkrn', 'mrnt', 'ijg', 'ilno', 'iprnr', 'icrz', 'vibrn', 'icin', 'birw', 'yirrn', 'tijrn', 'ijt', 'ikxrn', 'uirl', 'irso', 'jihrn', 'irand', 'ibbrn', 'inrqn', 'ipnu', 'iof', 'irhnc', 'crcn', 'ibny', 'cirz', 'oiin', 'rirnv', 'izrs', 'qiirn', 'nrln', 'xra', 'nzirn', 'izrt', 'ierq', 'imrnv', 'irhns', 'iernl', 'zrpn', 'iky', 'ixmn', 'trz', 'zirc', 'rru', 'iswrn', 'izln', 'oirnl', 'kirgn', 'ixb', 'lirdn', 'han', 'iprs', 'wirzn', 'ide', 'sikn', 'yvirn', 'iwrns', 'mirnd', 'igjrn', 'irbzn', 'ist', 'irnll', 'irean', 'icg', 'frcn', 'xiqrn', 'imbrn', 'ogirn', 'virnb', 'iwron', 'ipf', 'mnn', 'ijrh', 'irnh', 'ilk', 'krwn', 'irgnx', 'srsn', 'irpz', 'ihrkn', 'vbn', 'irfvn', 'zigrn', 'irmvn', 'miron', 'iruzn', 'inrk', 'urjn', 'ucrn', 'qrb', 'ity', 'ixq', 'ciro', 'qrnq', 'isren', 'dlirn', 'sron', 'irfc', 'otn', 'ijv', 'iirk', 'ifrnf', 'iwrz', 'tln', 'isnrn', 'riqn', 'rirqn', 'izrin', 'cijrn', 'ikk', 'mirbn', 'jirwn', 'ikrns', 'tidn', 'mirpn', 'irqj', 'qizn', 'kra', 'cron', 'llirn', 'ruin', 'iirnf', 'azn', 'ijp', 'irkcn', 'guirn', 'firbn', 'mifrn', 'ilern', 'orjn', 'irndi', 'trnp', 'iqnh', 'ibrnq', 'iuo', 'iqrnw', 'hkrn', 'mbn', 'uijrn', 'virne', 'ibwn', 'inmrn', 'iroqn', 'qrin', 'rizrn', 'irrg', 'lrnv', 'gcn', 'jisn', 'inzr', 'cirzn', 'wrx', 'jrnu', 'imn', 'irhgn', 'eirpn', 'xirnn', 'irdq', 'wiqrn', 'sirt', 'irena', 'ijnz', 'airh', 'tnr', 'ittrn', 'jircn', 'irnjy', 'ikfrn', 'ijrnw', 'otrn', 'iurnn', 'sira', 'icnk', 'nry', 'mirfn', 'tirk', 'irnmb', 'irnry', 'kiqrn', 'eihn', 'ite', 'ru', 'qrnv', 'ivrrn', 'idk', 'ianrn', 'ixrb', 'nyn', 'xirb', 'iurjn', 'iqno', 'irrnf', 'imtrn', 'ixt', 'irnji', 'tiryn', 'oln', 'itnrn', 'uirni', 'sjrn', 'cirk', 'ornf', 'icns', 'yirna', 'hirl', 'qrkn', 'yikn', 'erh', 'huirn', 'ofirn', 'qrfn', 'wlrn', 'ijwrn', 'ieron', 'igrvn', 'syrn', 'ipk', 'iarnj', 'uen', 'iror', 'durn', 'xrqn', 'erf', 'vnirn', 'ritrn', 'irxnu', 'ibern', 'irsno', 'oen', 'drfn', 'cirkn', 'lrnc', 'iwrna', 'inrnq', 'uirns', 'yiryn', 'born', 'qrm', 'eirq', 'ivzn', 'iwni', 'irhny', 'cirmn', 'izd', 'sen', 'mrny', 'arirn', 'vrg', 'arnz', 'pizrn', 'zirgn', 'iuyn', 'iirnt', 'frns', 'sirb', 'etn', 'irwi', 'jitn', 'mfrn', 'eizrn', 'inhn', 'ionp', 'tirnk', 'ikrgn', 'irynq', 'idrz', 'hifrn', 'irwm', 'irdno', 'irzg', 'itarn', 'liry', 'hrfn', 'zirnk', 'iijn', 'irto', 'imra', 'ilon', 'fwirn', 'arnf', 'iwp', 'vrmn', 'irfnv', 'pisn', 'ekrn', 'irini', 'irqm', 'dirni', 'irnmh', 'bizn', 'iqs', 'irpny', 'iwno', 'ikni', 'isrnw', 'grnr', 'ilcrn', 'epirn', 'ioorn', 'witrn', 'rnp', 'mdrn', 'rrun', 'eun', 'iqrb', 'hun', 'izrnw', 'dirh', 'reirn', 'diurn', 'irsw', 'iyzn', 'irnvi', 'firnc', 'irrpn', 'hire', 'ibrk', 'igsn', 'yicn', 'xirny', 'rirnk', 'tirnw', 'ijf', 'arxn', 'irsnv', 'igrc', 'eorn', 'qirnt', 'xrxn', 'irnrg', 'ifnd', 'iornd', 'irnas', 'crkn', 'sirfn', 'iruh', 'ihtn', 'inno', 'irck', 'iirne', 'mrsn', 'nrj', 'ikrhn', 'urwn', 'rairn', 'iznr', 'zrna', 'lirj', 'irezn', 'cirnx', 'irfnc', 'hdn', 'irgns', 'yihrn', 'uign', 'irqpn', 'sisn', 'firq', 'biurn', 'ivnh', 'ipw', 'irupn', 'brz', 'irarn', 'ivun', 'irtf', 'trln', 'irtnr', 'yinrn', 'itp', 'ivlrn', 'irndj', 'ivorn', 'hiarn', 'irnvh', 'ibnm', 'thrn', 'ircfn', 'arun', 'hcirn', 'sisrn', 'irmg', 'uirvn', 'pirpn', 'uirln', 'inr', 'irnal', 'jrbn', 'iwrnn', 'idln', 'jirn', 'irbnj', 'fbirn', 'irzh', 'irvi', 'iarhn', 'bvn', 'cimrn', 'eiarn', 'rirw', 'nrnm', 'ixnv', 'dire', 'irnfk', 'jirk', 'irbqn', 'irdnr', 'nrnz', 'izrqn', 'irnui', 'ordn', 'izrvn', 'drirn', 'ikrxn', 'iqun', 'iqrnb', 'irldn', 'irnyj', 'idfn', 'zrq', 'rirnf', 'hirnl', 'irctn', 'jiarn', 'iae', 'srz', 'yibn', 'zsrn', 'idh', 'irbi', 'eikrn', 'imren', 'ihry', 'imry', 'imnp', 'nrng', 'miyn', 'kirb', 'ifrcn', 'frqn', 'piri', 'oirj', 'xirwn', 'yrnc', 'jrnf', 'iirfn', 'isrin', 'iyrz', 'ziorn', 'ivnx', 'brt', 'ijrbn', 'trdn', 'prnk', 'rins', 'ijrno', 'firnb', 'ibnd', 'neirn', 'cibrn', 'eixrn', 'ihs', 'rw', 'iqyn', 'ienrn', 'idern', 'irpo', 'girnm', 'airx', 'ovn', 'viurn', 'ikrv', 'irgqn', 'orq', 'niin', 'qrh', 'imrn', 'idwrn', 'rrns', 'firg', 'iwrf', 'dirxn', 'ioran', 'hirzn', 'wdirn', 'ireng', 'sirvn', 'irenn', 'zirnj', 'inc', 'fign', 'crv', 'idvrn', 'iernn', 'irdbn', 'uyirn', 'irhp', 'rvirn', 'yirnk', 'ihrny', 'irnvk', 'ihcrn', 'or', 'srni', 'ienn', 'acrn', 'zifn', 'ipnq', 'arnr', 'iornc', 'ihorn', 'iroin', 'iknrn', 'idry', 'irxni', 'nizn', 'itrnp', 'irze', 'hirun', 'iwg', 'okirn', 'wiyn', 'lrd', 'irol', 'iimn', 'ieon', 'irnec', 'wrbn', 'irtnn', 'ifsrn', 'iervn', 'ornb', 'ihrq', 'rren', 'aien', 'zrirn', 'izrb', 'eirxn', 'irtgn', 'jzirn', 'sirtn', 'iznz', 'ijnt', 'iznd', 'lrln', 'indn', 'irrnp', 'iqi', 'irsmn', 'irnhl', 'qrni', 'frc', 'vprn', 'irrp', 'irnqt', 'iforn', 'pirnt', 'rir', 'irjcn', 'jurn', 'zwirn', 'iinn', 'iekrn', 'jqrn', 'irnij', 'idny', 'irnka', 'ii', 'ircbn', 'qiurn', 'zivn', 'igrnt', 'eirng', 'lirnz', 'izns', 'iqy', 'aion', 'ibo', 'iwrun', 'krt', 'iexrn', 'wsirn', 'iug', 'irpon', 'irncu', 'irnrv', 'ixzn', 'irou', 'cairn', 'iinl', 'diyrn', 'oirq', 'tiron', 'iyrxn', 'irenk', 'nxn', 'ircin', 'nibn', 'dirnt', 'airnu', 'pirnm', 'irynu', 'qrt', 'iars', 'irgc', 'dirsn', 'itrnr', 'tiirn', 'pircn', 'iyrr', 'rhrn', 'vzirn', 'irjnf', 'irwnz', 'iyrjn', 'iyon', 'ikcrn', 'ijkn', 'grj', 'iye', 'grp', 'ieu', 'irsni', 'irinq', 'frnb', 'birv', 'iroen', 'tirhn', 'ivj', 'oiron', 'akrn', 'iedrn', 'ilre', 'icne', 'isnn', 'iwrjn', 'irgu', 'wrn', 'qryn', 'orfn', 'dirc', 'irpnz', 'rirq', 'rtirn', 'irumn', 'smrn', 'zvirn', 'irmnn', 'izrnb', 'irnaf', 'irwng', 'wtn', 'lun', 'irpqn', 'itn', 'isrr', 'ihrnc', 'ixbn', 'frk', 'tron', 'brnt', 'izryn', 'tirnx', 'inrne', 'irogn', 'qrnb', 'qirnq', 'irdk', 'irnic', 'izran', 'wirs', 'ornm', 'iirnj', 'birin', 'istrn', 'iranv', 'irmf', 'irbbn', 'lirf', 'irew', 'hrtn', 'adirn', 'idre', 'arnb', 'irhvn', 'iiv', 'arp', 'ircnp', 'uirno', 'jidrn', 'esrn', 'tirnh', 'xrgn', 'jwirn', 'iaorn', 'rre', 'wqirn', 'wirnw', 'tiarn', 'ibs', 'vicn', 'ara', 'bijn', 'irba', 'ibrnk', 'zbn', 'itrnz', 'bsirn', 'uzrn', 'imnf', 'imr', 'lxn', 'iornu', 'ihryn', 'wjrn', 'ivrj', 'itnf', 'irnuu', 'wyirn', 'irhnb', 'uryn', 'exirn', 'ipnl', 'rbirn', 'iwnm', 'isran', 'ahn', 'wrz', 'igran', 'ernl', 'eihrn', 'vra', 'crn', 'irant', 'iurhn', 'imrnb', 'tirnl', 'irvnz', 'ixrjn', 'irnoj', 'ifrq', 'ibrnu', 'irtl', 'irndl', 'diro', 'yirkn', 'siren', 'xnn', 'crqn', 'qtirn', 'vir', 'irngr', 'ixrnw', 'urpn', 'vdirn', 'irunu', 'ircnd', 'ilrin', 'ifna', 'irpb', 'nrnc', 'cre', 'ixrs', 'hiru', 'eirny', 'qiyn', 'irnpf', 'dicrn', 'iirno', 'irnmz', 'innq', 'sibn', 'irvgn', 'irgl', 'ilrp', 'irniw', 'iqrjn', 'nsn', 'wrnk', 'yyrn', 'irbin', 'irnzh', 'igh', 'itnd', 'uirj', 'irnbq', 'birgn', 'cirnv', 'ifrmn', 'iwfn', 'jrr', 'eirhn', 'xryn', 'civrn', 'ish', 'icrnu', 'iwn', 'irntd', 'rinf', 'brdn', 'irgnb', 'urr', 'iruyn', 'nirnu', 'irnqn', 'rln', 'knirn', 'lvn', 'zcn', 'itr', 'itin', 'iqron', 'kirny', 'virgn', 'ynirn', 'ury', 'trf', 'irnzc', 'trrn', 'sirzn', 'kirpn', 'izne', 'hirfn', 'inbn', 'itny', 'itrnk', 'zirg', 'trt', 'rmin', 'fimn', 'irpnh', 'rign', 'vln', 'ickrn', 'iudn', 'irnip', 'dirnh', 'orhn', 'irga', 'iru', 'oiarn', 'divrn', 'isl', 'irbln', 'sirun', 'icra', 'irjmn', 'irlnq', 'ifwrn', 'hiern', 'irzon', 'erhn', 'irstn', 'oigrn', 'ere', 'yiurn', 'eiro', 'irndk', 'prnr', 'eiron', 'qirq', 'iqrdn', 'surn', 'pqrn', 'idng', 'irdmn', 'iyrnx', 'miurn', 'fn', 'ebn', 'inw', 'eirgn', 'irnvd', 'irnlr', 'iyrnc', 'iirin', 'eiin', 'iranb', 'wrv', 'iray', 'nirs', 'wnn', 'virno', 'mrbn', 'ireni', 'irg', 'eirnd', 'isrc', 'ifm', 'ins', 'krb', 'irsdn', 'oijrn', 'oiri', 'mrhn', 'irdp', 'rorn', 'iernu', 'urng', 'ilrz', 'isrfn', 'pirnb', 'ro', 'iing', 'ijrk', 'ixvrn', 'ifrnj', 'irnjj', 'eirdn', 'xiru', 'brkn', 'jirni', 'ijny', 'prpn', 'dfrn', 'egn', 'iyern', 'nrr', 'zrxn', 'drjn', 'ishn', 'giun', 'irnwg', 'irtk', 'oiun', 'ilrng', 'irhin', 'izrnu', 'yn', 'ijsn', 'sirp', 'fhrn', 'irfnh', 'tsn', 'dirwn', 'wrl', 'oikn', 'rrt', 'livn', 'miren', 'xiin', 'ikrin', 'ifrl', 'ytn', 'irxnq', 'iernk', 'ifv', 'iurzn', 'isno', 'ijj', 'iuyrn', 'eien', 'icrq', 'irni', 'kign', 'vnr', 'dirx', 'ihv', 'vrnw', 'ilnm', 'ftn', 'vpn', 'krnw', 'inkrn', 'zird', 'itrnx', 'crnt', 'inyrn', 'irmrn', 'qifrn', 'jrns', 'ilrnw', 'liln', 'iraq', 'inv', 'iryan', 'irnxd', 'ihnw', 'ipe', 'ibon', 'aird', 'imzrn', 'dxn', 'virnt', 'iwgrn', 'ziwrn', 'iirp', 'ijvrn', 'izrnk', 'trgn', 'igi', 'irnff', 'irxy', 'cirnc', 'iwru', 'irec', 'irpxn', 'umn', 'kirnp', 'xrn', 'imh', 'nrno', 'iwb', 'irpt', 'zjirn', 'brin', 'pryn', 'yr', 'wisrn', 'aicn', 'hjirn', 'irmjn', 'brd', 'ikrh', 'irfg', 'zrnj', 'intrn', 'drt', 'irkan', 'icnd', 'irvf', 'wwn', 'grh', 'irfqn', 'ieny', 'imrni', 'ibrn', 'syirn', 'siwn', 'nrnv', 'ireun', 'itnv', 'pdrn', 'oirln', 'pqn', 'innz', 'tirnv', 'tilrn', 'ibtrn', 'lbn', 'oibn', 'irhs', 'fisrn', 'izq', 'inxrn', 'irhxn', 'frwn', 'iercn', 'ibrnm', 'irnda', 'ihrnn', 'inrny', 'bikn', 'yrq', 'mrx', 'irnzz', 'siurn', 'asn', 'igwn', 'jirln', 'frno', 'itrx', 'irnnp', 'pirbn', 'trnx', 'ires', 'irvw', 'isra', 'irknp', 'rnirn', 'miyrn', 'iwo', 'itrbn', 'ikrdn', 'irgk', 'irvb', 'hrirn', 'irnaj', 'ibu', 'tmrn', 'irxnj', 'cen', 'aifrn', 'in', 'irhcn', 'ffirn', 'zirz', 'jln', 'dirun', 'iyrsn', 'irgne', 'aiqn', 'qiran', 'van', 'iorw', 'ipron', 'oiorn', 'arbn', 'iprl', 'otirn', 'jirt', 'gicrn', 'ixrwn', 'xrkn', 'irnpb', 'usn', 'jiyn', 'ciru', 'vrm', 'mhn', 'ionq', 'iwwrn', 'imro', 'vvirn', 'pmirn', 'uirnv', 'ich', 'ikrnl', 'pitrn', 'ibnb', 'mrxn', 'ivz', 'iqrnu', 'iujrn', 'frsn', 'ipxrn', 'uun', 'icnl', 'jirnn', 'nlirn', 'are', 'irvne', 'imyn', 'miran', 'frh', 'xfirn', 'diry', 'usrn', 'qmn', 'ieyrn', 'xiern', 'kirnd', 'yhn', 'nwrn', 'iync', 'jirne', 'idfrn', 'iraxn', 'ifrnk', 'gird', 'iruvn', 'izrnq', 'jikn', 'brp', 'irkr', 'zrz', 'nimrn', 'airng', 'iruhn', 'prd', 'gre', 'pipn', 'viyrn', 'ixe', 'ibrq', 'irnql', 'nnr', 'cjn', 'incr', 'bzn', 'irvno', 'itwn', 'yinr', 'iruk', 'hirln', 'uihn', 'yfn', 'hirmn', 'ivna', 'ienr', 'oihrn', 'xrnm', 'pimrn', 'arf', 'hyrn', 'bprn', 'irwh', 'hirnb', 'brl', 'hiqrn', 'nirsn', 'tion', 'iqan', 'eirc', 'uiran', 'pirt', 'ifon', 'irewn', 'pikn', 'kkirn', 'krnz', 'irniu', 'iotn', 'ikh', 'iax', 'irton', 'hrz', 'irneu', 'izrnn', 'irknl', 'lrgn', 'irwy', 'itrg', 'tzirn', 'fry', 'iqn', 'ibna', 'lrnp', 'qivn', 'ikrzn', 'iyw', 'irync', 'pirk', 'ycirn', 'iyna', 'icry', 'ixqn', 'jrnv', 'irnt', 'pirs', 'gtrn', 'fsrn', 'iuns', 'efn', 'iwrcn', 'iryfn', 'frp', 'pirsn', 'nyrn', 'biran', 'bkirn', 'gihn', 'ixqrn', 'mirna', 'hrp', 'uiry', 'rrcn', 'izurn', 'ikrrn', 'lhrn', 'mire', 'irek', 'wurn', 'ihrns', 'nirnh', 'irxhn', 'ierh', 'iwbrn', 'jdn', 'grnz', 'iornh', 'juirn', 'unr', 'iqrf', 'irmm', 'irxin', 'kwn', 'xrnn', 'ibrd', 'iodrn', 'iwr', 'iiny', 'gtn', 'ipzrn', 'iddrn', 'yirtn', 'ziyrn', 'rcirn', 'oiren', 'siqn', 'vidrn', 'irnkd', 'oire', 'viyn', 'innn', 'ijnr', 'jxrn', 'ifnu', 'icirn', 'irqi', 'wwirn', 'ivnw', 'weirn', 'hbirn', 'mitrn', 'irnye', 'irxnm', 'fimrn', 'ihhrn', 'yrv', 'iccn', 'qidrn', 'iic', 'iarjn', 'iril', 'isb', 'zirnx', 'dirtn', 'nire', 'girnl', 'iurln', 'xsn', 'wnr', 'pitn', 'frin', 'irsnp', 'kro', 'ixnh', 'irxwn', 'lyrn', 'iric', 'iprnz', 'iwrnp', 'iirt', 'irnkt', 'irfna', 'ndn', 'eirnw', 'icnr', 'hirnv', 'sirh', 'cicn', 'ivrwn', 'isrny', 'tlirn', 'iqmrn', 'ixbrn', 'zirf', 'irnfd', 'xnr', 'iana', 'ikne', 'oimrn', 'esn', 'iufn', 'dcirn', 'irgin', 'glrn', 'ipo', 'irxnh', 'igtn', 'xirbn', 'isyn', 'icrb', 'xln', 'hrvn', 'girr', 'nrv', 'zirb', 'ignk', 'irnez', 'irmo', 'brnn', 'irmfn', 'uimn', 'eirl', 'isrnn', 'drdn', 'irwnw', 'icprn', 'isen', 'kirxn', 'zrrn', 'liorn', 'xlrn', 'ivb', 'iurqn', 'joirn', 'iprpn', 'erb', 'crdn', 'hairn', 'ildrn', 'nbirn', 'kuirn', 'csrn', 'ixf', 'iertn', 'iao', 'irnon', 'citrn', 'igrnn', 'irnjz', 'hnrn', 'ihxn', 'isln', 'viryn', 'ikrf', 'frnz', 'tren', 'irthn', 'irim', 'wirne', 'emn', 'sion', 'ncirn', 'iean', 'ixln', 'iurno', 'ojn', 'irnu', 'wirx', 'igk', 'xirc', 'rjirn', 'izrl', 'birb', 'irrnr', 'iwjn', 'ipne', 'airni', 'rirl', 'ijnf', 'lien', 'irnyf', 'krn', 'yikrn', 'ryrn', 'ijdn', 'irwin', 'irxan', 'irs', 'firnw', 'iabn', 'irnjm', 'itnq', 'ironj', 'irra', 'irnzq', 'crc', 'ilqn', 'irnah', 'irbo', 'iairn', 'rurn', 'irgmn', 'vrb', 'irnrm', 'ijh', 'ixxrn', 'pirmn', 'itrq', 'yrh', 'ikprn', 'ikl', 'giin', 'iynz', 'ionn', 'zifrn', 'irsnw', 'irnfq', 'irnwn', 'vsrn', 'airyn', 'qzn', 'irljn', 'chrn', 'irtnk', 'crns', 'irnkp', 'aire', 'cibn', 'nirq', 'iwrnc', 'sirg', 'ifrln', 'biru', 'rdirn', 'urnx', 'krs', 'flrn', 'firon', 'kron', 'iwsn', 'irngg', 'srj', 'irlf', 'eirnf', 'irunr', 'irvnl', 'yirnl', 'ivnrn', 'irnbx', 'iutn', 'irfan', 'aipn', 'irnpc', 'ihfrn', 'idrne', 'isnw', 'frun', 'fyirn', 'dirhn', 'iih', 'sirnb', 'ircy', 'omrn', 'ihru', 'vry', 'irdyn', 'irnhf', 'iqrg', 'ihrnt', 'bqrn', 'inri', 'irdun', 'iyns', 'izren', 'irwxn', 'ifnh', 'tirbn', 'ifb', 'qirkn', 'idnt', 'irvnv', 'kirwn', 'miorn', 'irfa', 'igxn', 'igng', 'sorn', 'birns', 'mwn', 'irnr', 'irfne', 'inq', 'oiryn', 'sra', 'irjen', 'ciyn', 'girnw', 'igrsn', 'birnw', 'iqc', 'virqn', 'irki', 'ifsn', 'irqq', 'irmsn', 'irurn', 'iyen', 'xkn', 'irzmn', 'grnw', 'cifn', 'iyrg', 'qwrn', 'pnrn', 'ierm', 'irhjn', 'iuu', 'zirdn', 'piwn', 'iinu', 'ewn', 'emirn', 'itorn', 'irknk', 'hcn', 'irnqr', 'ifrd', 'ujn', 'irav', 'ylrn', 'ibf', 'iwi', 'iasn', 'iernv', 'ibe', 'irqnx', 'rpirn', 'qpn', 'ixrf', 'ierzn', 'yrg', 'irsp', 'ari', 'ionl', 'ixrqn', 'ilnu', 'ornu', 'drw', 'irenq', 'iln', 'irenw', 'irmne', 'irjnk', 'irofn', 'hirng', 'pirnq', 'ixkrn', 'irmny', 'ignc', 'ibng', 'ipqn', 'hrrn', 'xitrn', 'iwx', 'crr', 'wiran', 'sirnp', 'vhn', 'zrnu', 'gnn', 'prgn', 'diwrn', 'iuon', 'iret', 'jnrn', 'iwnb', 'rrz', 'ietn', 'qrjn', 'jizn', 'iyv', 'icnt', 'igrln', 'irbz', 'rix', 'igbrn', 'iqrqn', 'eifrn', 'ar', 'iruun', 'dirr', 'iirnl', 'lirc', 'irnzl', 'khrn', 'lgrn', 'irnqp', 'itfn', 'prfn', 'pirr', 'ienw', 'mhrn', 'grjn', 'imrhn', 'arc', 'grln', 'irhni', 'irngm', 'zrng', 'uirsn', 'pn', 'irsnf', 'irrne', 'icrnh', 'nqn', 'srf', 'ihjrn', 'frt', 'iparn', 'aan', 'citn', 'cilrn', 'midn', 'ikwrn', 'itrni', 'oirr', 'iork', 'qrnx', 'pivn', 'ihb', 'iwrnb', 'uin', 'iant', 'vrhn', 'infrn', 'eyrn', 'uran', 'arv', 'hirnk', 'irwc', 'irnhr', 'iyrnh', 'dikn', 'iurnf', 'rgrn', 'viro', 'irpln', 'nirno', 'firno', 'ornv', 'iib', 'abn', 'ixern', 'ibc', 'kdirn', 'irl', 'jhrn', 'zirnu', 'irln', 'irjfn', 'dbrn', 'iunrn', 'srnm', 'qrne', 'irid', 'sdrn', 'irzrn', 'rrj', 'tibrn', 'krgn', 'irnoa', 'virrn', 'irwna', 'uidrn', 'iirw', 'lyn', 'irneb', 'mirnz', 'nrin', 'irenf', 'dign', 'ubn', 'xyn', 'iprm', 'iqrq', 'irnod', 'irknb', 'virm', 'sinn', 'rern', 'irnhq', 'irenc', 'yzirn', 'pixn', 'irony', 'irhnn', 'dirz', 'iqrkn', 'ionh', 'dixrn', 'irocn', 'wprn', 'crt', 'iso', 'ermn', 'iqrnl', 'iuro', 'iyrp', 'vihn', 'ilqrn', 'icrno', 'inrcn', 'arnu', 'irnpg', 'inlrn', 'irnak', 'iskn', 'grtn', 'iqrnq', 'gibrn', 'xn', 'hrnn', 'irzsn', 'icrin', 'gnr', 'coirn', 'iroj', 'ilr', 'icrj', 'iohrn', 'ilf', 'irmbn', 'irrnk', 'bsn', 'kin', 'zrc', 'oqrn', 'rirjn', 'oian', 'jijn', 'itrsn', 'xirl', 'irzqn', 'izrjn', 'irnvz', 'inar', 'iourn', 'krhn', 'eimn', 'aiarn', 'imnr', 'wrna', 'iaen', 'ilrb', 'ure', 'isnf', 'iccrn', 'irnmx', 'ifnk', 'qqrn', 'itrnd', 'brns', 'rip', 'iirhn', 'iqru', 'rjn', 'iqrvn', 'nrfn', 'zrnf', 'ixen', 'imsn', 'lkirn', 'jsrn', 'xnirn', 'virv', 'qrx', 'hihrn', 'brxn', 'ijru', 'irpu', 'ioru', 'kibn', 'iorpn', 'erqn', 'irnis', 'rsrn', 'irovn', 'dira', 'iorng', 'iorjn', 'ivnd', 'jrnp', 'xwirn', 'ipnrn', 'irqy', 'virnf', 'viin', 'airun', 'ixrng', 'silrn', 'jjrn', 'nirdn', 'iqnn', 'irnld', 'xikrn', 'iyrfn', 'liri', 'oirny', 'axrn', 'oirnr', 'pairn', 'inrz', 'rinrn', 'irbw', 'iwf', 'eirln', 'ainrn', 'ifrzn', 'irynz', 'pirn', 'ignz', 'ibrcn', 'iriw', 'iqrl', 'iskrn', 'irknh', 'riyrn', 'fiin', 'hrno', 'irnfs', 'iqln', 'ibni', 'ixrkn', 'qvn', 'irxu', 'urin', 'hirhn', 'lxrn', 'rrno', 'zirng', 'irnyo', 'cdn', 'irnws', 'xbirn', 'dfirn', 'firm', 'kinr', 'iynu', 'gfn', 'rnq', 'xrx', 'irniy', 'qitrn', 'dirnk', 'dirns', 'idrwn', 'mirnp', 'inxn', 'mrt', 'iernw', 'rryn', 'irsk', 'txn', 'efrn', 'bran', 'milrn', 'srnv', 'ibrnf', 'kirf', 'firnj', 'irnbj', 'mirf', 'iygn', 'trxn', 'intr', 'lrne', 'iune', 'mrnf', 'xijn', 'ironv', 'izz', 'edrn', 'lon', 'iare', 'ikkrn', 'firln', 'ips', 'iranp', 'picrn', 'cirfn', 'rirkn', 'krnn', 'iroyn', 'ilbrn', 'urnw', 'trne', 'ijnu', 'diun', 'ernf', 'ibw', 'irnfe', 'ujirn', 'iarrn', 'jn', 'cprn', 'irnbo', 'hrb', 'zrd', 'jirsn', 'irqln', 'irntx', 'zisrn', 'hirqn', 'vkrn', 'irodn', 'ihro', 'isrmn', 'jirnc', 'irano', 'itrtn', 'wrr', 'irnkn', 'jprn', 'lirz', 'gxirn', 'ihrqn', 'irgni', 'prs', 'fiwrn', 'yixn', 'tirdn', 'cvn', 'brk', 'jirrn', 'irxyn', 'ikun', 'irqny', 'yiin', 'ejrn', 'nrb', 'irnzf', 'iop', 'irwnh', 'zzrn', 'mirln', 'ikd', 'rinx', 'srd', 'mwirn', 'trnr', 'rnz', 'enr', 'irwnd', 'irngn', 'ibrin', 'iryi', 'ihk', 'irnav', 'inrnb', 'einn', 'itrnh', 'ihvn', 'iqrs', 'purn', 'krne', 'oirns', 'icjn', 'gzn', 'irbj', 'tiqrn', 'irgg', 'airon', 'arno', 'grd', 'ivrz', 'nirny', 'gurn', 'irnok', 'iprln', 'giry', 'tfn', 'irnac', 'jiran', 'iesrn', 'birh', 'myrn', 'ioj', 'sir', 'igrg', 'qbrn', 'iwrnx', 'dirnr', 'micn', 'ircnx', 'irrhn', 'irxng', 'iyrnu', 'iwrdn', 'knn', 'frnh', 'irpne', 'irkh', 'firtn', 'ipnj', 'irnth', 'ynr', 'igrj', 'qiarn', 'nisn', 'ipd', 'gibn', 'irem', 'girnh', 'ijk', 'sicn', 'riln', 'irznc', 'zirnp', 'xrirn', 'iatn', 'ivra', 'wrq', 'mrnm', 'irqnk', 'srna', 'imzn', 'irppn', 'zilrn', 'ircx', 'qir', 'irnxr', 'tiorn', 'irdnq', 'idirn', 'zipn', 'irfnf', 'irbu', 'ivryn', 'irjq', 'inrpn', 'izrnm', 'xirnj', 'invr', 'iunc', 'kikn', 'simrn', 'riy', 'iwrhn', 'abrn', 'oiry', 'ijrrn', 'wrgn', 'irwnl', 'srgn', 'irivn', 'ibrb', 'irwnr', 'khirn', 'nprn', 'icrnz', 'irnmp', 'isrun', 'uivn', 'ixro', 'nr', 'itg', 'imnz', 'irmnp', 'iirnb', 'icrxn', 'tihn', 'evirn', 'uirkn', 'igns', 'hfrn', 'irany', 'url', 'iorq', 'mhirn', 'isrq', 'grzn', 'irwun', 'oirgn', 'hiwn', 'zrnk', 'wird', 'isrz', 'ixnx', 'ifrs', 'ihrm', 'sre', 'biryn', 'xcirn', 'tcn', 'vnn', 'irnol', 'iqrm', 'irdna', 'wnrn', 'oirh', 'vsn', 'en', 'igcrn', 'eirz', 'ywirn', 'isirn', 'igf', 'irain', 'eirt', 'bre', 'irgb', 'ictn', 'igni', 'ilna', 'irman', 'irpmn', 'niwn', 'yirj', 'imc', 'iark', 'krv', 'tirp', 'irspn', 'fro', 'cijn', 'irxnn', 'arr', 'kizn', 'irtnf', 'idan', 'irkk', 'brg', 'mrq', 'imrnj', 'zirl', 'irtmn', 'liwrn', 'ijrhn', 'xvn', 'irrnd', 'itbrn', 'iroz', 'jrnh', 'pre', 'crnz', 'niurn', 'iukrn', 'ijrg', 'ifrk', 'fin', 'iqrnt', 'prtn', 'rrq', 'bzirn', 'iqrz', 'imnv', 'rird', 'iqf', 'irnmy', 'iurnt', 'irmni', 'jirnd', 'swrn', 'icrg', 'myirn', 'mirkn', 'iyrj', 'nirni', 'oirsn', 'irkin', 'iqra', 'inre', 'uirg', 'irnmd', 'birq', 'oirfn', 'girx', 'airn', 'sijn', 'vlrn', 'finn', 'inwrn', 'isrs', 'rirun', 'arl', 'ifq', 'itro', 'ikre', 'yirm', 'oirxn', 'ivno', 'irzy', 'frirn', 'ptrn', 'trsn', 'mrnr', 'pkirn', 'iwc', 'iybrn', 'irrvn', 'ikz', 'kern', 'cwirn', 'irnxq', 'hhn', 'hidn', 'vinn', 'frbn', 'sirnk', 'pjirn', 'vrnc', 'irlq', 'iynm', 'xihrn', 'iroe', 'gin', 'ivpn', 'tfirn', 'irkjn', 'wirmn', 'irnrc', 'irwx', 'yon', 'jra', 'riern', 'jan', 'airan', 'iul', 'irha', 'iricn', 'irpv', 'cryn', 'nen', 'irnib', 'irfy', 'jcirn', 'iyjn', 'len', 'iji', 'ierfn', 'irwp', 'mivrn', 'rk', 'irmnu', 'cirr', 'jirqn', 'ijbn', 'ilvrn', 'kirn', 'iwa', 'izsrn', 'gfrn', 'erwn', 'crng', 'kln', 'gan', 'tirnq', 'ierne', 'isrf', 'rm', 'irnuo', 'irvv', 'bhn', 'lirnk', 'zdn', 'iqran', 'iken', 'irnfz', 'ndrn', 'lmn', 'birnr', 'irnoo', 'trnk', 'grqn', 'ivrs', 'ievn', 'irvnf', 'pifrn', 'mqrn', 'firnn', 'ivrvn', 'rc', 'ihren', 'bzrn', 'iwrln', 'uicn', 'iurin', 'innd', 'irjtn', 'gfirn', 'srq', 'ilsn', 'nzn', 'irdn', 'qisrn', 'qyrn', 'irkdn', 'iirkn', 'ignu', 'rini', 'kn', 'ihgrn', 'irnhe', 'airnw', 'rirvn', 'niry', 'aisn', 'irind', 'itrna', 'ivq', 'wrnq', 'irsnk', 'ibnx', 'qrny', 'lrun', 'irein', 'izkrn', 'irhr', 'anrn', 'ilrzn', 'arw', 'rirm', 'qcirn', 'jyrn', 'qirw', 'iwzn', 'xizrn', 'xrf', 'obirn', 'iery', 'idqrn', 'lirxn', 'ccrn', 'zran', 'qirbn', 'slrn', 'ero', 'ruirn', 'ydirn', 'riru', 'icqn', 'iirnk', 'fsn', 'bire', 'yirpn', 'xjrn', 'ibnu', 'hyn', 'acn', 'qirnx', 'irnlu', 'mmn', 'zirin', 'irqyn', 'irep', 'iyrwn', 'idrdn', 'irnrx', 'irznp', 'irke', 'drny', 'trw', 'irit', 'irnil', 'isfn', 'ibfrn', 'iprnv', 'irncs', 'rirfn', 'sirne', 'lirnl', 'alirn', 'irhrn', 'irgs', 'ila', 'jirxn', 'ivrp', 'ykirn', 'hrh', 'vmirn', 'psn', 'irms', 'iiran', 'uwn', 'rirnz', 'irinh', 'kirln', 'xon', 'irnri', 'iznn', 'ihyn', 'ohn', 'iarcn', 'rrl', 'hqn', 'gmn', 'ifren', 'qrnj', 'irnxk', 'irnwl', 'ioc', 'iwrs', 'prw', 'isry', 'inrfn', 'mihn', 'virna', 'jiqn', 'girk', 'uiyn', 'icrt', 'zizrn', 'ihm', 'ienk', 'jbn', 'ihnd', 'ornz', 'fzrn', 'mivn', 'irubn', 'irjnh', 'urd', 'lrnh', 'yibrn', 'arni', 'iyrq', 'iryt', 'ipjn', 'ivrl', 'ivrne', 'hgirn', 'ihtrn', 'rrbn', 'ailrn', 'dvn', 'ikran', 'ibnk', 'ndirn', 'irinv', 'imryn', 'irmen', 'ibrfn', 'irncg', 'ijnw', 'urnf', 'zirno', 'ixrnd', 'bimrn', 'iyhn', 'idnz', 'inmr', 'iirn', 'sirv', 'idu', 'qirnh', 'ihbn', 'uirv', 'vron', 'irfnk', 'irzx', 'uirpn', 'irmpn', 'oirng', 'icmrn', 'iuq', 'prnw', 'iunv', 'sun', 'rrxn', 'divn', 'ifron', 'mirnw', 'mirnx', 'irznq', 'irjf', 'crd', 'iqqn', 'cirw', 'ceirn', 'idwn', 'itrmn', 'irnsl', 'iknc', 'irndo', 'iprun', 'tiran', 'iony', 'ors', 'isd', 'icyrn', 'icrcn', 'yrnj', 'aiin', 'issrn', 'ixrhn', 'ifnz', 'rigrn', 'irvnu', 'ppn', 'ldirn', 'iurnu', 'aiun', 'tirrn', 'ivzrn', 'lrz', 'xpirn', 'nrnh', 'ilarn', 'karn', 'nirzn', 'nrpn', 'srnj', 'iirb', 'irsnz', 'ikrno', 'birfn', 'irhno', 'mimn', 'picn', 'fnirn', 'ikren', 'vqrn', 'rina', 'dizrn', 'ihd', 'mrin', 'rx', 'drrn', 'izvrn', 'krun', 'zan', 'irnsv', 'crna', 'ifqrn', 'mren', 'vorn', 'rian', 'oirnm', 'xirnq', 'nxrn', 'zrin', 'ia', 'itrng', 'irohn', 'iqrnp', 'ainr', 'elirn', 'iruny', 'nifrn', 'iut', 'ary', 'zrwn', 'fru', 'sdirn', 'ibkrn', 'dirt', 'crbn', 'irmns', 'brnb', 'brn', 'cirnr', 'ioin', 'eirr', 'iripn', 'idmn', 'nbn', 'xoirn', 'rirnm', 'pikrn', 'iqnt', 'iypn', 'vijrn', 'irgnp', 'hiprn', 'xrbn', 'ozrn', 'krpn', 'iqrin', 'pihrn', 'ijrgn', 'ibrnd', 'isrpn', 'irong', 'iorny', 'iql', 'rirzn', 'qijn', 'igrni', 'itcn', 'argn', 'kirnt', 'nryn', 'ijnx', 'iurni', 'umirn', 'prna', 'iari', 'virq', 'irnzp', 'imng', 'ilz', 'tiren', 'ihnt', 'r', 'imrnq', 'ircpn', 'tirna', 'drk', 'irnjv', 'ircn', 'ieirn', 'iknu', 'qibrn', 'irgno', 'iknm', 'bri', 'irlfn', 'iibn', 'ifnc', 'iugn', 'ixin', 'wen', 'idzn', 'izrsn', 'tsrn', 'sirnf', 'iadn', 'iprny', 'hrny', 'lrwn', 'irkun', 'irjnr', 'inna', 'krd', 'kisn', 'jrgn', 'uiron', 'ifrxn', 'irkvn', 'iwrqn', 'sirr', 'cnr', 'crfn', 'wwrn', 'sirmn', 'pirnf', 'iabrn', 'ianm', 'vro', 'lrvn', 'iyo', 'iornz', 'irnfa', 'pirl', 'iyra', 'cisrn', 'iiin', 'irnlv', 'sirwn', 'iarsn', 'pirnv', 'irnwe', 'eiqn', 'yrun', 'wrnc', 'rqin', 'ickn', 'jirnt', 'nrnl', 'irrnc', 'isrv', 'irtu', 'imrgn', 'iunw', 'mfirn', 'iobn', 'orj', 'ilron', 'irhnw', 'izhn', 'irpnu', 'tibn', 'xrnk', 'iarln', 'srno', 'irtng', 'pzrn', 'ioprn', 'xrr', 'bbirn', 'sfirn', 'riirn', 'pri', 'irmx', 'riryn', 'orr', 'igrnh', 'irvnd', 'irsin', 'libn', 'inur', 'nirc', 'aijn', 'ircm', 'erm', 'irdu', 'nrn', 'ixrnc', 'itnp', 'airin', 'axirn', 'iknt', 'ticrn', 'uprn', 'ika', 'irhon', 'iodn', 'difrn', 'idrk', 'riurn', 'ixyn', 'idx', 'qdn', 'irnmq', 'pirnk', 'ibrhn', 'arwn', 'ijw', 'irdwn', 'ixrnb', 'wairn', 'isrp', 'lisn', 'jrp', 'nrnp', 'cra', 'ore', 'iorz', 'vibn', 'irpen', 'cirf', 'iznw', 'izrnp', 'liru', 'trk', 'ciry', 'ciern', 'wrs', 'girp', 'iem', 'ircnw', 'irfln', 'prhn', 'ihrnp', 'anirn', 'xrnu', 'icro', 'irfe', 'crwn', 'jrcn', 'prk', 'aixn', 'irbpn', 'uwrn', 'ijrr', 'girni', 'iqrnj', 'irnko', 'diru', 'miprn', 'ibrnp', 'irnos', 'icrf', 'ukirn', 'zirnd', 'ygrn', 'irnbt', 'irzen', 'irynd', 'iqrne', 'ura', 'imna', 'firz', 'wjn', 'brnx', 'prnu', 'yirun', 'idl', 'zrf', 'irknf', 'irld', 'irez', 'oirnz', 'irls', 'kicrn', 'iubrn', 'iurxn', 'wirnh', 'uirk', 'pfn', 'irrin', 'ivyrn', 'cixrn', 'oairn', 'ircj', 'brmn', 'bivn', 'igrz', 'qmrn', 'ihln', 'zirnw', 'ihrnf', 'nrp', 'ihrpn', 'ixrpn', 'lrfn', 'iak', 'eiryn', 'ean', 'srny', 'eirfn', 'hrw', 'prnp', 'izre', 'irdi', 'uxrn', 'ilw', 'niyrn', 'kirnj', 'irndb', 'mmrn', 'rbrn', 'imfrn', 'minn', 'prnc', 'idnh', 'viarn', 'irtt', 'frg', 'ovirn', 'ierun', 'irjg', 'itnw', 'oirz', 'irbnr', 'gsirn', 'zirnl', 'gign', 'kirnz', 'drnm', 'lre', 'izrny', 'irfv', 'igri', 'irfnl', 'irje', 'oirvn', 'imdn', 'iuna', 'iwrnr', 'irka', 'sren', 'virnu', 'morn', 'ianv', 'iunf', 'ftrn', 'irnju', 'irdln', 'jibrn', 'hrnr', 'dprn', 'jiren', 'oirv', 'birf', 'ijrln', 'suirn', 'zron', 'irwq', 'ibqn', 'iiln', 'igkn', 'ipzn', 'ckn', 'pgn', 'licn', 'yrxn', 'qran', 'ierno', 'pdn', 'idyrn', 'irgnr', 'itrcn', 'ririn', 'bifrn', 'idrf', 'jun', 'fird', 'irjz', 'hirj', 'enn', 'igz', 'qirhn', 'ilg', 'iurb', 'indr', 'iacn', 'yiun', 'krna', 'kqirn', 'trns', 'dirf', 'zirnf', 'grxn', 'rirt', 'kipn', 'irntp', 'trin', 'hivrn', 'irosn', 'prnx', 'gmirn', 'brrn', 'kairn', 'vdrn', 'ijarn', 'girm', 'finrn', 'imrv', 'zrv', 'ucirn', 'xrrn', 'ilrni', 'lirs', 'xurn', 'airvn', 'piarn', 'lrzn', 'xiprn', 'irqna', 'igurn', 'prirn', 'yarn', 'irtw', 'irenb', 'pirdn', 'irm', 'iym', 'irynb', 'ircr', 'kbirn', 'icyn', 'grm', 'ven', 'iwern', 'inrnz', 'iirgn', 'tirb', 'izwn', 'hrq', 'binn', 'irnsr', 'ixnl', 'hlrn', 'girv', 'iwnz', 'sihrn', 'niirn', 'uxirn', 'yilrn', 'rirnr', 'dhrn', 'qirgn', 'i', 'igre', 'crnv', 'itrr', 'irex', 'isrnq', 'iranu', 'izrx', 'iwnv', 'ihrt', 'iau', 'irxnx', 'riprn', 'uro', 'ijns', 'irom', 'riry', 'oiwn', 'irjun', 'zrsn', 'irwrn', 'cirnn', 'ptirn', 'irgnk', 'irwnp', 'sijrn', 'ivon', 'rwirn', 'iero', 'sirpn', 'iwmrn', 'irce', 'vizrn', 'rrnz', 'iif', 'irmzn', 'iucrn', 'skrn', 'hirnd', 'irank', 'irnvp', 'oion', 'ymn', 'qirni', 'frr', 'zrns', 'iia', 'iqnc', 'hmn', 'krl', 'irjh', 'dikrn', 'krw', 'ilrnd', 'izyn', 'mnr', 'airnt', 'hhrn', 'irncm', 'yen', 'diqn', 'irlx', 'vicrn', 'rf', 'wigrn', 'qirin', 'irse', 'irkxn', 'itrs', 'itsn', 'niun', 'hirno', 'rimn', 'zrfn', 'lirnh', 'diarn', 'iurx', 'vrrn', 'irnzt', 'idru', 'irnep', 'isni', 'srwn', 'puirn', 'irnrf', 'imgn', 'iurf', 'rirnh', 'inarn', 'irgj', 'irz', 'carn', 'zien', 'ibarn', 'itnm', 'isk', 'ehn', 'irisn', 'arvn', 'iind', 'isrnd', 'ribrn', 'qrhn', 'irdg', 'irnhh', 'stirn', 'krfn', 'utrn', 'imj', 'ianb', 'isnr', 'igna', 'iehn', 'iqj', 'ixfrn', 'birnj', 'imri', 'iwqn', 'eirvn', 'xbrn', 'imnh', 'ierwn', 'mirmn', 'jsirn', 'iqns', 'ornl', 'srnb', 'ln', 'airp', 'irau', 'igln', 'kirs', 'iryun', 'iksn', 'sro', 'irnnu', 'irmnk', 'wiri', 'irntc', 'cirni', 'irri', 'iua', 'lilrn', 'gidn', 'grl', 'ircnq', 'bdrn', 'ixgn', 'hrcn', 'iinq', 'virh', 'innrn', 'iczn', 'ifrnq', 'ixlrn', 'mbirn', 'qiron', 'iynb', 'inl', 'iuirn', 'oitrn', 'htirn', 'innm', 'ivrk', 'rij', 'icrnq', 'izorn', 'rint', 'irynf', 'irqwn', 'iqprn', 'igrf', 'irtm', 'qirln', 'irah', 'irnlb', 'iirdn', 'iwrk', 'irnit', 'irh', 'ibirn', 'irjm', 'rinq', 'oirmn', 'firy', 'dra', 'zeirn', 'irnhu', 'tarn', 'virg', 'ziru', 'girnp', 'iorv', 'icny', 'men', 'aran', 'iarl', 'firj', 'uan', 'jrqn', 'ikra', 'ixrdn', 'irwnu', 'iirun', 'inrvn', 'brnm', 'iorr', 'rein', 'ivhrn', 'kihn', 'icrnv', 'izrnl', 'qrdn', 'efirn', 'grnp', 'ilm', 'pren', 'mlirn', 'grk', 'hirr', 'isc', 'tirmn', 'iws', 'zrk', 'kren', 'ciorn', 'nitrn', 'irnim', 'iryj', 'jen', 'ifrqn', 'pvrn', 'idrnv', 'itru', 'bikrn', 'iunu', 'irnwf', 'itrns', 'nizrn', 'icrl', 'ivnk', 'imx', 'igrny', 'tgirn', 'ibr', 'ircnj', 'irch', 'irnyh', 'jirnv', 'dirbn', 'irrx', 'irlu', 'mirsn', 'izirn', 'virnm', 'irub', 'iqmn', 'nirnx', 'firqn', 'idron', 'irned', 'rrfn', 'irya', 'ics', 'irvwn', 'iurh', 'qrln', 'zrl', 'irva', 'iarh', 'kirh', 'irkl', 'irynw', 'iradn', 'ihrbn', 'ris', 'iryc', 'irpna', 'ubrn', 'siwrn', 'ismn', 'ioi', 'irby', 'iwl', 'mcrn', 'jnr', 'iqrc', 'iirnx', 'rilrn', 'mran', 'yeirn', 'iord', 'ifkn', 'iaon', 'ijon', 'rrjn', 'irndy', 'wikn', 'lion', 'cirq', 'sifrn', 'ihrna', 'irdqn', 'yrfn', 'iurnw', 'uiryn', 'wrun', 'ikrp', 'irndw', 'hsn', 'hen', 'mdn', 'irnml', 'urnc', 'fran', 'iiz', 'irdb', 'iryvn', 'xrni', 'erni', 'iznb', 'gihrn', 'ivvrn', 'yiry', 'mxrn', 'irhne', 'iph', 'ihbrn', 'vire', 'mirnk', 'birng', 'irfng', 'irnwc', 'akirn', 'ibj', 'ann', 'zqn', 'crmn', 'rrb', 'ifurn', 'nkirn', 'gpirn', 'qinr', 'jirhn', 'iw', 'iaw', 'aeirn', 'brnr', 'fircn', 'hicn', 'lirnt', 'srp', 'hirjn', 'uiro', 'ciarn', 'irdnd', 'iarnu', 'ficrn', 'vrgn', 'crno', 'qrnk', 'yrnx', 'liqn', 'idyn', 'ife', 'siun', 'hirn', 'iqrfn', 'yirnn', 'cru', 'zqrn', 'idy', 'ihcn', 'iwvn', 'lrq', 'vkn', 'hrpn', 'ixan', 'kiprn', 'iyd', 'ixrt', 'tirn', 'ibm', 'iruni', 'wirg', 'irsnt', 'pign', 'idrg', 'iiw', 'ijrnv', 'isnm', 'ivnr', 'dryn', 'nirnf', 'ikrqn', 'bilrn', 'irnpr', 'pirne', 'ictrn', 'irlm', 'inrzn', 'iwcrn', 'imen', 'iuw', 'fan', 'ikrx', 'ivcrn', 'dibrn', 'wirqn', 'iptrn', 'zbirn', 'ioren', 'iarnf', 'fisn', 'irinr', 'irkt', 'jin', 'iirq', 'igsrn', 'uigrn', 'igrgn', 'hrr', 'tgrn', 'irbn', 'iznt', 'ixk', 'birnq', 'iwna', 'urfn', 'ikrna', 'iirpn', 'ionrn', 'iknz', 'yisn', 'irik', 'iqrni', 'wrnj', 'irpnq', 'ioqn', 'vifrn', 'tin', 'irxnl', 'fizrn', 'iahn', 'xern', 'ogrn', 'ieo', 'zircn', 'tirnj', 'iisrn', 'txrn', 'nirl', 'ghrn', 'yiri', 'ibrbn', 'cxirn', 'iqhrn', 'rik', 'vwn', 'izsn', 'urnr', 'ihrnq', 'iyrnw', 'jyirn', 'gipn', 'grirn', 'ibz', 'lirnv', 'xbn', 'iwrr', 'nrrn', 'iyrh', 'vrnk', 'iroi', 'giren', 'dre', 'wfrn', 'kirnb', 'ibv', 'tiqn', 'mrns', 'iomn', 'iysrn', 'pry', 'lgirn', 'fbrn', 'itrqn', 'ifdn', 'iorzn', 'irvj', 'uiprn', 'lirk', 'sirhn', 'uirp', 'giqn', 'frln', 'inrnd', 'irvng', 'iirna', 'zrn', 'iwrrn', 'frnj', 'tiri', 'iprtn', 'miqrn', 'uirtn', 'qri', 'yrnh', 'hry', 'ibrsn', 'nrz', 'irneq', 'prns', 'prnz', 'aicrn', 'qn', 'imt', 'irxp', 'vzn', 'ixy', 'brln', 'fln', 'ifnj', 'uren', 'iirni', 'ikrfn', 'irnwp', 'isf', 'eirnc', 'iinh', 'igrnc', 'vrf', 'einrn', 'irnkv', 'ieqrn', 'irnjt', 'firns', 'zgrn', 'zirnh', 'irqr', 'nion', 'mirnm', 'irnan', 'airnj', 'isj', 'xirno', 'irjjn', 'giirn', 'isnz', 'uirz', 'krin', 'irond', 'uiren', 'ivirn', 'kun', 'wrln', 'jrln', 'irbc', 'dtirn', 'irntb', 'hirf', 'yirnq', 'irjzn', 'irvy', 'ivo', 'crnk', 'nsirn', 'virw', 'bisrn', 'nibrn', 'irdon', 'rkn', 'ircln', 'iwyn', 'eizn', 'gyirn', 'irrrn', 'mcirn', 'icrnc', 'bpn', 'rwrn', 'iyrbn', 'ito', 'ihrwn', 'ijre', 'mkrn', 'iemn', 'irvnc', 'immrn', 'nrgn', 'oirw', 'wrng', 'didn', 'vivrn', 'irdne', 'iprc', 'sirnm', 'vigrn', 'izgrn', 'wrw', 'irgkn', 'dimrn', 'linrn', 'qixrn', 'irymn', 'qirng', 'tirm', 'ipwrn', 'jrt', 'stn', 'irxtn', 'pirln', 'iyrc', 'grz', 'hrnp', 'zixrn', 'riran', 'irwjn', 'titn', 'wirw', 'frnf', 'iyny', 'izrf', 'ivnf', 'iwra', 'irux', 'afirn', 'iroxn', 'izan', 'eimrn', 'grns', 'irnaq', 'icmn', 'hijn', 'xisrn', 'brq', 'ijrt', 'irion', 'jiqrn', 'uirnd', 'br', 'brb', 'ircng', 'lxirn', 'ipqrn', 'vion', 'ijxrn', 'irpnw', 'hqirn', 'grv', 'iraqn', 'eirnl', 'rrw', 'qinn', 'filn', 'aiprn', 'eirni', 'ixrne', 'kicn', 'wrnx', 'xiun', 'irnnm', 'ivin', 'tprn', 'qun', 'iqwrn', 'iorm', 'irgnj', 'ihf', 'ibvrn', 'yirjn', 'qbn', 'rrg', 'ijrnh', 'iryno', 'siarn', 'iqnf', 'qircn', 'ifrnm', 'cyn', 'ierhn', 'arnd', 'trvn', 'lirnr', 'eiurn', 'lrrn', 'itv', 'irznz', 'itrm', 'isx', 'irntg', 'prp', 'trnb', 'wiren', 'snirn', 'idrng', 'kran', 'urtn', 'yjn', 'ignn', 'iwnk', 'irgvn', 'trun', 'iurt', 'icern', 'irnkw', 'krkn', 'irden', 'iprnh', 'iwsrn', 'imon', 'wmn', 'gidrn', 'vird', 'ignf', 'nrh', 'kkn', 'mirnv', 'tun', 'uifrn', 'wrp', 'ifrnp', 'irlnj', 'itrpn', 'icna', 'iwzrn', 'irnfb', 'itrnv', 'ric', 'ibin', 'iend', 'prl', 'ysirn', 'fiun', 'ifrf', 'irnxx', 'qirnj', 'irknc', 'irgwn', 'ijjn', 'qtn', 'inx', 'iyrnb', 'lrf', 'avrn', 'frxn', 'irekn', 'yrs', 'iern', 'myn', 'grn', 'fiorn', 'iffn', 'iknq', 'yirnd', 'ikrnk', 'irzw', 'irznb', 'uirqn', 'jrtn', 'hidrn', 'irrtn', 'irswn', 'iurne', 'irncc', 'irnki', 'ith', 'wiprn', 'ierrn', 'ita', 'qarn', 'irunj', 'birxn', 'irod', 'lin', 'iis', 'bro', 'mirnn', 'nrs', 'ziron', 'oicrn', 'irky', 'ipryn', 'urirn', 'pirp', 'igryn', 'iiryn', 'ixj', 'qkn', 'ibnh', 'innr', 'mrzn', 'bron', 'sbirn', 'ijne', 'zirln', 'wilrn', 'irbg', 'lifn', 'zitn', 'krnf', 'idnb', 'irao', 'qrtn', 'cirh', 'ycrn', 'trnh', 'itx', 'atirn', 'rinc', 'imrnk', 'yrno', 'hryn', 'ivrn', 'iwrsn', 'irjwn', 'igt', 'iku', 'iarnv', 'isrln', 'hre', 'irdc', 'ihgn', 'xitn', 'idrnc', 'nirg', 'ivrg', 'lpirn', 'tizrn', 'rrmn', 'zign', 'kirno', 'irot', 'zdirn', 'dirgn', 'tiurn', 'crrn', 'wire', 'irnsy', 'mirjn', 'szrn', 'jixn', 'orvn', 'airnp', 'qlirn', 'mcn', 'ibmn', 'im', 'iu', 'ilrnh', 'irjl', 'irpin', 'irgn', 'unn', 'imz', 'xiurn', 'irmtn', 'imni', 'ivrnx', 'jrnw', 'xorn', 'iaun', 'ilrj', 'ihrln', 'rgirn', 'irvg', 'ipgn', 'irbny', 'xzirn', 'arjn', 'zrnq', 'ijdrn', 'irqe', 'yirq', 'icvn', 'iurpn', 'iono', 'id', 'frzn', 'srnc', 'yiro', 'ihnp', 'ixrj', 'kijn', 'bijrn', 'vxn', 'winr', 'ecrn', 'siru', 'ijrz', 'sxirn', 'xirne', 'sirk', 'igyrn', 'iirzn', 'ikv', 'lidn', 'ihnx', 'iarng', 'ijnk', 'odirn', 'wion', 'icw', 'irjo', 'ifhrn', 'izrns', 'irizn', 'irenm', 'dihn', 'irgv', 'ilin', 'ghn', 'kirhn', 'ijron', 'ixc', 'jhn', 'issn', 'iorbn', 'ijin', 'ireh', 'iyrs', 'irlh', 'iwd', 'prv', 'irnus', 'girsn', 'firo', 'jirdn', 'hrgn', 'irncq', 'icn', 'tixrn', 'gifrn', 'irmnm', 'irsln', 'himrn', 'qirn', 'inrns', 'jrkn', 'miwn', 'pbirn', 'xrnx', 'mirtn', 'virns', 'uvrn', 'ixrfn', 'jrny', 'ignm', 'ixnw', 'vipn', 'rnn', 'iknx', 'yrpn', 'isrnl', 'ilrjn', 'iynd', 'fbn', 'irrb', 'rira', 'obn', 'krz', 'itrc', 'krnj', 'aivn', 'oon', 'tirin', 'girng', 'iknh', 'nirnz', 'irja', 'ibrg', 'firna', 'aian', 'yirc', 'nrzn', 'ilyn', 'eirnv', 'aoirn', 'ilrn', 'iurnq', 'pan', 'irnwv', 'nirnm', 'lsn', 'pirny', 'jrfn', 'igqn', 'den', 'idw', 'irge', 'drf', 'ibnz', 'yrnw', 'iprnn', 'fikn', 'ihnq', 'iarna', 'virfn', 'irqnt', 'ipnx', 'grfn', 'inzrn', 'yoirn', 'itc', 'bitn', 'rnf', 'igd', 'difn', 'xiarn', 'brnu', 'wirng', 'cirwn', 'iit', 'iprbn', 'wiin', 'iornt', 'isz', 'nidn', 'hirwn', 'ionm', 'impn', 'irgnu', 'bern', 'trq', 'ioa', 'iyrnj', 'tirl', 'hrnq', 'iinv', 'dry', 'iyrt', 'irune', 'aihrn', 'lnrn', 'icv', 'veirn', 'nirb', 'wian', 'irus', 'icryn', 'irnnj', 'vixrn', 'uiru', 'diorn', 'cirqn', 'irnov', 'arnp', 'iharn', 'uirn', 'idz', 'uirb', 'iuh', 'mtn', 'iwnx', 'ibsrn', 'ciqrn', 'irzo', 'uidn', 'kinn', 'virf', 'irjv', 'iulrn', 'iyt', 'sirx', 'rl', 'pirnr', 'igwrn', 'ivrh', 'tkirn', 'dirq', 'imrnz', 'mirx', 'iogrn', 'vvrn', 'frw', 'kirnm', 'srnz', 'ihrnd', 'esirn', 'izf', 'arnw', 'irian', 'lrnu', 'yrns', 'yirb', 'ptn', 'uisn', 'ijrnn', 'qwn', 'idno', 'iyrf', 'ircb', 'ufrn', 'eirnj', 'iarkn', 'irnvs', 'gren', 'lirnm', 'vrirn', 'ikrz', 'iryin', 'isrng', 'org', 'loirn', 'idrx', 'btirn', 'wirb', 'xirni', 'nisrn', 'irar', 'isrgn', 'iry', 'xirm', 'hrnu', 'zrj', 'uirnn', 'iprv', 'lirmn', 'ixrm', 'iarwn', 'drz', 'eiry', 'irvk', 'xiro', 'irxne', 'iorh', 'crvn', 'icrh', 'irbrn', 'ctirn', 'bibn', 'ixcrn', 'piran', 'airnh', 'uon', 'qirm', 'sirin', 'irnxj', 'itren', 'mtirn', 'itirn', 'ireln', 'irunn', 'erl', 'iwmn', 'iar', 'oikrn', 'irk', 'vwrn', 'irnua', 'girz', 'rijrn', 'ernr', 'iddn', 'aizn', 'uirrn', 'irnli', 'rirj', 'yrb', 'irzne', 'irgbn', 'xtn', 'ivu', 'jirtn', 'ixnd', 'rdrn', 'pirno', 'airb', 'irwyn', 'irst', 'inrnx', 'irfsn', 'zirnr', 'srnn', 'dirn', 'irfnj', 'iqrnc', 'iine', 'jlrn', 'jiun', 'iria', 'irme', 'qrnt', 'ilmn', 'urno', 'irnwx', 'run', 'ipdn', 'itrp', 'inm', 'ieng', 'irnxo', 'irpe', 'hikn', 'ouirn', 'likrn', 'irx', 'eirne', 'idrj', 'zri', 'asrn', 'iqrw', 'yivrn', 'iprfn', 'krq', 'imru', 'inirn', 'iorrn', 'jrg', 'crin', 'iyrd', 'iarmn', 'iref', 'uirnb', 'wru', 'jrxn', 'nirnn', 'mru', 'yirp', 'ihun', 'inkn', 'ikrjn', 'ient', 'jiern', 'xrq', 'prnb', 'iors', 'zdrn', 'iyarn', 'inns', 'jjn', 'firr', 'mian', 'iep', 'wkirn', 'irknr', 'cirm', 'virnr', 'biarn', 'ircrn', 'zivrn', 'kirnw', 'irxln', 'iinc', 'hrnv', 'ibqrn', 'cirvn', 'giorn', 'ikrnn', 'firh', 'irgnt', 'grg', 'ijl', 'vkirn', 'irnhi', 'ijrx', 'arq', 'izrh', 'inrv', 'ifrne', 'min', 'irnqu', 'virun', 'iien', 'ernh', 'iordn', 'isrnv', 'buirn', 'igron', 'biin', 'irpnt', 'girne', 'nirin', 'ibrm', 'ipran', 'ikrn', 'won', 'iohn', 'iorhn', 'irnja', 'bcrn', 'rcin', 'ikdrn', 'iysn', 'wrc', 'uiqn', 'ivrt', 'igr', 'grmn', 'oirnw', 'imrng', 'ivne', 'irunm', 'wron', 'idxn', 'icrp', 'ikrwn', 'ikmrn', 'pirm', 'irwnn', 'girno', 'ivrc', 'vixn', 'miun', 'irksn', 'wfirn', 'khn', 'irmun', 'isryn', 'igrbn', 'iynj', 'girdn', 'rirnw', 'lirsn', 'idrnu', 'ice', 'dorn', 'iwz', 'xsirn', 'lrnx', 'wzn', 'idnj', 'xprn', 'wrnh', 'irvq', 'zvrn', 'dirln', 'qirg', 'riyn', 'vrs', 'xmn', 'iryz', 'oiqrn', 'igrl', 'wdrn', 'iby', 'fvrn', 'ilnf', 'wrpn', 'kirx', 'irrn', 'idrnh', 'hcrn', 'ingn', 'hxirn', 'iurtn', 'drh', 'iriv', 'bnirn', 'xrns', 'irsnn', 'pnn', 'irng', 'ijrvn', 'irmw', 'iprkn', 'pirgn', 'yirln', 'nirkn', 'wrnn', 'inan', 'wijrn', 'irnqs', 'iuprn', 'ibrna', 'irho', 'kirnq', 'irxnt', 'izl', 'cirun', 'irfxn', 'oir', 'brc', 'iqgrn', 'ergn', 'iqnr', 'srl', 'rirnx', 'wirf', 'irnop', 'fdn', 'diryn', 'uirna', 'ibbn', 'iknj', 'irqn', 'imrnf', 'zrm', 'ikf', 'irwzn', 'izrxn', 'pirnh', 'imln', 'ciren', 'irnpl', 'giri', 'iirmn', 'izrnx', 'idj', 'rrnt', 'son', 'uqirn', 'srnk', 'trnd', 'irecn', 'ids', 'pfrn', 'kqn', 'ini', 'nrc', 'ilkrn', 'irre', 'imrcn', 'iag', 'ibd', 'ivrqn', 'oirf', 'birk', 'irpi', 'cin', 'srln', 'uirng', 'wrjn', 'ibrjn', 'irbv', 'urhn', 'zrqn', 'irgun', 'wirk', 'ihna', 'uirnz', 'ikno', 'vvn', 'rirnj', 'yrhn', 'crnq', 'njrn', 'ziryn', 'irnqf', 'idjrn', 'hiry', 'irnif', 'irrdn', 'orns', 'ernz', 'mln', 'tiry', 'iro', 'itrzn', 'jgirn', 'irjnn', 'iorin', 'virjn', 'iqb', 'imne', 'ilpn', 'zcirn', 'giprn', 'ihrd', 'wirdn', 'ytirn', 'miin', 'xiry', 'irta', 'ars', 'irgnh', 'eir', 'irxa', 'irmng', 'arnc', 'iqnp', 'hizrn', 'imk', 'lign', 'iridn', 'ibln', 'iruq', 'ironl', 'dvrn', 'firnx', 'iwrpn', 'irnbr', 'ieen', 'iven', 'idrnl', 'itrn', 'ymirn', 'iins', 'airw', 'irwcn', 'ignb', 'inrwn', 'xpn', 'zirpn', 'izrn', 'jzrn', 'ifg', 'ireo', 'iamrn', 'ircnn', 'iarz', 'ichn', 'imrne', 'uhn', 'irnpx', 'igarn', 'mrnc', 'trnc', 'irnqh', 'irnrj', 'iart', 'rind', 'mrno', 'prj', 'dtn', 'mjrn', 'idhrn', 'mirxn', 'gcirn', 'iranz', 'zirun', 'irxk', 'kbn', 'zinr', 'iyro', 'iufrn', 'isrh', 'ypirn', 'iurbn', 'xeirn', 'erpn', 'tirg', 'ukrn', 'trnt', 'wiru', 'ianz', 'innp', 'irnvg', 'iqin', 'prjn', 'irqg', 'orm', 'ilan', 'iurc', 'qrnm', 'hirns', 'oixn', 'irncl', 'teirn', 'brm', 'uisrn', 'irif', 'irmn', 'idrfn', 'zmirn', 'dkn', 'girt', 'bipn', 'krln', 'ifj', 'flirn', 'lizn', 'ilnz', 'ivrnu', 'iers', 'itjn', 'gire', 'ixrg', 'vtrn', 'iuxrn', 'iranr', 'ivrm', 'iqorn', 'irlgn', 'irpnc', 'ktirn', 'iewn', 'ikry', 'czn', 'xirin', 'irsf', 'iwm', 'cirpn', 'iynh', 'ircnf', 'pra', 'gmrn', 'rii', 'fwn', 'yrm', 'iwvrn', 'irmnc', 'kifn', 'illn', 'rrna', 'iltrn', 'lipn', 'wsrn', 'irven', 'vizn', 'ixkn', 'uinn', 'irnpt', 'hiln', 'tjrn', 'aln', 'irlnh', 'irqp', 'iunx', 'rkrn', 'hrnm', 'amirn', 'ilrnt', 'pirb', 'irhd', 'wirnp', 'izw', 'itrnt', 'ocrn', 'iwrnq', 'qdrn', 'wisn', 'irmy', 'dien', 'irnfi', 'ijrnd', 'xrtn', 'ipkn', 'ixtrn', 'drno', 'drne', 'ifzrn', 'ioen', 'ihrk', 'irnzg', 'jern', 'idrnm', 'qrnf', 'irnts', 'ilrkn', 'ierl', 'zirnc', 'iprna', 'siprn', 'itm', 'irnbu', 'jrq', 'ivurn', 'orbn', 'filrn', 'rirbn', 'lurn', 'yire', 'izry', 'virnc', 'iwnf', 'iwnu', 'irvn', 'irnia', 'fairn', 'kmrn', 'srcn', 'gizrn', 'nmirn', 'hiun', 'icrng', 'bwn', 'ipn', 'izrpn', 'gwn', 'irten', 'iain', 'ijrwn', 'irac', 'irnob', 'irnly', 'ircnu', 'gigrn', 'tgn', 'ilrc', 'ikrnm', 'oisrn', 'isrnz', 'igg', 'ivran', 'ild', 'irnue', 'isrne', 'mmirn', 'birjn', 'irgo', 'tiern', 'itu', 'jigrn', 'iurnb', 'nirfn', 'nirnt', 'zwrn', 'ivc', 'yran', 'grc', 'ivs', 'ixwrn', 'idrnk', 'iprnt', 'ernn', 'jrpn', 'idmrn', 'irfno', 'miryn', 'liern', 'dirkn', 'iur', 'wro', 'uiyrn', 'ibri', 'iwlrn', 'pyn', 'horn', 'orkn', 'ztirn', 'yinn', 'irnva', 'rzn', 'qrirn', 'dirvn', 'ilv', 'wirnn', 'ieb', 'virnq', 'imrw', 'itkn', 'ziwn', 'irnhw', 'crq', 'fxrn', 'ir', 'rdn', 'wrnd', 'irxnd', 're', 'irnmf', 'sn', 'avn', 'trcn', 'iurgn', 'irnmm', 'irjk', 'ihq', 'eirjn', 'dr', 'krirn', 'xqirn', 'ick', 'irji', 'inrs', 'pbrn', 'mrpn', 'iam', 'ncrn', 'urnm', 'jrun', 'lircn', 'jfirn', 'imrvn', 'cvirn', 'trwn', 'iriun', 'iera', 'ibwrn', 'ie', 'imvn', 'iov', 'yre', 'ios', 'girs', 'ijrqn', 'zrw', 'cizn', 'srhn', 'kihrn', 'cirnh', 'ing', 'ihfn', 'nnn', 'irhbn', 'iyqn', 'igon', 'ifrnt', 'icrnd', 'cirin', 'iiqn', 'kiin', 'urnj', 'aun', 'iknb', 'irntl', 'iayn', 'lidrn', 'irnlc', 'tdn', 'irnxh', 'mirny', 'eirnt', 'irnoh', 'jrng', 'ficn', 'ifrw', 'irfni', 'izri', 'hrn', 'nirnb', 'ionw', 'ierkn', 'irkf', 'yidn', 'iane', 'irnsa', 'yiern', 'imsrn', 'ihon', 'wirtn', 'ifun', 'fidn', 'iwkn', 'nirmn', 'irnwa', 'irntz', 'iian', 'mron', 'iidrn', 'iyrx', 'irbh', 'iymrn', 'iqnb', 'zkrn', 'irfen', 'irkmn', 'iirxn', 'iynr', 'crz', 'ivrf', 'iwprn', 'eirm', 'eirx', 'ikgn', 'cirj', 'iww', 'iuy', 'riron', 'jrno', 'izj', 'ixrnh', 'birni', 'pron', 'iorb', 'circ', 'zirtn', 'urj', 'irfin', 'irnyb', 'sirnc', 'keirn', 'iazn', 'irzhn', 'sgrn', 'irvna', 'lron', 'irniq', 'drr', 'earn', 'dkirn', 'airne', 'firnl', 'irnnz', 'onn', 'irbmn', 'igrnp', 'irrun', 'irku', 'irqsn', 'ornh', 'bvrn', 'ikx', 'ipy', 'irnai', 'ilrtn', 'hinrn', 'irbk', 'hkn', 'iycn', 'ijbrn', 'iraa', 'arnv', 'iywn', 'ihns', 'ixz', 'irfny', 'ivdrn', 'hrc', 'prnm', 'ikrln', 'gnirn', 'rsin', 'jrirn', 'kon', 'zirwn', 'hvrn', 'iqbrn', 'qrnu', 'jivn', 'ykn', 'irnkq', 'bru', 'viqrn', 'srnl', 'idnu', 'jrna', 'bjrn', 'cire', 'ijzn', 'izwrn', 'diyn', 'zirxn', 'izbn', 'ikt', 'irqin', 'ircnt', 'lrhn', 'ienb', 'hirvn', 'yign', 'arqn', 'iyry', 'ib', 'idrnf', 'ilnp', 'yirr', 'irnuj', 'ibru', 'iyrvn', 'infn', 'nrk', 'ioz', 'oirnh', 'iob', 'if', 'qirnu', 'nfn', 'imw', 'hinr', 'sirno', 'icwrn', 'frtn', 'icrdn', 'iqnq', 'ifrnc', 'ihno', 'imwn', 'imrdn', 'wrdn', 'wcn', 'mixn', 'irqh', 'lirl', 'lifrn', 'iflrn', 'wirnk', 'gikn', 'ihrhn', 'yirv', 'iraon', 'krnk', 'iptn', 'xrjn', 'ifnx', 'inrhn', 'iurnh', 'nirnl', 'inqn', 'iumrn', 'iin', 'uirx', 'irqbn', 'misn', 'icjrn', 'prng', 'irntu', 'icrnt', 'qicrn', 'ojrn', 'itrun', 'iwfrn', 'yitrn', 'irtns', 'ricrn', 'irunb', 'irrnz', 'hern', 'fnn', 'airf', 'irnhy', 'givn', 'ikrnj', 'irqt', 'vrj', 'ixarn', 'lirm', 'imrt', 'ije', 'ilnn', 'ifrc', 'irahn', 'hitrn', 'irnms', 'zirk', 'irnad', 'lirwn', 'jiorn', 'crni', 'vrnh', 'zirjn', 'ivrin', 'diren', 'iornm', 'aigrn', 'jitrn', 'irxw', 'krnr', 'irnfr', 'iyr', 'ein', 'irczn', 'xirv', 'iznm', 'ienf', 'iyin', 'pirq', 'isrnb', 'irwkn', 'irnnn', 'irnbs', 'irnwi', 'iub', 'wqrn', 'irznk', 'qirr', 'aern', 'kirqn', 'aiyn', 'koirn', 'hihn', 'oirnx', 'mrl', 'lirnp', 'irnex', 'jir', 'igrrn', 'idm', 'fron', 'irvjn', 'yrne', 'ifrx', 'ixrnz', 'itra', 'idnq', 'zbrn', 'ibron', 'ijcrn', 'kan', 'iernh', 'irrh', 'ztn', 'lrnw', 'irqnm', 'rib', 'irmnx', 'jixrn', 'iprxn', 'irlnl', 'irnhk', 'ittn', 'irvns', 'ipvrn', 'irtkn', 'birvn', 'yrnf', 'airrn', 'zern', 'idn', 'dirfn', 'titrn', 'qru', 'man', 'izqrn', 'lird', 'pilrn', 'ikro', 'rio', 'prnn', 'tisn', 'idrh', 'irnzs', 'wfn', 'ikqn', 'biro', 'imrc', 'icx', 'iwrnj', 'hsirn', 'irqfn', 'xrnh', 'agn', 'mirz', 'ekn', 'ixjrn', 'irxx', 'viren', 'firpn', 'irrwn', 'tirln', 'irxz', 'csn', 'idnc', 'iarp', 'mien', 'frnr', 'iakrn', 'lixrn', 'iunq', 'yrrn', 'oien', 'iwre', 'mrf', 'nran', 'lr', 'wirnb', 'il', 'irtbn', 'lairn', 'jrjn', 'ijun', 'irnp', 'aign', 'izrnh', 'iknr', 'ervn', 'ivqrn', 'ekirn', 'brzn', 'iurk', 'hjrn', 'krjn', 'piru', 'irwg', 'iqrnf', 'ixjn', 'jirpn', 'ircan', 'irjnm', 'irnpy', 'ihqn', 'dqirn', 'irmgn', 'mikn', 'iir', 'qirvn', 'irynk', 'irtan', 'iyun', 'iryen', 'qrnp', 'iyvn', 'kir', 'cqirn', 'irzf', 'iarnb', 'itmrn', 'irwnx', 'ipri', 'iblrn', 'irwnm', 'jvn', 'uizn', 'ijern', 'iornp', 'irrnl', 'wiqn', 'irnxf', 'xdirn', 'brna', 'risn', 'irnqi', 'irajn', 'irfnt', 'yrl', 'turn', 'iraw', 'ibrp', 'biqrn', 'isrnt', 'krrn', 'bien', 'tfrn', 'ken', 'iryxn', 'wirnt', 'irddn', 'ipa', 'irbng', 'ircxn', 'ivp', 'ikru', 'imxrn', 'iropn', 'qirpn', 'irncj', 'dri', 'rrc', 'iranh', 'irjkn', 'irinp', 'eirno', 'irsnh', 'ilrg', 'zinrn', 'imrnc', 'norn', 'ikrnv', 'cnirn', 'ifrt', 'ircqn', 'niern', 'ssn', 'brw', 'ernm', 'emrn', 'oirwn', 'itrnq', 'iruln', 'isnb', 'mrnj', 'tipn', 'firjn', 'irnzu', 'icri', 'nurn', 'grdn', 'lren', 'irqw', 'likn', 'bmn', 'drnf', 'yirfn', 'cizrn', 'tcrn', 'irnau', 'dbirn', 'ixrnn', 'irxny', 'irotn', 'hrzn', 'dion', 'iryon', 'viry', 'ircjn', 'illrn', 'ilni', 'ijq', 'ivrnt', 'vairn', 'ibnw', 'irnjd', 'iqrgn', 'idnn', 'sdn', 'erq', 'ipni', 'ciln', 'dren', 'sirn', 'irnfc', 'lrt', 'iurnk', 'mzirn', 'ooirn', 'rfin', 'tri', 'nrni', 'iermn', 'irfx', 'izrm', 'iryni', 'wirun', 'nirn', 'irpnx', 'nirx', 'dsn', 'ixurn', 'qsn', 'hiran', 'iranx', 'ireon', 'erno', 'igro', 'glirn', 'innf', 'irdpn', 'ikvn', 'nirpn', 'irjb', 'osn', 'zire', 'izrnv', 'irnes', 'tirsn', 'roin', 'isnv', 'iorc', 'ijqn', 'irxxn', 'irsnr', 'irinj', 'brirn', 'irhz', 'irtne', 'vrn', 'yirno', 'eln', 'irdnt', 'sirsn', 'frmn', 'irlp', 'oirg', 'imrp', 'krnq', 'irnuc', 'wrirn', 'iurnr', 'vrna', 'itnz', 'mrn', 'zirnv', 'iryw', 'jxn', 'irgt', 'csirn', 'jrni', 'aifn', 'wixn', 'dian', 'iaurn', 'irugn', 'kjn', 'irgrn', 'irjp', 'irgnc', 'irsne', 'irnyx', 'imno', 'jorn', 'arzn', 'liron', 'uikrn', 'yimrn', 'ihrnl', 'idrd', 'lirzn', 'ipnf', 'rrirn', 'iqr', 'xrno', 'wicrn', 'jian', 'gsrn', 'irqnj', 'rnb', 'hirxn', 'ria', 'irmna', 'zirx', 'mxirn', 'grb', 'arhn', 'idnv', 'rrr', 'biorn', 'lirp', 'irpd', 'crne', 'irnha', 'iqg', 'bgrn', 'ifmn', 'irmnl', 'higrn', 'irts', 'iqre', 'wrxn', 'itfrn', 'vrnf', 'irnyy', 'fnr', 'ijrna', 'cvrn', 'gryn', 'igrnl', 'icnrn', 'dn', 'irrnj', 'iurun', 'iqsn', 'hvn', 'urs', 'iucn', 'irhzn', 'ixnp', 'ivnp', 'irjno', 'irfnu', 'irog', 'wern', 'yijn', 'xrnb', 'iernt', 'izrun', 'ueirn', 'jiri', 'irye', 'ixri', 'ifrjn', 'nhirn', 'ihwrn', 'rirn', 'ibrwn', 'nicrn', 'irnwz', 'chirn', 'drtn', 'vlirn', 'ktn', 'krm', 'lgn', 'fmrn', 'irnix', 'ihern', 'ialn', 'yien', 'imrsn', 'irnur', 'itqn', 'grnf', 'eirnq', 'ifni', 'irnbv', 'iumn', 'irznu', 'znirn', 'jrc', 'irpk', 'icnh', 'isrnk', 'uifn', 'ircen', 'ikhrn', 'icrvn', 'virsn', 'ilrq', 'ieren', 'rrnh', 'fiirn', 'lpn', 'ikb', 'syn', 'iajrn', 'kiirn', 'nnirn', 'iqren', 'ifh', 'zimn', 'ikwn', 'ijhrn', 'pibn', 'mrrn', 'lvirn', 'icsn', 'bimn', 'icrny', 'ilzn', 'ixnb', 'irsy', 'iakn', 'ilrnz', 'ijb', 'itgrn', 'blirn', 'irtnb', 'virpn', 'nixrn', 'icrnw', 'xikn', 'lln', 'pirni', 'jirin', 'iwy', 'inrw', 'irxo', 'iirnm', 'fvirn', 'ixm', 'ihre', 'irlmn', 'wln', 'itw', 'urnq', 'ixyrn', 'izrfn', 'soirn', 'nrnw', 'irdin', 'viwrn', 'iqrpn', 'iyvrn', 'imrkn', 'iraen', 'ilnq', 'frf', 'mrv', 'hirnu', 'ihi', 'wqn', 'jron', 'iizn', 'zzn', 'tirq', 'eigrn', 'oirin', 'jifn', 'uirc', 'yigrn', 'oirni', 'dirnc', 'kinrn', 'ivrni', 'izjrn', 'ibsn', 'irat', 'yrnv', 'igrmn', 'drnu', 'iryna', 'prkn', 'icrnp', 'limn', 'irnls', 'vitrn', 'ercn', 'irpns', 'girnz', 'izx', 'irnlt', 'idrb', 'itrdn', 'iog', 'sixn', 'jirq', 'isri', 'lcirn', 'irukn', 'wign', 'pcn', 'zrbn', 'jnn', 'piprn', 'yrna', 'irnsh', 'gr', 'urvn', 'irpkn', 'urcn', 'trm', 'bwirn', 'ibk', 'birz', 'rrnr', 'irfpn', 'xiln', 'vre', 'irjnv', 'irfns', 'pivrn', 'inyr', 'cren', 'icxn', 'iurcn', 'irwf', 'pirnj', 'imd', 'idrn', 'eirrn', 'irxjn', 'kdrn', 'trb', 'uicrn', 'irum', 'aiern', 'iqnz', 'isvrn', 'irinx', 'minrn', 'rtin', 'ifrtn', 'riin', 'trnv', 'irwnf', 'kivn', 'irmp', 'rrnu', 'irvm', 'iarj', 'hxn', 'ihnrn', 'awn', 'iuc', 'hrni', 'ikrnt', 'firc', 'irbwn', 'irhnh', 'aikrn', 'iorqn', 'hdirn', 'icron', 'srbn', 'bmrn', 'qcrn', 'rhin', 'irnuw', 'crnm', 'irnpu', 'isro', 'zurn', 'ive', 'oiern', 'imrb', 'airnl', 'jilrn', 'ilrln', 'icrqn', 'tiyn', 'iyrnk', 'rry', 'iyxn', 'jicrn', 'dgn', 'irmnr', 'irbnu', 'ixrmn', 'ybrn', 'aryn', 'iuzrn', 'iik', 'ic', 'sirc', 'virl', 'nn', 'clirn', 'irinm', 'irnm', 'irunz', 'girfn', 'zhn', 'zrnr', 'iretn', 'idrnd', 'iknn', 'srne', 'xiren', 'circn', 'igqrn', 'irmxn', 'iont', 'iner', 'irhn', 'irrnx', 'iinj', 'amn', 'iqwn', 'ttn', 'try', 'ifrno', 'irejn', 'irnrz', 'ibrun', 'ixrno', 'iorln', 'ilgrn', 'iiwn', 'qgrn', 'irfnn', 'lirns', 'irtz', 'irxq', 'rnt', 'mrnp', 'zzirn', 'irbnm', 'xign', 'gqirn', 'jkirn', 'itj', 'irtnd', 'rtn', 'ienj', 'iwrm', 'ifen', 'dro', 'qirnd', 'irhv', 'dsirn', 'tirc', 'irnmg', 'irnnl', 'iys', 'qirnb', 'wrnm', 'prg', 'tpirn', 'wirj', 'hrs', 'iarf', 'irjnu', 'wira', 'ijnn', 'ivrnd', 'irbni', 'mirr', 'irql', 'nrcn', 'kirc', 'ernk', 'ilrxn', 'sirj', 'inrr', 'irnno', 'irhqn', 'irynh', 'icrs', 'irfh', 'idrnn', 'uinr', 'irytn', 'airnd', 'iruns', 'eirwn', 'jirnr', 'uirnf', 'viern', 'ipl', 'ixi', 'kre', 'pire', 'imern', 'qird', 'vijn', 'invrn', 'kirt', 'ironr', 'iprg', 'eisn', 'ioarn', 'ikrnq', 'itqrn', 'ertn', 'lnirn', 'ihrun', 'irlne', 'iyng', 'iprd', 'ironi', 'urzn', 'vrnq', 'ijrdn', 'hrd', 'irsu', 'lirqn', 'ijnq', 'apn', 'iyrno', 'irhu', 'yrzn', 'irnjw', 'mirnt', 'uirwn', 'firfn', 'birl', 'ixrny', 'igru', 'odrn', 'jwn', 'rq', 'kiln', 'ircw', 'anr', 'firp', 'ifw', 'irynn', 'igrnq', 'inhrn', 'ilrqn', 'orf', 'bhrn', 'irwno', 'pirtn', 'zrnx', 'imre', 'iyz', 'irzq', 'izdn', 'irunc', 'yrk', 'dzrn', 'erdn', 'xixrn', 'hfn', 'iod', 'xvrn', 'pru', 'icb', 'irrt', 'ikkn', 'azrn', 'iartn', 'irlnd', 'iurns', 'irco', 'lrxn', 'zrjn', 'airns', 'ierv', 'eiru', 'fkirn', 'litrn', 'yron', 'irynr', 'yirsn', 'qfrn', 'idrbn', 'qiin', 'gisn', 'ilro', 'hirpn', 'icm', 'iygrn', 'irjyn', 'irqa', 'irnzi', 'oirl', 'cfn', 'drvn', 'iwnj', 'iriwn', 'nrg', 'uirnx', 'ibrnx', 'icgn', 'nrhn', 'prny', 'irvnq', 'wiln', 'wyrn', 'cidrn', 'zrnp', 'icurn', 'irin', 'ridn', 'bian', 'qicn', 'nivn', 'bnr', 'ircnc', 'ziern', 'ilrmn', 'ienu', 'mirk', 'riorn', 'ifin', 'prh', 'ijsrn', 'irkm', 'iurfn', 'irdnn', 'irxn', 'ipun', 'irpni', 'iens', 'nilrn', 'inn', 'irps', 'riv', 'dihrn', 'isrt', 'riro', 'aitn', 'ivrbn', 'oren', 'ipkrn', 'vifn', 'ehirn', 'ism', 'ilrbn', 'einr', 'iryg', 'nuirn', 'rihrn', 'yln', 'ibro', 'irntj', 'ewrn', 'ipnt', 'irnbd', 'iwun', 'eibn', 'piren', 'idnx', 'eirn', 'inrg', 'uirnt', 'kire', 'irnf', 'irmd', 'rrvn', 'irwni', 'ursn', 'isrna', 'ixirn', 'liyrn', 'iwrnl', 'irlon', 'arnm', 'czrn', 'ikrmn', 'irqng', 'irmi', 'jinn', 'xrun', 'trg', 'ijnp', 'xirnu', 'irte', 'irib', 'ip', 'mirb', 'lijn', 'vrxn', 'vcirn', 'ixren', 'nihrn', 'srin', 'irrw', 'imjn', 'irig', 'niln', 'jkn', 'wizn', 'ironw', 'nian', 'iarnw', 'uire', 'mrk', 'iyrnp', 'ilh', 'irnfj', 'itz', 'iyrzn', 'rihn', 'rrni', 'virng', 'ido', 'sivn', 'iinm', 'ifrnb', 'vren', 'qirnv', 'irsj', 'ibrtn', 'iti', 'irhnj', 'cirx', 'ise', 'irngh', 'mirnf', 'ime', 'xicrn', 'iore', 'iikrn', 'iinx', 'itrd', 'zru', 'rhn', 'iny', 'iond', 'irnxn', 'ugirn', 'wirnr', 'wrkn', 'yirxn', 'ihan', 'jrsn', 'iyrpn', 'xre', 'iwrnk', 'irhy', 'eon', 'nikn', 'yirny', 'irhw', 'eiyn', 'inry', 'xrm', 'blrn', 'srh', 'irkni', 'ixorn', 'rjin', 'sirl', 'pmrn', 'oird', 'imcn', 'qikn', 'hirna', 'npn', 'iqarn', 'vrnn', 'dzn', 'iegn', 'sidn', 'ikrc', 'irnou', 'nwirn', 'mirc', 'yyn', 'inrq', 'inrln', 'irnb', 'irsg', 'fqirn', 'mirm', 'irsa', 'irpyn', 'irqv', 'irnvt', 'eisrn', 'irtb', 'qin', 'isgn', 'mrnw', 'gen', 'irknz', 'itran', 'riny', 'ixna', 'odn', 'ybirn', 'iiry', 'icrn', 'miqn', 'ifa', 'irrfn', 'rixrn', 'adrn', 'hnr', 'vrnr', 'iqp', 'uhrn', 'omirn', 'qpirn', 'arln', 'icrna', 'nro', 'idrvn', 'rirsn', 'brun', 'zikn', 'mkn', 'izro', 'isnl', 'qilrn', 'widn', 'lcrn', 'irpng', 'lcn', 'lirh', 'zian', 'irnrp', 'zibn', 'hxrn', 'jmn', 'irly', 'firk', 'nairn', 'iorna', 'ixdn', 'ifrh', 'jrl', 'iwrb', 'dcn', 'irrno', 'rirc', 'irftn', 'wiro', 'lijrn', 'qjn', 'igdn', 'crnw', 'iftn', 'tirz', 'irfnz', 'invn', 'irtnu', 'lirr', 'irnat', 'irknm', 'rxin', 'icrnf', 'prn', 'iqhn', 'iurr', 'qirk', 'ivrnb', 'ibrh', 'irwne', 'irkqn', 'vrqn', 'inro', 'thirn', 'irnjf', 'ihrh', 'qiqrn', 'pirnd', 'irnrs', 'irws', 'jidn', 'iwrnz', 'ixrvn', 'irzna', 'ixrh', 'jry', 'srs', 'uirf', 'yirdn', 'cirg', 'iqurn', 'iirnc', 'iayrn', 'sqirn', 'kira', 'gqn', 'iqri', 'foirn', 'yairn', 'irngu', 'prnv', 'ninn', 'iiro', 'irdfn', 'irpfn', 'ireb', 'xrt', 'mnrn', 'lrj', 'ijrfn', 'mirh', 'irih', 'ikrnu', 'irnxu', 'ihrnv', 'sirs', 'irwe', 'cirnz', 'irown', 'iwrw', 'srnp', 'ipirn', 'imm', 'rnc', 'giyn', 'inrmn', 'irsen', 'qgn', 'ornk', 'ngn', 'igra', 'isy', 'irnei', 'izi', 'yirnz', 'euirn', 'rno', 'zgn', 'irxdn', 'urbn', 'irrnb', 'nirna', 'frnk', 'lirb', 'icrmn', 'itt', 'ipre', 'iqw', 'rbin', 'iuqn', 'jirh', 'ienx', 'iqng', 'zirsn', 'vrkn', 'grw', 'zxrn', 'nirp', 'ijrc', 'irncd', 'jirnu', 'ingr', 'rirna', 'worn', 'xfrn', 'uirnl', 'irio', 'irdrn', 'lrno', 'rirmn', 'tizn', 'yirhn', 'orx', 'irlb', 'drng', 'trnz', 'yirw', 'zlirn', 'wijn', 'birg', 'zirnq', 'irien', 'irsns', 'sivrn', 'ihrtn', 'rrne', 'itgn', 'bun', 'tryn', 'idb', 'iqni', 'evn', 'jnirn', 'irngb', 'kidrn', 'irvzn', 'igrd', 'zrun', 'girnc', 'iernp', 'ork', 'irfnw', 'irnsx', 'oirm', 'xidn', 'fren', 'izc', 'ilrnp', 'grwn', 'iyrv', 'qwirn', 'ery', 'iixn', 'zhrn', 'edn', 'diern', 'ijng', 'hrwn', 'ilny', 'bqn', 'irnqc', 'wirnl', 'hln', 'rnin', 'pvn', 'rinj', 'vnrn', 'arne', 'hion', 'kkrn', 'xarn', 'irrc', 'irndm', 'trni', 'srpn', 'ijrnr', 'irlnf', 'isrtn', 'ton', 'girns', 'airo', 'ijrkn', 'isne', 'cry', 'irlnc', 'oiro', 'iqon', 'izpn', 'crnd', 'irnrq', 'lzrn', 'garn', 'iorne', 'virnd', 'qoirn', 'isrnf', 'nign', 'vrnj', 'irko', 'ixrx', 'izgn', 'jirjn', 'irnwt', 'inrl', 'ijrnq', 'irdf', 'ohirn', 'qimn', 'ilt', 'iuri', 'igrns', 'oirzn', 'grr', 'iruno', 'tixn', 'iruan', 'brnv', 'pirzn', 'aren', 'prun', 'izzn', 'ix', 'iwrzn', 'girnt', 'ihdrn', 'trjn', 'yijrn', 'idnd', 'irdr', 'dfn', 'wkn', 'jirv', 'imrg', 'itrln', 'ixw', 'ivnc', 'wikrn', 'krmn', 'irnpp', 'frrn', 'tirnm', 'ernc', 'ignrn', 'ircne', 'trd', 'ivbrn', 'fnrn', 'dyirn', 'imnb', 'qirh', 'irnlk', 'irtjn', 'airpn', 'ircvn', 'irxnk', 'jirmn', 'iwrnw', 'tra', 'srmn', 'iiyrn', 'inh', 'smirn', 'znrn', 'ihrzn', 'uimrn', 'xijrn', 'pxn', 'kvn', 'irc', 'nun', 'kgn', 'irkd', 'qion', 'ihrsn', 'irwen', 'urny', 'ivru', 'qfn', 'wirnx', 'ernw', 'nrq', 'ivrx', 'ezirn', 'ircnb', 'imrs', 'irdjn', 'hirrn', 'arfn', 'drb', 'iamn', 'iarun', 'src', 'eirtn', 'iank', 'erng', 'yrsn', 'ihnk', 'mirw', 'jran', 'irznt', 'nidrn', 'ijnl', 'isrjn', 'imrnx', 'irpl', 'izarn', 'erun', 'oprn', 'irnmr', 'rinu', 'cion', 'qirp', 'ernp', 'vrx', 'mtrn', 'drqn', 'ivrjn', 'kirsn', 'irsv', 'xiyrn', 'ikrny', 'irtg', 'irnqq', 'irojn', 'irip', 'irkg', 'vrsn', 'zrno', 'iprng', 'ierp', 'irinc', 'ivgn', 'virln', 'rmrn', 'iburn', 'erln', 'cxrn', 'yiru', 'ifirn', 'igq', 'inkr', 'fr', 'msirn', 'hrna', 'grin', 'ijnj', 'irfnm', 'lmirn', 'art', 'irll', 'iva', 'irnsd', 'irngi', 'ginrn', 'rrtn', 'irtwn', 'ivnm', 'viorn', 'girmn', 'ahrn', 'irkfn', 'irwhn', 'irnl', 'iqrng', 'iez', 'dcrn', 'virhn', 'irren', 'ihrf', 'wirhn', 'iqrd', 'ijran', 'ircna', 'brhn', 'zren', 'yan', 'irhf', 'irhan', 'non', 'ziran', 'uhirn', 'irut', 'iqnd', 'ivk', 'sqn', 'ivrhn', 'ajrn', 'pian', 'birln', 'krsn', 'ixrnl', 'iirh', 'uipn', 'iard', 'rd', 'ri', 'irjnj', 'irtnl', 'icz', 'irnmc', 'ihnj', 'xyirn', 'iruj', 'pirrn', 'ikern', 'ikrpn', 'drln', 'fpirn', 'fien', 'ijrpn', 'irnfw', 'wirv', 'irnrr', 'irgq', 'idv', 'igrk', 'lirnb', 'qien', 'kirfn', 'ienh', 'isrzn', 'ifnl', 'kirdn', 'ivmrn', 'iruw', 'zfn', 'hrt', 'yirnp', 'igrkn', 'irjy', 'ifrv', 'tvrn', 'nitn', 'iiorn', 'airm', 'ipro', 'ipmn', 'hrm', 'ivsn', 'ironc', 'irdan', 'ibrng', 'ipcn', 'oxirn', 'wrqn', 'dern', 'ilrun', 'mre', 'sprn', 'itrf', 'mqn', 'irdnx', 'iaqn', 'mirn', 'tiin', 'iarq', 'girnf', 'wrni', 'tifn', 'ixfn', 'kirq', 'imny', 'airdn', 'ivgrn', 'orp', 'girzn', 'airs', 'iryd', 'lrna', 'fiqn', 'ijwn', 'frny', 'ernj', 'kimrn', 'ziry', 'qiren', 'kiro', 'idrnb', 'ikrw', 'iiun', 'irnty', 'irtna', 'okn', 'irxd', 'wirsn', 'igfn', 'irfun', 'iunr', 'itrk', 'irnoz', 'imrtn', 'irrz', 'irayn', 'irzln', 'iwrg', 'firnm', 'tirv', 'rrnd', 'ozirn', 'ifz', 'jign', 'xirhn', 'izrnj', 'drmn', 'ihwn', 'iroq', 'hn', 'iirz', 'irnuv', 'irnmt', 'ibyrn', 'ecirn', 'zrg', 'irxfn', 'midrn', 'dipn', 'irnjn', 'uijn', 'xrng', 'dnirn', 'uirq', 'ilsrn', 'qrs', 'irnlj', 'irnjg', 'ierx', 'irene', 'eian', 'yrmn', 'rirz', 'icrnx', 'iurw', 'krj', 'irqc', 'imgrn', 'brvn', 'mikrn', 'iljrn', 'jirm', 'virnh', 'jrnt', 'rqrn', 'irrl', 'iwnt', 'ntirn', 'irlln', 'mifn', 'qrc', 'ihurn', 'irbnl', 'idran', 'iobrn', 'scrn', 'sirrn', 'klirn', 'jirw', 'srnf', 'itern', 'ihrnm', 'ivrzn', 'irihn', 'nin', 'mrna', 'eipn', 'hirv', 'miern', 'ilxrn', 'vrnb', 'izen', 'uirxn', 'bira', 'uirun', 'fqrn', 'irnrw', 'owrn', 'ivg', 'ivr', 'iyrnl', 'lirnj', 'iden', 'icran', 'qiro', 'izr', 'byirn', 'dkrn', 'igrpn', 'lirln', 'bln', 'iernr', 'iyrtn', 'irct', 'itns', 'vryn', 'irdnp', 'ifny', 'itnt', 'firvn', 'ipern', 'ioern', 'iryng', 'xrg', 'rirh', 'irqk', 'gion', 'ubirn', 'iuno', 'iezrn', 'xrh', 'lfirn', 'ibrqn', 'ybn', 'frjn', 'boirn', 'krnv', 'ugn', 'hirm', 'iwpn', 'ikyrn', 'irqnh', 'urrn', 'kiru', 'ipng', 'pirng', 'aibrn', 'irmh', 'pzn', 'ivrv', 'tikrn', 'ironu', 'ydn', 'qrvn', 'er', 'siyn', 'xirgn', 'xirun', 'nre', 'rine', 'irpq', 'hyirn', 'ivri', 'qirzn', 'sirnt', 'mn', 'tzrn', 'lqn', 'lirx', 'giarn', 'qrnl', 'idrnr', 'irjvn', 'yrdn', 'iaro', 'ixnj', 'ihnv', 'xirf', 'trtn', 'krni', 'icbn', 'irifn', 'yrwn', 'uirmn', 'igry', 'birhn', 'hru', 'nijrn', 'ivrnv', 'uivrn', 'xrhn', 'irp', 'ydrn', 'yren', 'ifri', 'irnsw', 'ihn', 'rikrn', 'iprnc', 'abirn', 'jiwrn', 'pirnw', 'oern', 'irwbn', 'vrln', 'isbrn', 'irnbg', 'rrnl', 'wrg', 'irul', 'yrbn', 'iand', 'crnu', 'didrn', 'irnlh', 'irxmn', 'xrd', 'yirt', 'qra', 'idbrn', 'sirnl', 'birnv', 'irli', 'izrnt', 'yhrn', 'irpnf', 'nirns', 'wun', 'gron', 'virr', 'miarn', 'ivv', 'yirvn', 'eion', 'ierbn', 'eirs', 'ibry', 'irncf', 'irfnp', 'cern', 'bisn', 'zrh', 'irevn', 'ivt', 'uiurn', 'piyn', 'zmn', 'irrni', 'hiurn', 'disn', 'jire', 'irfn', 'pun', 'irwtn', 'inrnp', 'irvz', 'iszrn', 'ifrrn', 'iijrn', 'ibcrn', 'iernf', 'hiorn', 'iexn', 'xirrn', 'icl', 'iwv', 'iarns', 'tirwn', 'irngx', 'ieprn', 'irnqg', 'firw', 'krnx', 'airu', 'rrh', 'irzns', 'mrnn', 'izprn', 'zrnt', 'hibrn', 'fon', 'irprn', 'irnam', 'iwnq', 'ornp', 'lirhn', 'yjrn', 'mzn', 'iosrn', 'wizrn', 'ify', 'aen', 'bihrn', 'irnft', 'irgnl', 'iyq', 'iunb', 'iwnl', 'iibrn', 'prmn', 'irwnq', 'iunp', 'irqb', 'orb', 'inbrn', 'ifnt', 'irxsn', 'irj', 'iramn', 'urnt', 'xrnr', 'eirun', 'kdn', 'irjon', 'kirz', 'isrhn', 'fuirn', 'girkn', 'uairn', 'uirne', 'pirnl', 'ijtrn', 'airmn', 'aiqrn', 'inrrn', 'irntf', 'iopn', 'irnig', 'irrv', 'xrin', 'irpnb', 'prsn', 'istn', 'urqn', 'hrin', 'ieqn', 'xrnw', 'cien', 'inj', 'bcirn', 'biln', 'clrn', 'rqn', 'gkn', 'wry', 'birnc', 'irann', 'icd', 'tirng', 'irenr', 'qon', 'ivrsn', 'ipbrn', 'ifrn', 'ihrmn', 'lirfn', 'inrsn', 'drcn', 'wrnp', 'iuorn', 'ian', 'gijrn', 'igp', 'hdrn', 'nirh', 'kikrn', 'trl', 'irnqk', 'eijn', 'pyrn', 'kirl', 'ixsn', 'tirr', 'frd', 'ihen', 'lrr', 'drnx', 'iqrns', 'dmrn', 'irznv', 'irxqn', 'iezn', 'ihrnj', 'ipm', 'prf', 'irnne', 'ienq', 'iryy', 'yrqn', 'irunk', 'irda', 'ianc', 'iho', 'irngy', 'nrm', 'oirqn', 'irdh', 'tlrn', 'irwon', 'iglrn', 'brno', 'lrl', 'inrkn', 'bdn', 'qdirn', 'idp', 'igny', 'iihn', 'ikm', 'yin', 'birny', 'rirln', 'airnm', 'znn', 'irpr', 'pixrn', 'ilwrn', 'irpc', 'itryn', 'zrdn', 'krx', 'sern', 'bdirn', 'irnso', 'irzn', 'dird', 'irlnw', 'kyirn', 'ifrun', 'irnir', 'nrnf', 'irjln', 'ikrk', 'trna', 'irnpe', 'icxrn', 'irngo', 'iwxn', 'riarn', 'xixn', 'eern', 'nrbn', 'kirj', 'xrpn', 'iprsn', 'tinn', 'vuirn', 'ajirn', 'irix', 'ibnf', 'irgd', 'ixru', 'nrx', 'wrnt', 'igrx', 'brsn', 'iyni', 'irznh', 'uirr', 'ixrnj', 'irgng', 'xcrn', 'iwnd', 'irqnd', 'qrz', 'rirs', 'yrtn', 'kmn', 'yrnl', 'isnk', 'irmu', 'iarne', 'inrnh', 'srdn', 'airi', 'ifprn', 'inng', 'phirn', 'ilzrn', 'irlbn', 'iwrnt', 'iwrnd', 'inrnf', 'gqrn', 'vrun', 'iqrbn', 'yizrn', 'frs', 'irrcn', 'girna', 'ilrd', 'iytn', 'dqn', 'iwan', 'irnjh', 'idrs', 'eiwn', 'xrny', 'idzrn', 'ixnf', 'vikrn', 'arnq', 'irbxn', 'birnt', 'birt', 'firnq', 'tirw', 'itk', 'ixrr', 'isnd', 'irngl', 'irfhn', 'yirnx', 'irxnb', 'irxnc', 'afrn', 'frnx', 'birm', 'siri', 'nihn', 'isjrn', 'irunx', 'kirnl', 'ierqn', 'grnv', 'itne', 'irnao', 'akn', 'irszn', 'irlc', 'irndg', 'gbn', 'iuln', 'xrnd', 'ixnq', 'ivx', 'pirnp', 'ige', 'irvpn', 'ison', 'qjrn', 'un', 'srnu', 'ifnr', 'igl', 'irnmn', 'ibdrn', 'sri', 'irlns', 'dirnb', 'iynw', 'bry', 'lrpn', 'hirni', 'ibrne', 'dirnn', 'irnev', 'imrnw', 'qrsn', 'irskn', 'kru', 'rrnb', 'igorn', 'irqu', 'tigrn', 'dnn', 'ciran', 'tern', 'ilrnk', 'tmn', 'irnfy', 'irzb', 'xhirn', 'irwdn', 'ilryn', 'vihrn', 'qrv', 'xron', 'iaz', 'ireq', 'idren', 'kirnr', 'vyirn', 'imrh', 'viirn', 'iznh', 'irtpn', 'cirnm', 'yrnz', 'izrnz', 'srnx', 'ireqn', 'irnog', 'miln', 'cidn', 'gbrn', 'wcirn', 'irlnr', 'irvh', 'viran', 'iwnh', 'ivmn', 'icrbn', 'krzn', 'kfrn', 'kjirn', 'ijz', 'uibn', 'irmmn', 'ban', 'piry', 'irkn', 'ifrfn', 'ieln', 'ipsn', 'ikrnr', 'iunz', 'irrnv', 'winrn', 'irent', 'idne', 'iwt', 'irbl', 'idd', 'izrp', 'fibrn', 'irwt', 'irvin', 'srk', 'irnkk', 'itjrn', 'gkrn', 'arsn', 'trj', 'irntk', 'misrn', 'ikxn', 'irfyn', 'spirn', 'iaran', 'ikrbn', 'isxrn', 'ijzrn', 'itbn', 'nqirn', 'vrr', 'irqnc', 'pijn', 'eiwrn', 'eicrn', 'yryn', 'urna', 'iwgn', 'witn', 'iernq', 'irwn', 'djrn', 'icarn', 'isun', 'ienl', 'irckn', 'wirp', 'itnb', 'imfn', 'ezn', 'lirnx', 'airy', 'wicn', 'kiurn', 'uilrn', 'ifnm', 'jirz', 'kirnf', 'isng', 'ipnd', 'qorn', 'eira', 'ixnm', 'iirc', 'oun', 'yrt', 'idarn', 'iwon', 'irys', 'ivi', 'drx', 'jirnj', 'irnoe', 'ironn', 'yizn', 'irrs', 'itdrn', 'iocrn', 'sircn', 'irpnn', 'izhrn', 'isv', 'uiorn', 'irinz', 'ikrj', 'iztn', 'rirng', 'sinr', 'xirnw', 'hicrn', 'eirmn', 'inrx', 'geirn', 'virkn', 'irnih', 'ixhrn', 'irsng', 'ifnn', 'fgrn', 'osirn', 'ifrin', 'xr', 'girnk', 'ivkn', 'eirp', 'iorno', 'bren', 'irhtn', 'iraan', 'rrqn', 'xqrn', 'iqrln', 'wrnr', 'sizn', 'irtnh', 'arz', 'ivsrn', 'irnqx', 'ifrwn', 'wxirn', 'mern', 'xxn', 'iynk', 'hirnj', 'mrjn', 'crp', 'cirxn', 'kqrn', 'ieran', 'birpn', 'lvrn', 'iqm', 'dircn', 'irdnb', 'irbb', 'rrnv', 'iein', 'ibq', 'umrn', 'ihrnk', 'kirns', 'eird', 'iazrn', 'bnrn', 'hrnk', 'imrnd', 'ixrc', 'idrnp', 'inrn', 'eilrn', 'hwrn', 'ijrin', 'cyirn', 'rrx', 'irgnq', 'ixny', 'frne', 'trny', 'mri', 'iqrv', 'rny', 'izcn', 'xkrn', 'iznl', 'tran', 'wirno', 'pirkn', 'bfirn', 'dxrn', 'yrw', 'siorn', 'artn', 'kirbn', 'lrp', 'igirn', 'iaru', 'irinl', 'iqnl', 'ioh', 'mon', 'idrna', 'sry', 'izrna', 'iqbn', 'iruz', 'iwrq', 'uiern', 'irnze', 'ixvn', 'sxn', 'ixnt', 'irqnv', 'irgz', 'zrb', 'ihnl', 'jirzn', 'img', 'insn', 'xrl', 'irbq', 'zxirn', 'irjd', 'iyrnv', 'niorn', 'iok', 'vwirn', 'wmirn', 'irujn', 'ovrn', 'iylrn', 'olirn', 'iebn', 'iqzrn', 'iwrnh', 'irngj', 'mrr', 'irnpw', 'irbhn', 'rna', 'isrg', 'irgw', 'igrun', 'nirun', 'irgcn', 'qizrn', 'nrtn', 'irlg', 'iyhrn', 'wiwrn', 'ifarn', 'ierpn', 'mryn', 'airnq', 'sirnn', 'irdcn', 'rwn', 'birnm', 'orng', 'itry', 'ioqrn', 'grnq', 'fhn', 'ibrv', 'itvn', 'sirkn', 'uirnh', 'onrn', 'iruxn', 'irht', 'lirjn', 'wran', 'ijfrn', 'irdl', 'moirn', 'yidrn', 'eirqn', 'ihrdn', 'irnra', 'irev', 'iryrn', 'ijan', 'dnrn', 'yifrn', 'lrnm', 'ixry', 'zon', 'uikn', 'lirin', 'lirni', 'iztrn', 'furn', 'aiurn', 'irtdn', 'iurj', 'wirr', 'fira', 'irug', 'iwns', 'wirnf', 'cri', 'irnul', 'isr', 'irnyu', 'tirj', 'iion', 'injrn', 'irwnc', 'ipu', 'irint', 'ijry', 'nirnq', 'wxrn', 'irnfv', 'irebn', 'iraun', 'irof', 'irnlf', 'kixrn', 'mirnb', 'irnfg', 'irqnn', 'aimrn', 'iprf', 'iwln', 'irfj', 'irrm', 'ire', 'ikrnw', 'iryb', 'irbr', 'zrhn', 'irlcn', 'irngp', 'irtd', 'gwirn', 'iusn', 'iorwn', 'yrn', 'drni', 'xibrn', 'iurwn', 'lrin', 'ijnb', 'iporn', 'irzpn', 'crnl', 'irnzj', 'irnhz', 'irgnv', 'nirng', 'iznf', 'ibgn', 'mra', 'vhrn', 'uirnr', 'ikrun', 'xren', 'iyrb', 'irnrk', 'lrnq', 'lrsn', 'ivnz', 'ixpn', 'wirin', 'iano', 'wirc', 'brnz', 'isrnp', 'ikrq', 'sizrn', 'imnj', 'rrsn', 'irjnx', 'irq', 'irnpn', 'ziirn', 'iuran', 'drnj', 'iatrn', 'iardn', 'irgnn', 'iriu', 'tirx', 'xirtn', 'irryn', 'rirne', 'iozrn', 'crln', 'ilrno', 'irknq', 'mrqn', 'airg', 'iogn', 'hirb', 'irdnj', 'ioyrn', 'yqn', 'rirf', 'iryx', 'nifn', 'hrng', 'itf', 'hirt', 'xjirn', 'irnun', 'fxn', 'yxn', 'wuirn', 'erirn', 'irnuk', 'iafn', 'ciun', 'thn', 'irtnx', 'ijy', 'ieri', 'irnho', 'shrn', 'owirn', 'irnza', 'sirqn', 'erin', 'brnd', 'lirnw', 'iykrn', 'irzni', 'hikrn', 'rlin', 'kircn', 'iprnb', 'eqn', 'irznd', 'irbun', 'irhq', 'idro', 'ijrnl', 'yirh', 'irnvb', 'ibrrn', 'girn', 'irvo', 'itrnl', 'xmrn', 'irnoq', 'mzrn', 'ihrx', 'irlnn', 'isnh', 'birtn', 'hird', 'ttirn', 'iarg', 'frb', 'mirqn', 'qirnn', 'siirn', 'airtn', 'idkn', 'imrf', 'isre', 'grnn', 'irqf', 'oivn', 'grnm', 'zirq', 'idns', 'hnirn', 'trnq', 'krnp', 'xzn', 'airnb', 'ibrno', 'izs', 'infr', 'yvn', 'etrn', 'qiryn', 'imrr', 'grnu', 'iqa', 'irzu', 'irsnq', 'dirzn', 'warn', 'lrnr', 'iriyn', 'irlz', 'wrno', 'whn', 'idrhn', 'iuren', 'cirln', 'btn', 'irnaa', 'wgrn', 'nan', 'gian', 'burn', 'oiran', 'iunl', 'iwrnm', 'enirn', 'iirns', 'feirn', 'irvu', 'icrnj', 'ilri', 'whrn', 'iscn', 'ivprn', 'irqnp', 'ikgrn', 'irnyr', 'hirh', 'ddirn', 'igrxn', 'inrun', 'hiin', 'uion', 'gjn', 'irknx', 'tircn', 'urv', 'ida', 'irgxn', 'uixrn', 'era', 'cn', 'leirn', 'hron', 'hrnl', 'yqrn', 'inrf', 'irvxn', 'ixni', 'marn', 'uiln', 'brjn', 'qern', 'yrx', 'ifcrn', 'iraln', 'ivnv', 'ziln', 'isrbn', 'vrl', 'siron', 'xirln', 'nirm', 'isna', 'jtn', 'vrcn', 'iuj', 'eiirn', 'igrnj', 'inrnw', 'icfn', 'ixwn', 'irgr', 'jcrn', 'irdm', 'irhj', 'irrnm', 'oizn', 'uzirn', 'cfirn', 'irwnv', 'hirgn', 'irgan', 'nra', 'irsnc', 'wivrn', 'tirnu', 'dirv', 'irndz', 'iqna', 'ilrns', 'iffrn', 'inrng', 'jirnp', 'ibrt', 'ziqn', 'vfn', 'uian', 'ihzn', 'ers', 'izy', 'ipj', 'iilrn', 'zirj', 'iarr', 'ierd', 'ipz', 'irhfn', 'qjirn', 'fifrn', 'ihhn', 'wpirn', 'idin', 'ersn', 'cmirn', 'minr', 'iang', 'oinrn', 'iwrp', 'irtfn', 'yrgn', 'ioe', 'inern', 'urb', 'iivrn', 'quirn', 'irnvo', 'sirng', 'jrnk', 'ewirn', 'irngk', 'irfw', 'imrnh', 'pirvn', 'firi', 'brqn', 'pern', 'erns', 'vrp', 'jrrn', 'drl', 'crk', 'iton', 'urnn', 'erp', 'ilp', 'irfm', 'ximrn', 'tirjn', 'iarw', 'irnyz', 'ilnl', 'jrwn', 'igyn', 'iah', 'irwsn', 'aidn', 'zrnn', 'irnaz', 'imjrn', 'ijrj', 'ilfrn', 'ijrnc', 'xrz', 'hirin', 'irnkh', 'pir', 'ikin', 'ironz', 'uien', 'kirin', 'idkrn', 'iqirn', 'zarn', 'yrny', 'ispn', 'iolrn', 'udn', 'icni', 'qirmn', 'imi', 'iqrun', 'gun', 'iprz', 'dirm', 'qrnc', 'inb', 'dirjn', 'irasn', 'irncr', 'sirni', 'iorvn', 'ignv', 'uiirn', 'iirwn', 'ipx', 'bihn', 'irsi', 'iyyn', 'ilrpn', 'yiarn', 'iurnd', 'frn', 'ern', 'dmirn', 'ihmrn', 'itvrn', 'ikrl', 'iryu', 'cirno', 'gln', 'hinn', 'ihirn', 'xirnl', 'irndn', 'irndt', 'iojn', 'iqlrn', 'ifrb', 'ict', 'cdrn', 'cirsn', 'irrln', 'vran', 'iernd', 'cro', 'niyn', 'fikrn', 'iryny', 'irhx', 'irhwn', 'wifrn', 'rcrn', 'riun', 'mr', 'vrpn', 'ifjrn', 'irign', 'iqnw', 'qrns', 'pinn', 'icbrn', 'iernz', 'liurn', 'qlrn', 'gbirn', 'ixrln', 'ircmn', 'iyrhn', 'ikrnb', 'frvn', 'zirbn', 'ddrn', 'brr', 'piun', 'iko', 'iurng', 'icrr', 'oirb', 'irqni', 'nirw', 'ugrn', 'ioy', 'irynx', 'brj', 'iprq', 'jjirn', 'rinm', 'irpnl', 'yuirn', 'lrnk', 'mrc', 'tcirn', 'ilnk', 'mircn', 'birp', 'crny', 'ixrxn', 'ig', 'irncv', 'irpvn', 'kilrn', 'lrb', 'irqs', 'yiran', 'dinr', 'indrn', 'wbirn', 'irmk', 'irnvv', 'ivrny', 'wirt', 'irntr', 'xiran', 'ikzrn', 'ianl', 'irgln', 'vzrn', 'irgtn', 'irywn', 'ikron', 'rirk', 'ijen', 'ijmrn', 'orun', 'igrcn', 'imbn', 'irqnw', 'irrnh', 'iqrnm', 'irbne', 'iwrvn', 'yisrn', 'irang', 'isq', 'crgn', 'hiren', 'uixn', 'zicrn', 'ieryn', 'kirtn', 'irdnh', 'drnc', 'hirx', 'iwdrn', 'irtun', 'irncb', 'iprh', 'irwo', 'fijrn', 'ibrnn', 'iyrn', 'airr', 'iifn', 'hiro', 'zcrn', 'ibn', 'drin', 'bicn', 'imnk', 'lrg', 'rr', 'qirun', 'xibn', 'ljn', 'ibnt', 'imnw', 'idnrn', 'uqrn', 'irknu', 'irbnx', 'rrnk', 'irfb', 'oifrn', 'uvirn', 'ize', 'ipp', 'ianf', 'dirnf', 'iznrn', 'jrx', 'qmirn', 'kiry', 'oirnj', 'irlo', 'irqz', 'luirn', 'eixn', 'irktn', 'iqrj', 'eirkn', 'itwrn', 'frnd', 'irnsq', 'grpn', 'airnv', 'ayirn', 'kryn', 'irscn', 'irlj', 'nirwn', 'ra', 'ormn', 'riz', 'okrn', 'qirc', 'ygn', 'izlrn', 'ifan', 'ycn', 'izrcn', 'qirf', 'irmhn', 'jikrn', 'irzr', 'kiqn', 'biern', 'uron', 'izin', 'oirt', 'iicn', 'iefn', 'mun', 'iha', 'irfnd', 'firs', 'irmkn', 'iirsn', 'irqan', 'fjn', 'yirk', 'irwny', 'ircf', 'vin', 'ornx', 'irqhn', 'sirnz', 'qfirn', 'udirn', 'eyirn', 'qidn', 'qiri', 'irwln', 'qira', 'ienm', 'irenj', 'iznv', 'irptn', 'irpcn', 'rtrn', 'ifrvn', 'iay', 'rcn', 'jinr', 'irkc', 'iryr', 'aisrn', 'btrn', 'inrj', 'girh', 'nirxn', 'irbns', 'ieq', 'birwn', 'zjn', 'ign', 'irvnw', 'ifrbn', 'irinn', 'iuni', 'ygirn', 'iersn', 'zmrn', 'irvkn', 'inun', 'ifru', 'iirr', 'wre', 'qirwn', 'ijrne', 'jairn', 'gjrn', 'ifrnl', 'iaan', 'ijni', 'xtirn', 'icnv', 'ijrnt', 'itb', 'lrc', 'xnrn', 'iprdn', 'wtirn', 'iyprn', 'irti', 'srvn', 'gilrn', 'ieun', 'yirqn', 'vqirn', 'fryn', 'icnu', 'npirn', 'wipn', 'icrnm', 'fiwn', 'lirw', 'aairn', 'wkrn', 'iwrny', 'imrk', 'grnl', 'qrn', 'iyryn', 'ius', 'arj', 'rirgn', 'vrny', 'irnbp', 'cran', 'igrng', 'birnx', 'irnnd', 'qeirn', 'izcrn', 'ibnq', 'irawn', 'zrzn', 'nvrn', 'ciyrn', 'iprhn', 'yorn', 'ihrnx', 'cbrn', 'ironp', 'iqe', 'iyrk', 'bsrn', 'ifno', 'kwirn', 'rrwn', 'zro', 'fern', 'grnh', 'icnz', 'rrpn', 'irjgn', 'irznx', 'irznn', 'zirfn', 'irneh', 'irngs', 'izrzn', 'rlirn', 'iscrn', 'srqn', 'irvnm', 'irjin', 'irnek', 'erv', 'irnlp', 'irjj', 'lirn', 'tiyrn', 'vyn', 'siro', 'vun', 'iagn', 'kixn', 'qiern', 'xtrn', 'irnii', 'yimn', 'acirn', 'zpirn', 'ikarn', 'irtrn', 'irno', 'dirnw', 'wirbn', 'kirnk', 'hrxn', 'hirz', 'iurs', 'pprn', 'irggn', 'wiirn', 'cbn', 'nipn', 'drun', 'girl', 'nrns', 'irsrn', 'irnax', 'tird', 'kfn', 'inen', 'wan', 'rnj', 'uiqrn', 'ginr', 'iml', 'ijrf', 'nrwn', 'iznu', 'irvmn', 'irjng', 'ieru', 'igrp', 'ikrd', 'girq', 'qkirn', 'jrb', 'girny', 'ixd', 'irnnv', 'amrn', 'isnj', 'ibrnj', 'plirn', 'siry', 'qprn', 'iornw', 'zyrn', 'uurn', 'izrno', 'ziro', 'irtxn', 'sjirn', 'vxirn', 'uiarn', 'sihn', 'iwhrn', 'mrni', 'mirni', 'jirna', 'ibrni', 'nird', 'imp', 'iarxn', 'xrne', 'own', 'sirnh', 'lrng', 'irlxn', 'oitn', 'irnkz', 'ibkn', 'liryn', 'iubn', 'inir', 'piwrn', 'sirm', 'prno', 'ihrnz', 'smn', 'ixmrn', 'irnxg', 'erj', 'ornq', 'vrw', 'eran', 'irnmk', 'iat', 'ivln', 'jiprn', 'tirqn', 'iwrtn', 'uihrn', 'idryn', 'srkn', 'prln', 'irxon', 'irhnt', 'vqn', 'ilrnq', 'iranw', 'cirdn', 'kiwn', 'sign', 'iyrne', 'iryqn', 'dbn', 'ipry', 'oyrn', 'ixp', 'ljirn', 'orna', 'iwen', 'ireny', 'irxkn', 'bra', 'vrfn', 'crl', 'cigrn', 'zun', 'irnrl', 'larn', 'hrnd', 'irbnh', 'irui', 'qren', 'innt', 'wrnb', 'bixrn', 'lirno', 'irnnk', 'ibrgn', 'irmj', 'irqzn', 'jtrn', 'ikfn', 'snrn', 'hien', 'biry', 'ailn', 'uirjn', 'iot', 'rirnd', 'mrcn', 'jihn', 'kirna', 'irkj', 'ixrnq', 'xilrn', 'irexn', 'rim', 'iury', 'iyno', 'ktrn', 'irqne', 'ifxrn', 'icrni', 'rrnf', 'nirr', 'xirjn', 'srzn', 'imvrn', 'wirns', 'nixn', 'irnvl', 'bitrn', 'irmwn', 'qrwn', 'pirnz', 'irza', 'sibrn', 'iiu', 'irft', 'mird', 'ireyn', 'zirnn', 'viqn', 'iurmn', 'yirnb', 'srm', 'girwn', 'psrn', 'iwq', 'mirnl', 'irvsn', 'crw', 'drkn', 'qibn', 'irvnb', 'irsjn', 'ioln', 'zirnm', 'irehn', 'irhpn', 'iqkrn', 'igprn', 'itl', 'cisn', 'irbdn', 'iorcn', 'grrn', 'irffn', 'irii', 'wibn', 'irnnx', 'iynq', 'vrnz', 'iyrln', 'birqn', 'ierin', 'ijd', 'urz', 'jrd', 'irbnq', 'yyirn', 'ilrne', 'idrnx', 'ican', 'iuny', 'ivrmn', 'qgirn', 'ihzrn', 'rire', 'firnf', 'iux', 'gpn', 'iwj', 'rirwn', 'irph', 'ihrs', 'itrz', 'oirtn', 'frni', 'ixsrn', 'rinr', 'iknp', 'ivro', 'irij', 'ibrnr', 'itrnb', 'nlrn', 'rrk', 'yrin', 'zen', 'ibpn', 'iyrnr', 'xirnz', 'oxn', 'giwn', 'cipn', 'grq', 'eirnh', 'ircv', 'rnm', 'mrun', 'nrnr', 'ihni', 'pinrn', 'yirnh', 'pifn', 'viprn', 'inron', 'vrno', 'mirwn', 'mirdn', 'oicn', 'fiyrn', 'irnqy', 'disrn', 'uircn', 'irvny', 'itnu', 'arin', 'iarzn', 'idrmn', 'ijgn', 'cirs', 'ierjn', 'fmirn', 'hzirn', 'firne', 'mrs', 'igrzn', 'pon', 'zirm', 'iprw', 'rizn', 'iizrn', 'irlzn', 'itrin', 'rkirn', 'irbkn', 'liun', 'fibn', 'irinf', 'idrv', 'srn', 'icrun', 'iaxrn', 'iqry', 'xrp', 'virtn', 'ifcn', 'rvin', 'ifc', 'orzn', 'cinr', 'irnle', 'irsh', 'airnr', 'irnya', 'hrnf', 'ffn', 'dirnl', 'oirnn', 'iea', 'iyirn', 'cr', 'irnby', 'wren', 'qiprn', 'prqn', 'yiyrn', 'iernb', 'dirl', 'igrnb', 'lrs', 'girtn', 'irgy', 'ihkrn', 'svn', 'ckirn', 'irwpn', 'hjn', 'irbnz', 'prnd', 'urn', 'irnwj', 'iurkn', 'pirwn', 'ixrcn', 'ilrnr', 'xen', 'kbrn', 'brwn', 'grnd', 'iprx', 'irnkf', 'drna', 'hixrn', 'irrnq', 'inrin', 'srb', 'ixrun', 'irxpn', 'ircno', 'idrsn', 'iofn', 'jirno', 'ibrnw', 'iekn', 'nren', 'qign', 'aidrn', 'brfn', 'irnbe', 'nikrn', 'irnxv', 'qipn', 'yivn', 'rz', 'ikcn', 'iruen', 'mimrn', 'orxn', 'yipn', 'wirvn', 'iirln', 'krnl', 'gixn', 'oiurn', 'liqrn', 'iryzn', 'mpirn', 'iljn', 'iya', 'irnhm', 'xrnz', 'harn', 'ibrln', 'ijrtn', 'eren', 'nirrn', 'iuron', 'bjn', 'yifn', 'wrfn', 'irnlg', 'iorns', 'hrnz', 'ihqrn', 'iqx', 'iiru', 'orni', 'zirvn', 'yiwrn', 'iuwrn', 'idun', 'irdnz', 'tr', 'ixrnv', 'prxn', 'kirne', 'aibn', 'nrun', 'irshn', 'iris', 'ibrf', 'izrng', 'hgrn', 'urq', 'viln', 'itnk', 'fijn', 'ixv', 'kcrn', 'irgnd', 'ivny', 'irnuz', 'nrny', 'irud', 'ivrnm', 'ivjrn', 'rirnu', 'ircns', 'mrnq', 'isnp', 'ligrn', 'crnf', 'irnys', 'iqny', 'gitrn', 'byrn', 'iqh', 'irvt', 'yirl', 'mdirn', 'ibrnl', 'iqz', 'irnkj', 'irmnq', 'jrhn', 'jmrn', 'kirnx', 'yrnn', 'mro', 'airnz', 'irnyi', 'irvbn', 'ijrw', 'qrmn', 'spn', 'irkzn', 'iwtrn', 'iwyrn', 'firyn', 'zfrn', 'irnma', 'irfq', 'ignh', 'iina', 'iga', 'rrkn', 'rdin', 'irhnv', 'igrdn', 'qifn', 'xirnp', 'uirs', 'ikrvn', 'icsrn', 'icrjn', 'giro', 'irynj', 'uird', 'irnae', 'ivrxn', 'sran', 'icc', 'firb', 'piern', 'izra', 'dyn', 'irabn', 'iirnu', 'dirqn', 'idrw', 'irnxy', 'wirnd', 'kiran', 'swn', 'vtirn', 'ukn', 'xuirn', 'birrn', 'ntrn', 'dyrn', 'iraf', 'ipvn', 'jicn', 'trc', 'tirno', 'iki', 'ikpn', 'srnt', 'peirn', 'idrxn', 'biyrn', 'jird', 'zrnh', 'qrun', 'isrnr', 'iregn', 'ord', 'phrn', 'lwn', 'arnx', 'irnkb', 'sien', 'ifrgn', 'ksrn', 'cihrn', 'fcirn', 'hpn', 'xgrn', 'iyp', 'jira', 'imarn', 'ilrnm', 'iona', 'vjrn', 'ijnv', 'ipnr', 'irbsn', 'irnqv', 'ikq', 'wzrn', 'irtnt', 'icnp', 'narn', 'osrn', 'lprn', 'irtj', 'irhna', 'zirs', 'grun', 'yrr', 'irnto', 'iruon', 'jiurn', 'pijrn', 'ulirn', 'fion', 'qhrn', 'iqrsn', 'jivrn', 'firnt', 'idrin', 'irusn', 'aron', 'iban', 'irpx', 'tirun', 'girnb', 'irmnb', 'gdrn', 'irhsn', 'grcn', 'airna', 'yirnv', 'rni', 'eurn', 'iig', 'eivn', 'ireno', 'zirna', 'ilirn', 'iyrl', 'ibrj', 'irvdn', 'beirn', 'iyh', 'idrnj', 'irow', 'rrny', 'icre', 'iyren', 'irml', 'igrtn', 'uln', 'ijlrn', 'irnzk', 'aikn', 'iirv', 'diran', 'vrjn', 'murn', 'jrvn', 'irunf', 'qnirn', 'ditn', 'irny', 'kiarn', 'rrnx', 'irop', 'irpnd', 'zxn', 'xion', 'bxirn', 'limrn', 'qiorn', 'irxe', 'ivtrn', 'hrln', 'iup', 'irtp', 'knr', 'xrnj', 'njirn', 'njn', 'isrm', 'ihng', 'rg', 'idnf', 'irnik', 'iom', 'igjn', 'inbr', 'ixns', 'pjn', 'irhmn', 'yzrn', 'imrin', 'imtn', 'jrnq', 'irwl', 'mirnc', 'iten', 'iznp', 'airt', 'ierc', 'xzrn', 'idnl', 'mrg', 'virxn', 'ltrn', 'igne', 'irnmo', 'ry', 'drnl', 'crnc', 'iyc', 'girnd', 'rsn', 'iefrn', 'hirny', 'uitrn', 'piin', 'xirqn', 'vira', 'drp', 'lira', 'igrjn', 'krg', 'wimrn', 'ikvrn', 'irvfn', 'immn', 'ivan', 'brnl', 'irnds', 'xirs', 'irina', 'ikw', 'lirng', 'isdn', 'fitrn', 'iqv', 'ilhn', 'irnpk', 'jirny', 'irie', 'aiwn', 'grno', 'erjn', 'irunv', 'kr', 'ihin', 'irtv', 'swirn', 'hrne', 'ivy', 'ixxn', 'ibrvn', 'vrnt', 'oira', 'miro', 'krny', 'iyrnf', 'iknl', 'iyrna', 'irnub', 'grt', 'igren', 'ipyrn', 'jiln', 'yrln', 'irndq', 'prt', 'ihmn', 'firn', 'ifmrn', 'izo', 'imnt', 'irqnr', 'irchn', 'iorgn', 'iarnx', 'igrv', 'yrnt', 'xircn', 'irwan', 'arn', 'izon', 'rrf', 'irma', 'icnm', 'ornc', 'eirnr', 'ippn', 'iwren', 'irvnt', 'iikn', 'oirne', 'rnx', 'eirk', 'ievrn', 'irhnl', 'idrq', 'iei', 'irndr', 'egirn', 'porn', 'irben', 'isu', 'izun', 'winn', 'ierj', 'irnox', 'qirsn', 'orno', 'irfd', 'an', 'giurn', 'ilne', 'irnsb', 'rinp', 'hhirn', 'igno', 'iroh', 'ilnw', 'arb', 'cirnd', 'irjnc', 'irhnd', 'ihvrn', 'trng', 'irzz', 'ltirn', 'irnin', 'iryyn', 'zirp', 'ziqrn', 'iitn', 'tairn', 'ofrn', 'zrnm', 'nrnt', 'imrln', 'kizrn', 'ianr', 'iyrnn', 'niru', 'ivrnq', 'dsrn', 'nrirn', 'ixnr', 'ifrnw', 'irxl', 'irjna', 'rifn', 'srfn', 'irlnt', 'trh', 'lry', 'xiirn', 'seirn', 'irnxt', 'hiri', 'tiru', 'ibre', 'iaron', 'irnpi', 'lirnd', 'gyn', 'xirnh', 'ians', 'itrny', 'iroon', 'hivn', 'jifrn', 'iurq', 'drns', 'irtnw', 'san', 'rjrn', 'iqro', 'vilrn', 'irnmi', 'ixrrn', 'idrgn', 'hlirn', 'irdsn', 'zicn', 'qirne', 'krh', 'irvtn', 'uiwrn', 'ifi', 'uiri', 'rnl', 'drv', 'ixnn', 'sirbn', 'qirnm', 'irntn', 'gern', 'gimn', 'hrmn', 'irdgn', 'irrnu', 'vtn', 'phn', 'ijnd', 'inqr', 'irqcn', 'iqyrn', 'xxrn', 'isnq', 'rb', 'wbrn', 'irniv', 'arns', 'irgfn', 'pidrn', 'iprnm', 'irson', 'frgn', 'wyn', 'prin', 'trfn', 'irnlo', 'twirn', 'irzng', 'iynv', 'ucn', 'virzn', 'imrnr', 'irazn', 'wpn', 'iortn', 'iszn', 'ikirn', 'atn', 'iryl', 'zirt', 'ihri', 'iplrn', 'ijrnj', 'imurn', 'ixrv', 'nirnc', 'riren', 'ujrn', 'irvan', 'vimn', 'nivrn', 'niwrn', 'xxirn', 'qrrn', 'ggn', 'iqxn', 'ioxn', 'epn', 'inpn', 'xrk', 'wixrn', 'irlng', 'isern', 'rnd', 'jrnn', 'crb', 'xjn', 'ixrns', 'eairn', 'vrd', 'irfon', 'irpbn', 'idcrn', 'cign', 'jqirn', 'xirq', 'vrz', 'dicn', 'ibyn', 'qirxn', 'wirni', 'rif', 'zizn', 'irvnx', 'zidn', 'mrnx', 'orw', 'uizrn', 'oiwrn', 'igo', 'hqrn', 'lorn', 'ibb', 'rrv', 'zibrn', 'irla', 'itsrn', 'birnp', 'ymrn', 'imin', 'girb', 'izrr', 'sipn', 'cirgn', 'ilrsn', 'idrln', 'vr', 'xihn', 'irhnr', 'nimn', 'irgjn', 'irmr', 'iewrn', 'icrw', 'jrnd', 'wrh', 'rkin', 'przn', 'xirns', 'nirnj', 'ij', 'gprn', 'txirn', 'sikrn', 'iirnp', 'ipfn', 'ipnb', 'iks', 'rirns', 'irpa', 'irwmn', 'kirun', 'yirg', 'irnhb', 'wrk', 'irad', 'irnbm', 'xrmn', 'hir', 'irnhc', 'iycrn', 'irinb', 'xirkn', 'irrnw', 'irlnp', 'iprt', 'irqdn', 'itrfn', 'hnn', 'oirnp', 'fihrn', 'xrw', 'dirnm', 'qrbn', 'pbn', 'iey', 'cnrn', 'nigrn', 'inran', 'ioron', 'irndv', 'iene', 'bryn', 'eirh', 'iqryn', 'qirns', 'awirn', 'tre', 'kiyn', 'wrnw', 'irpg', 'iryn', 'uibrn', 'czirn', 'kirng', 'birr', 'fsirn', 'irag', 'ionb', 'bgirn', 'fjrn', 'irnzy', 'iuvrn', 'iman', 'irvyn', 'onr', 'iorkn', 'qirnp', 'iprnf', 'urxn', 'ten', 'irnrt', 'yrnd', 'prnh', 'qihrn', 'irjqn', 'fihn', 'rrgn', 'airq', 'ifn', 'can', 'ibjn', 'vbrn', 'iyf', 'ianu', 'oimn', 'oisn', 'inrh', 'vinrn', 'xiwrn', 'icnx', 'ihrin', 'prc', 'eirzn', 'irhhn', 'oirrn', 'jarn', 'birnu', 'ihsn', 'irdo', 'iunm', 'agirn', 'izron', 'ifp', 'tikn', 'irsnm', 'trnm', 'iqvn', 'irncw', 'iimrn', 'iai', 'bvirn', 'nrnn', 'slirn', 'iarv', 'qirl', 'bir', 'xvirn', 'hilrn', 'sbn', 'iyrgn', 'mrnd', 'irai', 'frnt', 'ivfrn', 'ihrcn', 'pirjn', 'iza', 'urnl', 'ixu', 'icrk', 'hian', 'mirne', 'biirn', 'iet', 'hisrn', 'zorn', 'giran', 'uirnq', 'irun', 'iora', 'udrn', 'zrkn', 'icrnn', 'iqq', 'nkrn', 'irqd', 'xinn', 'imorn', 'xirnd', 'ikg', 'aorn', 'ikjrn', 'znr', 'ieern', 'ihnm', 'irend', 'bkn', 'irnxb', 'bwrn', 'ibrnc', 'imrny', 'iyu', 'uri', 'iiprn', 'rrp', 'irnom', 'qian', 'kirg', 'jeirn', 'icrwn', 'iitrn', 'idlrn', 'lirrn', 'cirhn', 'inon', 'ifrnn', 'ggrn', 'irmnf', 'wn', 'erc', 'jro', 'visrn', 'irnpd', 'mixrn', 'irknw', 'eirnp', 'gircn', 'srg', 'irty', 'oirkn', 'alrn', 'isrns', 'krf', 'mirl', 'xkirn', 'idrnw', 'jrnl', 'iyru', 'idrun', 'iunj', 'isorn', 'irqvn', 'iotrn', 'ijyn', 'iranc', 'iorx', 'isns', 'gikrn', 'izm', 'ieni', 'gra', 'gifn', 'jiron', 'irrnn', 'giryn', 'frnp', 'iawrn', 'xirnx', 'dirk', 'fyn', 'voirn', 'ieno', 'brnw', 'iyurn', 'rj', 'jiru', 'iroy', 'hrbn', 'ionc', 'rirnc', 'iqrnr', 'isnt', 'iere', 'irkgn', 'urp', 'iargn', 'mihrn', 'ipny', 'tqirn', 'irvnn', 'brne', 'iros', 'mvirn', 'irqun', 'eibrn', 'airno', 'ivnj', 'ivnb', 'ikc', 'oirnt', 'vru', 'birj', 'ioun', 'kidn', 'igs', 'mirzn', 'irnfh', 'iran', 'girun', 'qirnz', 'irnxm', 'airnn', 'ixdrn', 'ikp', 'krns', 'iuarn', 'irynt', 'irzt', 'irnbf', 'rbn', 'iprp', 'zirkn', 'xyrn', 'tirtn', 'iurnm', 'iiy', 'irsnd', 'eirsn', 'idrtn', 'icrd', 'iunn', 'frl', 'liwn', 'igrr', 'vidn', 'irqnz', 'irsgn', 'ifrna', 'nvirn', 'qrr', 'wrb', 'iyrkn', 'grnk', 'xirna', 'insrn', 'diprn', 'xire', 'irirn', 'sfrn', 'jrf', 'yiirn', 'ixo', 'yirbn', 'orn', 'xrnt', 'frng', 'irens', 'izu', 'trnn', 'ciwrn', 'igrnz', 'irfdn', 'firmn', 'ipr', 'irrk', 'ibnj', 'rircn', 'iornn', 'hirnr', 'iwry', 'hrdn', 'irmno', 'bizrn', 'iura', 'yiren', 'iknd', 'cbirn', 'wirpn', 'iff', 'atrn', 'irpno', 'idni', 'igrt', 'ggirn', 'irtn', 'irngt', 'irntq', 'irtcn', 'lrnb', 'biren', 'itni', 'don', 'irfmn', 'scn', 'djn', 'iiren', 'ilu', 'uvn', 'igrnw', 'kibrn', 'ivd', 'irua', 'yrkn', 'wrwn', 'irrmn', 'eiern', 'wra', 'srxn', 'ihkn', 'ijc', 'erd', 'irhl', 'lzirn', 'nirnr', 'ihrj', 'zkn', 'ijpn', 'fkn', 'vpirn', 'irnyc', 'isjn', 'irnsj', 'ine', 'avirn', 'ihrb', 'irt', 'vjn', 'grx', 'irnej', 'ijro', 'drnv', 'eirb', 'ixrnt', 'rrin', 'xisn', 'jiryn', 'zijrn', 'drwn', 'xrcn', 'wirnv', 'oiyn', 'inwn', 'irfkn', 'irnid', 'iwbn', 'irnio', 'ies', 'trnl', 'ixa', 'iprvn', 'irmnh', 'kurn', 'inlr', 'fqn', 'pihn', 'imq', 'irbt', 'iprqn', 'mrne', 'siln', 'ldrn', 'trhn', 'trs', 'ivqn', 'nri', 'qrno', 'enrn', 'pcirn', 'trn', 'gvirn', 'irudn', 'idrni', 'ihrnh', 'isnu', 'iktn', 'irxgn', 'binr', 'wrhn', 'iprin', 'ihr', 'irnvf', 'lirgn', 'ignr', 'inrc', 'girg', 'qiun', 'irtnz', 'prnt', 'irgi', 'trx', 'piryn', 'uirt', 'xran', 'drd', 'ifrnv', 'imrzn', 'ibran', 'fitn', 'prrn', 'irnlw', 'qrqn', 'tivrn', 'iee', 'ixrn', 'qzrn', 'lizrn', 'ipno', 'irnmu', 'irnch', 'qiwrn', 'irkhn', 'oorn', 'wivn', 'airhn', 'kion', 'inni', 'imlrn', 'tnirn', 'irncp', 'isrd', 'xirdn', 'rpin', 'ilren', 'irmc', 'irane', 'iiurn', 'iht', 'iwnn', 'sgirn', 'irks', 'arx', 'iorl', 'ibcn', 'rns', 'girgn', 'irmon', 'its', 'yir', 'iqkn', 'irnvx', 'djirn', 'hrnb', 'birsn', 'irnxp', 'iarni', 'irxen', 'cmn', 'irpnv', 'iinr', 'uirzn', 'irnqb', 'iprk', 'cxn', 'iovrn', 'ikrne', 'kzirn', 'iprcn', 'irob', 'itrno', 'oryn', 'igzn', 'ivnl', 'idr', 'pirg', 'oijn', 'yern', 'izbrn', 'ypn', 'iyron', 'iacrn', 'iaern', 'crnn', 'irfrn', 'riwrn', 'qirfn', 'irnhp', 'wimn', 'inrni', 'cwn', 'irqnb', 'krr', 'corn', 'eicn', 'ijrm', 'ivjn', 'ironf', 'isrnh', 'vrnl', 'ironk', 'irysn', 'idrt', 'irkrn', 'iaren', 'iirs', 'ipnn', 'irnhs', 'irbf', 'ran', 'zrln', 'snr', 'ihrw', 'lwrn', 'innj', 'iryf', 'iwrkn', 'idrnz', 'xmirn', 'irron', 'iurp', 'irznj', 'irnpq', 'kzrn', 'wirnj', 'iwng', 'dir', 'uwirn', 'yirmn', 'irf', 'iurnz', 'iarnc', 'ienp', 'zrmn', 'irqo', 'irdnm', 'yirx', 'wirnu', 'lirq', 'ianw', 'grnc', 'firzn', 'birnh', 'frkn', 'iqxrn', 'irsn', 'ica', 'ircnr', 'ironx', 'tirpn', 'irnyq', 'orh', 'ibtn', 'ilry', 'jisrn', 'qrcn', 'isrno', 'qsirn', 'irrgn', 'irnxe', 'arg', 'inrp', 'cjrn', 'ifnrn', 'irncn', 'ijrcn', 'biwrn', 'xqn', 'trr', 'ixrd', 'viron', 'ikrnp', 'irpnj', 'yrz', 'rxirn', 'irdw', 'utn', 'srw', 'lqirn', 'vrnm', 'tirni', 'irpw', 'xhrn', 'ysn', 'wirjn', 'ilx', 'lirt', 'ivyn', 'biron', 'mnirn', 'frz', 'zitrn', 'isp', 'iown', 'ykrn', 'iworn', 'hipn', 'irynm', 'uirin', 'brnk', 'ivxn', 'mxn', 'bixn', 'iprb', 'firng', 'iyrnt', 'tro', 'eirnn', 'qiru', 'rirnp', 'ohrn', 'iel', 'jqn', 'icrns', 'iracn', 'virs', 'jren', 'arny', 'zrgn', 'cirtn', 'yxrn', 'iwrj', 'girin', 'adn', 'idnk', 'ibnl', 'eidn', 'inu', 'girqn', 'aircn', 'gru', 'irnyn', 'iqrh', 'iruo', 'iow', 'irnxi', 'kri', 'iixrn', 'ierng', 'iftrn', 'iuryn', 'mirnq', 'ipon', 'awrn', 'hran', 'rrnw', 'irzwn', 'icen', 'mlrn', 'kiren', 'lrk', 'kirjn', 'oign', 'iribn', 'jirb', 'igu', 'irbnt', 'irzk', 'krnb', 'rinb', 'irel', 'dirj', 'iresn', 'idxrn', 'irtnq', 'ixrnu', 'iqrnv', 'icgrn', 'irnoy', 'hizn', 'cirnl', 'ibzn', 'airk', 'eru', 'irnke', 'irund', 'oirc', 'iwkrn', 'ernd', 'tirvn', 'irnqe', 'zirni', 'irrny', 'oqirn', 'qvrn', 'iifrn', 'icun', 'irnj', 'isrqn', 'ifrnh', 'gnrn', 'brnj', 'lirpn', 'irxj', 'nyirn', 'qtrn', 'itd', 'ijrs', 'aizrn', 'iomrn', 'irnkx', 'inrd', 'zirn', 'ibx', 'irxt', 'irwnb', 'irnuh', 'irae', 'cgirn', 'iywrn', 'jkrn', 'nirvn', 'rirni', 'lra', 'irnfn', 'dirmn', 'irth', 'ihsrn', 'iarin', 'icln', 'iutrn', 'qrpn', 'irlni', 'mjirn', 'ifhn', 'iynl', 'urw', 'sirnv', 'ziprn', 'iron', 'ixrgn', 'vikn', 'eifn', 'lirny', 'ikan', 'ienv', 'tbirn', 'ikrnz', 'iwrmn', 'ion', 'sian', 'iirbn', 'nrmn', 'qairn', 'irjw', 'isrj', 'ivhn', 'iirnr', 'givrn', 'irndc', 'irnvn', 'wirh', 'nrkn', 'irsna', 'ihp', 'ibzrn', 'pfirn', 'irngf', 'qiyrn', 'urni', 'inrnn', 'girln', 'vmn', 'irkyn', 'kmirn', 'ivrnc', 'giern', 'brni', 'tirnz', 'riq', 'brcn', 'irdd', 'qrd', 'iprr', 'dron', 'sairn', 'grkn', 'zrnw', 'irrkn', 'iirg', 'iernx', 'mrnl', 'imu', 'ielrn', 'iint', 'jirbn', 'ivrnp', 'rirr', 'irnln', 'birnn', 'iuern', 'ivren', 'irnzx', 'irnor', 'wirn', 'imran', 'irnxc', 'ilnt', 'cirp', 'sirnu', 'xirfn', 'iap', 'eiorn', 'lirbn', 'inpr', 'ikhn', 'xifn', 'irsbn', 'mirnj', 'iroun', 'urh', 'ienc', 'irunl', 'ufn', 'mizn', 'irlwn', 'icng', 'iras', 'iurz', 'rnk', 'ijx', 'tiwrn', 'rien', 'irok', 'itrv', 'nijn', 'ikrnd', 'pirw', 'irmnv', 'ikrnf', 'igrb', 'krng', 'ibdn', 'frnw', 'lfrn', 'irlnz', 'biwn', 'ionk', 'dun', 'irju', 'iqrno', 'diln', 'irran', 'gvn', 'hiyn', 'iqrna', 'irfl', 'orc', 'erbn', 'ico', 'wihrn', 'rrnp', 'irknt', 'ivrng', 'zrr', 'iyrdn', 'irrns', 'irdvn', 'zgirn', 'liprn', 'ieg', 'rnr', 'irvnk', 'oizrn', 'girnv', 'ntn', 'gsn', 'iynt', 'bign', 'irhdn', 'lirne', 'qisn', 'imnx', 'ixno', 'nrnu', 'ilnh', 'iira', 'irlno', 'irnjp', 'hrnx', 'ayn', 'lrnn', 'ernx', 'iwirn', 'jrw', 'jirnm', 'irtq', 'tivn', 'ilrl', 'ilnrn', 'ijrun', 'jiro', 'irzyn', 'irbno', 'ilns', 'ivrln', 'irnse', 'jrnb', 'gyrn', 'wr', 'iv', 'niprn', 'omn', 'irnw', 'irfz', 'ibrmn', 'irnre', 'virc', 'tinrn', 'yvrn', 'idra', 'iurvn', 'ijryn', 'zirnt', 'igrfn', 'xinr', 'arnk', 'irry', 'orpn', 'qirnl', 'lrnt', 'irznl', 'fipn', 'fifn', 'oirno', 'igrs', 'irnvm', 'mrfn', 'icp', 'irnvq', 'inyn', 'ixrl', 'twn', 'gixrn', 'irrzn', 'ioyn', 'eqrn', 'inqrn', 'irrq', 'irnet', 'pirhn', 'iriy', 'ircd', 'rsirn', 'trnj', 'bircn', 'kprn', 'bfrn', 'ibns', 'erg', 'iy', 'birun', 'lrnj', 'jimn', 'ilrrn', 'uern', 'arkn', 'zirnz', 'msrn', 'qsrn', 'xrln', 'eoirn', 'wrns', 'cirnk', 'ifvn', 'prm', 'zpn', 'gimrn', 'iqrx', 'uirhn', 'ihc', 'iaq', 'irine', 'oirpn', 'elrn', 'irenx', 'idon', 'snn', 'sirnw', 'ilng', 'pin', 'irwk', 'iwrnf', 'ixryn', 'wrin', 'iqrmn', 'irvun', 'iecrn', 'irvx', 'kirw', 'eirbn', 'irxb', 'fvn', 'irnlq', 'frj', 'icrv', 'idrjn', 'irzzn', 'yira', 'itnr', 'iiqrn', 'fcrn', 'iajn', 'ziun', 'iire', 'niarn', 'irnkm', 'lmrn', 'iprgn', 'xiwn', 'ikny', 'yirne', 'orv', 'irrsn', 'dirne', 'qitn', 'idnm', 'rfrn', 'idrpn', 'irnyd', 'ifrnu', 'iinb', 'piirn', 'tirgn', 'irnkg', 'iaa', 'sire', 'iigrn', 'hrv', 'tirnn', 'ihne', 'lirna', 'iqqrn', 'iornk', 'qirnw', 'idcn', 'irhh', 'irkng', 'eircn', 'irufn', 'ywrn', 'xirnt', 'bnn', 'eqirn', 'ieurn', 'irkno', 'cirt', 'brx', 'urm', 'zimrn', 'zirv', 'fhirn', 'iqnj', 'yry', 'krnd', 'dgrn', 'ihjn', 'irfzn', 'iuun', 'jirnk', 'itdn', 'birnb', 'icq', 'hirnc', 'ivrnj', 'zirqn', 'iynn', 'qrna', 'cirnq', 'irndp', 'jrdn', 'zrnb', 'izrk', 'ixrsn', 'uqn', 'airln', 'irnwb', 'ijm', 'irynl', 'aijrn', 'oin', 'ihdn', 'ihrjn', 'irnph', 'igkrn', 'xirng', 'ircny', 'dwn', 'igpn', 'ilbn', 'igrh', 'ibrs', 'cikn', 'iram', 'irjnp', 'iocn', 'iwrin', 'idrny', 'viri', 'irlan', 'hprn', 'rnv', 'ibrpn', 'irhb', 'miirn', 'izrln', 'inrbn', 'rinv', 'kifrn', 'iwrno', 'irbe', 'cyrn', 'ihxrn', 'fiarn', 'tihrn', 'irnxz', 'irvl', 'uoirn', 'irndu', 'kirmn', 'iqrnh', 'gira', 'girnr', 'ivrkn', 'pirxn', 'aiwrn', 'plrn', 'mibrn', 'jsn', 'lrn', 'itrt', 'iruv', 'zrx', 'hirbn', 'xiryn', 'wrny', 'ibrnv', 'ixrbn', 'ignt', 'wrnl', 'irsb', 'pzirn', 'virvn', 'iwrh', 'uirnc', 'ihrr', 'pirnn', 'ijirn', 'mirj', 'irdnf', 'irnmw', 'kirvn', 'izrc', 'iung', 'idt', 'izno', 'oirnb', 'nirbn', 'ornj', 'irnbn', 'ifbn', 'irsvn', 'ircni', 'iort', 'izqn', 'ezrn', 'firhn', 'ivrns', 'iicrn', 'irnsc', 'gir', 'irwd', 'irunp', 'oirnk', 'isron', 'irwns', 'diri', 'iwrni', 'irzv', 'irvni', 'yrnm', 'ima', 'jirfn', 'fen', 'grs', 'ihrgn', 'irqen', 'fire', 'ibrnb', 'iejrn', 'farn', 'jiyrn', 'xira', 'isarn', 'dirno', 'ssrn', 'ifrnz', 'ebirn', 'itrjn', 'lrv', 'irvp', 'ipi', 'jibn', 'jrn', 'iprrn', 'idc', 'irnsn', 'igy', 'ert', 'irzbn', 'zryn', 'iara', 'irnpa', 'ozn', 'izrhn', 'irnjl', 'oihn', 'hirc', 'orln', 'rirnb', 'ile', 'iryp', 'ilxn', 'fiern', 'ivnu', 'irle', 'irnhg', 'virnw', 'iac', 'igc', 'rfirn', 'wirln', 'fzn', 'ihran', 'tsirn', 'ibrz', 'irlr', 'wlirn', 'ixra', 'irsz', 'kvirn', 'ivvn', 'irfnx', 'srt', 'mvn', 'irdnl', 'cpn', 'izrw', 'irxc', 'lkrn', 'srnd', 'wirnm', 'irnqa', 'irwu', 'irngz', 'xhn', 'iyrqn', 'cun', 'drnk', 'iritn', 'iursn', 'iwrnv', 'aivrn', 'trqn', 'iqo', 'airl', 'mipn', 'mirgn', 'ikna', 'girnx', 'jr', 'bbn', 'icrhn', 'ihrv', 'wrt', 'irfk', 'vgirn', 'aon', 'nxirn', 'uirnm', 'iorxn', 'ibra', 'oeirn', 'jizrn', 'virdn', 'xirx', 'orirn', 'irnww', 'iokrn', 'forn', 'iinrn', 'girrn', 'ben', 'gro', 'iornr', 'irneo', 'irpjn', 'kiyrn', 'irqtn', 'iredn', 'jdrn', 'jirnx', 'irwr', 'birkn', 'ivnt', 'incrn', 'xwrn', 'rgn', 'airjn', 'yitn', 'aarn', 'izh', 'ihrl', 'irsxn', 'nhn', 'ifns', 'irnxs', 'irjr', 'ihrg', 'piro', 'hirg', 'oirun', 'ivni', 'orne', 'oyn', 'ibp', 'igen', 'iynx', 'nln', 'fpn', 'eivrn', 'izrwn', 'wrmn', 'irnvu', 'cirrn', 'kirzn', 'iyzrn', 'tvn', 'yrjn', 'xairn', 'iedn', 'hircn', 'pr', 'iarnk', 'itrb', 'itno', 'brnc', 'isn', 'dtrn', 'jirgn', 'isrk', 'iroa', 'virx', 'irbnf', 'n', 'irbnc', 'lran', 'jirnf', 'ixnu', 'kiwrn', 'xirnk', 'xirnf', 'iqk', 'irdnv', 'wibrn', 'ijjrn', 'irgnf', 'ifk', 'lrnl', 'zwn', 'rvn', 'jirc', 'ijrnz', 'irnks', 'kxirn', 'airz', 'irnrb', 'izng', 'ixng', 'irunw', 'sirnd', 'ora', 'irkbn', 'irzxn', 'hgn', 'iirx', 'bidn', 'irhk', 'yirnr', 'skn', 'irtin', 'ur', 'nrxn', 'frx', 'irnaw', 'ivdn', 'ibrr', 'lirg', 'ilurn', 'iino', 'irnjr', 'nron', 'irgnw', 'iorfn', 'irnzr', 'jhirn', 'trkn', 'irmnd', 'oirnf', 'tkn', 'irntv', 'ihrn', 'cirb', 'irmv', 'yirzn', 'idtn', 'irnky', 'irnbb', 'dirnu', 'liren', 'ijrzn', 'qirz', 'ikrm', 'imrj', 'firkn', 'edirn', 'irung', 'qrnh', 'ions', 'prwn', 'qxrn', 'ipns', 'idnr', 'hirtn', 'hifn', 'pqirn', 'pirnx', 'inrtn', 'rirxn', 'ibun', 'irlnx', 'yrcn', 'isrnm', 'ilrx', 'irnvj', 'irpsn', 'iqrnx', 'firwn', 'iznj', 'roirn', 'torn', 'ciin', 'liarn', 'virn', 'vrng', 'irgf', 'iragn', 'ily', 'irzm', 'ilq', 'qikrn', 'irnwd', 'imcrn', 'kirnu', 'iqrnn', 'yion', 'dzirn', 'tnn', 'iwran', 'irxno', 'irona', 'grnx', 'irff', 'eiran', 'iirnz', 'oirk', 'oiprn', 'inra', 'widrn', 'pirns', 'ikrs', 'irvd', 'iryhn', 'ijren', 'zijn', 'liirn', 'irkv', 'ihrnu', 'iarnp', 'vimrn', 'iirqn', 'rrnn', 'ipnc', 'inrnj', 'hra', 'dirnq', 'icnn', 'ciqn', 'firnu', 'mirs', 'irrbn', 'jxirn', 'ivfn', 'rng', 'qiqn', 'ihz', 'airfn', 'rirhn', 'digrn', 'eron', 'oan', 'ione', 'idri', 'xrnp', 'irey', 'hirs', 'vrq', 'jru', 'himn', 'szn', 'xicn', 'ift', 'ardn', 'irynp', 'ivron', 'iund', 'varn', 'bon', 'iruu', 'yzn', 'niqrn', 'iirnn', 'nicn', 'vn', 'mirin', 'ildn', 'iini', 'itrhn', 'ilrny', 'piyrn', 'hrf', 'dijn', 'noirn', 'tru', 'ighrn', 'yicrn', 'ird', 'inryn', 'nzrn', 'irvs', 'iqrp', 'ytrn', 'airnf', 'imv', 'ihw', 'iarfn', 'trnw', 'wgirn', 'ikr', 'irdj', 'ireu', 'irnnw', 'pwirn', 'iert', 'ciryn', 'orrn', 'irvrn', 'vrnu', 'irdhn', 'kirp', 'vrbn', 'iruna', 'iud', 'xirmn', 'irinw', 'irmyn', 'cirnb', 'kirnh', 'timn', 'rzrn', 'cicrn', 'igzrn', 'yqirn', 'sarn', 'ijri', 'grbn', 'mfn', 'ziyn', 'irhnu', 'ili', 'oibrn', 'yrnk', 'firnd', 'airzn', 'ifnp', 'itrnn', 'eirv', 'irnsz', 'ijurn', 'ixnc', 'ihpn', 'lbrn', 'iruy', 'irneg', 'gitn', 'iqgn', 'irgnm', 'ill', 'irnta', 'iornx', 'irtnv', 'irnzw', 'irnar', 'ifrnx', 'qirna', 'iqcn', 'ifern', 'piron', 'vrt', 'iejn', 'iyre', 'krno', 'hiyrn', 'drpn', 'ejirn', 'ixrtn', 'ltn', 'ierny', 'ikrni', 'fiprn', 'kitn', 'urkn', 'imwrn', 'irons', 'oran', 'vian', 'ijrsn', 'urf', 'pgirn', 'ocirn', 'isgrn', 'ipnh', 'urnk', 'inrb', 'nrdn', 'szirn', 'igv', 'ofn', 'irnym', 'izru', 'mgrn', 'isnc', 'rirpn', 'aitrn', 'irxr', 'iwny', 'iurnc', 'io', 'xir', 'irei', 'ijln', 'bpirn', 'irdny', 'mirrn', 'irbx', 'ivrb', 'iavrn', 'hrnw', 'innu', 'xirn', 'crm', 'ikrnh', 'imun', 'iex', 'vri', 'iqd', 'zre', 'wvirn', 'izxn', 'irb', 'irbna', 'iurnv', 'irtsn', 'tira', 'irnht', 'gjirn', 'irkx', 'mibn', 'vgn', 'irsfn', 'cinrn', 'lihn', 'pkn', 'irjnw', 'birnf', 'irmin', 'yirn', 'ibnc', 'uirm', 'wirwn', 'ioan', 'yiron', 'irbcn', 'iwrxn', 'ornt', 'ory', 'lbirn', 'frv', 'isrb', 'ipwn', 'zrny', 'iemrn', 'xri', 'irnzn', 'jlirn', 'rrnj', 'ivrun', 'irnro', 'ibrc', 'lrnd', 'iznq', 'biri', 'inrnt', 'irpan', 'ixrw', 'ihh', 'ikrt', 'iorf', 'cira', 'irqno', 'gzrn', 'imrnm', 'ierk', 'irnjx', 'cikrn', 'ijmn', 'mbrn', 'twrn', 'ismrn', 'irngv', 'ixre', 'pirqn', 'air', 'itrnu', 'zry', 'irenh', 'irzin', 'ivtn', 'prcn', 'irer', 'yrp', 'krnm', 'iroln', 'irpp', 'iuz', 'orny', 'iudrn', 'innc', 'pirin', 'fixrn', 'qqn', 'oru', 'tifrn', 'idhn', 'firnp', 'jirnb', 'irnte', 'ioni', 'lrirn', 'irorn', 'ignj', 'gtirn', 'ifra', 'ipfrn', 'ivnq', 'iany', 'fiurn', 'icvrn', 'qhn', 'ifrpn', 'ilc', 'icrm', 'zuirn', 'ritn', 'iidn', 'ijrnu', 'korn', 'tien', 'ifrny', 'imnm', 'pgrn', 'igcn', 'miwrn', 'finr', 'irdy', 'vgrn', 'srnw', 'ifryn', 'idrzn', 'rrm', 'vjirn', 'von', 'ngirn', 'prnl', 'iqrnz', 'iwrbn', 'srx', 'birne', 'sjn', 'biprn', 'bion', 'irpy', 'irfs', 'zirmn', 'iqrwn', 'pdirn', 'iynrn', 'birnk', 'hrsn', 'izrbn', 'strn', 'rv', 'irynv', 'uirgn', 'izrnd', 'irgh', 'dpirn', 'nrnx', 'wzirn', 'iqjn', 'tqrn', 'rirrn', 'ijnc', 'xrb', 'lrni', 'gorn', 'lrns', 'ijrni', 'irzjn', 'yrnp', 'dru', 'vrnx', 'oxrn', 'ssirn', 'girnu', 'pkrn', 'orwn', 'irbd', 'sirdn', 'win', 'jrnx', 'lan', 'irqrn', 'igrwn', 'hirne', 'ifo', 'iyrnm', 'pirx', 'qrf', 'ornd', 'idqn', 'aqn', 'dlrn', 'ribn', 'iqfrn', 'ihrvn', 'nfrn', 'ivrfn', 'irnwh', 'irgny', 'irwz', 'iprnj', 'irfnb', 'isprn', 'ijfn', 'irfcn', 'irnwy', 'iwrt', 'iwrv', 'oixrn', 'iba', 'bjirn', 'ircnl', 'ilrcn', 'irakn', 'ioon', 'iinf', 'xrvn', 'bhirn', 'lhirn', 'ccirn', 'ni', 'hurn', 'girf', 'irnce', 'urmn', 'hirnt', 'krnc', 'zirhn', 'isny', 'yrnr', 'yrd', 'tiwn', 'yirin', 'iwxrn', 'irnqw', 'krcn', 'rino', 'iuxn', 'irhkn', 'ixrz', 'irvc', 'ilrnj', 'irnvw', 'iarbn', 'icfrn', 'ernq', 'jipn', 'lern', 'grny', 'ibrnt', 'iwcn', 'dirna', 'nir', 'lnr', 'irvln', 'kivrn', 'virk', 'ciri', 'hmrn', 'egrn', 'idnw', 'iory', 'iipn', 'ditrn', 'igrnv', 'imnrn', 'qrnw', 'rqirn', 'ocn', 'ivrtn', 'girnq', 'lrw', 'yurn', 'trnf', 'wgn', 'irbnd', 'imy', 'eirnk', 'sirln', 'ifrm', 'hirnz', 'itq', 'pird', 'irbyn', 'grnt', 'yra', 'iprns', 'irnbi', 'jrh', 'iaprn', 'usirn', 'aqrn', 'injr', 'ibjrn', 'pira', 'hrnj', 'fre', 'iary', 'inor', 'vrin', 'kiorn', 'ivrna', 'ipurn', 'irimn', 'imrnt', 'iirm', 'wir', 'mirnu', 'wrnf', 'imron', 'ihnu', 'ikrkn', 'tirnb', 'ircc', 'iwro', 'siryn', 'iwrc', 'imrjn', 'yirz', 'mkirn', 'irzj', 'qrj', 'irmt', 'rrng', 'ipv', 'irnwo', 'tpn', 'nmn', 'yiqn', 'riqrn', 'ikyn', 'iornb', 'ihrni', 'irbnn', 'kigrn', 'trno', 'itlrn', 'irjnq', 'igrn', 'ihnf', 'irnqz', 'uitn', 'irwqn', 'rinl', 'etirn', 'rirdn', 'iosn', 'jryn', 'irbs', 'cirnp', 'xrnc', 'wrnv', 'irnsf', 'insr', 'pxrn', 'iori', 'ibxn', 'eiqrn', 'nrnj', 'izrg', 'wrd', 'iratn', 'xirxn', 'cinn', 'frhn', 'jirx', 'pirf', 'idnp', 'ilrf', 'ixrnm', 'innb', 'ourn', 'idf', 'mrb', 'jirnl', 'mirg', 'irmq', 'eiri', 'krqn', 'qre', 'dirrn', 'curn', 'sidrn', 'erk', 'ilrnb', 'iyjrn', 'dran', 'yiwn', 'irjny', 'ilnc', 'duirn', 'irndd', 'irkz', 'ithn', 'cirnu', 'erne', 'itprn', 'riri', 'yrnb', 'iwk', 'ircl', 'bmirn', 'ifpn', 'iab', 'yirgn', 'iqsrn', 'iiq', 'iqpn', 'inrt', 'tn', 'zihrn', 'hrnh', 'hiwrn', 'toirn', 'ijnh', 'vmrn', 'zsirn', 'inzn', 'bifn', 'nrvn', 'ifrdn', 'icrln', 'mirng', 'irue', 'igxrn', 'iryjn', 'ifs', 'wirfn', 'mgn', 'dirg', 'rxrn', 'kyn', 'itrrn', 'qirny', 'lyirn', 'crnb', 'irccn', 'ifnb', 'irjx', 'sru', 'igrnr', 'ijn', 'irkwn', 'irfp', 'birx', 'virmn', 'icj', 'irzan', 'ibi', 'rivrn', 'itrj', 'hpirn', 'tirnd', 'iuru', 'lrh', 'xrna', 'iormn', 'iahrn', 'piqrn', 'wnirn', 'pien', 'ina', 'ldn', 'irnhv', 'ilrnn', 'tirnf', 'jmirn', 'ipru', 'miry', 'irzl', 'gijn', 'rirno', 'zra', 'pirnu', 'airwn', 'ivrnr', 'ikurn', 'iqrnk', 'iix', 'krnh', 'virp', 'ifrni', 'iprnw', 'ibrkn', 'airqn', 'uirnj', 'mign', 'iuvn', 'vfrn', 'ilorn', 'ixran', 'iroc', 'iqnrn', 'fmn', 'gn', 'izkn', 'ijrny', 'icy', 'rinw', 'ianh', 'zrvn', 'cifrn', 'mirp', 'irnot', 'iivn', 'gri', 'irsnj', 'isurn', 'irzfn', 'iepn', 'xrnv', 'jre', 'sirny', 'iprnp', 'hibn', 'virbn', 'ipxn', 'wiry', 'irnnt', 'irrqn', 'virnx', 'ziin', 'upn', 'tiro', 'oirhn', 'iclrn', 'lrmn', 'qirrn', 'irej', 'ionu', 'wircn', 'iie', 'irqxn', 'jfn', 'ikrcn', 'uyn', 'uira', 'krvn', 'dirb', 'mrnh', 'irnzo', 'irban', 'girj', 'idsrn', 'wien', 'iearn', 'hirnh', 'irhnp', 'irnnh', 'icrkn', 'oirn', 'iral', 'irnjo', 'eirna', 'irnbl', 'qirv', 'cwrn', 'idrl', 'darn', 'imnq', 'lirtn', 'niri', 'oiln', 'eirw', 'imrrn', 'mrmn', 'vrzn', 'yrc', 'ifgn', 'ixl', 'ipln', 'eyn', 'ifrz', 'jirf', 'livrn', 'kijrn', 'iiron', 'airnx', 'izrj', 'irztn', 'xirr', 'irwnj', 'irlkn', 'mjn', 'dhirn', 'hzn', 'zir', 'irnwu', 'tmirn', 'irxf', 'wryn', 'ifnv', 'irrjn', 'drxn', 'fgirn', 'irsr', 'drc', 'kxrn', 'ijqrn', 'iykn', 'qr', 'drhn', 'bigrn', 'qrw', 'idgn', 'iaj', 'irox', 'iriny', 'ircu', 'irnup', 'inrnc', 'uirdn', 'jwrn', 'irsq', 'drm', 'qirnk', 'tirkn', 'ianj', 'irhnk', 'yrf', 'poirn', 'ivn', 'irnyt', 'ftirn', 'isrcn', 'ircdn', 'iinw', 'iurg', 'crsn', 'imxn', 'hitn', 'ircwn', 'iorn', 'xirg', 'ihrne', 'xin', 'ibt', 'iorun', 'ernu', 'kcirn', 'ikrg', 'irnjb', 'ebrn', 'rvrn', 'mrwn', 'yrnq', 'uirh', 'irnru', 'crf', 'uuirn', 'ierw', 'rifrn', 'izni', 'tbrn', 'ityn', 'irnag', 'irak', 'rinh', 'irjnb', 'wvrn', 'iuqrn', 'izrnc', 'irhyn', 'nircn', 'iebrn', 'auirn', 'ivh', 'yiyn', 'prne', 'mijrn', 'cln', 'ximn', 'uirfn', 'iircn', 'ixrna', 'prz', 'utirn', 'unrn', 'sryn', 'frpn', 'arm', 'ihrxn', 'wirl', 'sitrn', 'ixnrn', 'ninrn', 'tirzn', 'fxirn', 'irwgn', 'irtzn', 'iev', 'rnrn', 'drnp', 'iirny', 'iofrn', 'inhr', 'izmrn', 'drnt', 'eirnm', 'ifr', 'irqnl', 'ziren', 'rinn', 'irjns', 'iarvn', 'rpn', 'frnm', 'ircgn', 'imrq', 'pirj', 'irmb', 'imkn', 'iriz', 'imnc', 'irhe', 'irgon', 'wifn', 'ixnz', 'irbgn', 'iwri', 'irssn', 'ipt', 'iapn', 'fprn', 'piln', 'wrsn', 'muirn', 'cdirn', 'icnc', 'izv', 'irnge', 'wrj', 'izrkn', 'irjc', 'jiirn', 'imhrn', 'iynf', 'lfn', 'icnq', 'irnpv', 'oirjn', 'uiin', 'ilrnv', 'ron', 'ilgn', 'iqrny', 'irnyp', 'iknv', 'lri', 'xirp', 'irnug', 'iwrx', 'irzkn', 'arh', 'iwin', 'asirn', 'ijhn', 'qnr', 'birmn', 'lrnz', 'mrvn', 'ernb', 'tvirn', 'wrcn', 'iprnk', 'iqern', 'iuin', 'zsn', 'ishrn', 'irnyl', 'izvn', 'hbn', 'vrns', 'uir', 'tijn', 'xirj', 'axn', 'zira', 'rit', 'skirn', 'niran', 'irpnm', 'tirnc', 'ienz', 'iwjrn', 'irnwr', 'ifgrn', 'xirh', 'ikrr', 'iou', 'kxn', 'kiri', 'iqrzn', 'ixun', 'irnyw', 'nirne', 'iyfn', 'irnrd', 'iwarn', 'kird', 'hirk', 'imqrn', 'ihnr', 'iorj', 'lhn', 'ifng', 'crg', 'mrtn', 'irken', 'bxrn', 'iuf', 'iyrin', 'irgzn', 'ipgrn', 'xirnr', 'yihn', 'ixrk', 'oirp', 'sinrn', 'wrzn', 'iunt', 'iirrn', 'ridrn', 'meirn', 'pln', 'inrnu', 'uirw', 'eidrn', 'gdn', 'iirvn', 'irijn', 'irnga', 'fyrn', 'bin', 'rrd', 'dirnd', 'pimn', 'icrrn', 'ifran', 'irozn', 'ilrgn', 'ibrx', 'jien', 'ijgrn', 'dimn', 'lrqn', 'irhm', 'rrrn', 'irntt', 'kyrn', 'isrwn', 'ajn', 'wirny', 'irsun', 'rirnl', 'ike', 'yirnc', 'irnxa', 'iwrng', 'irxun', 'irap', 'iarx', 'rran', 'irlpn', 'firrn', 'iarpn', 'irzi', 'isvn', 'ifrj', 'urnh', 'nfirn', 'iren', 'igrhn', 'hirnf', 'ijrn', 'mrnz', 'eiun', 'lru', 'izna', 'qiwn', 'lrnf', 'innk', 'cian', 'mrj', 'mairn', 'cird', 'xirk', 'irnca', 'iriin', 'qro', 'iurnx', 'ilrnl', 'airen', 'irnhj', 'irpm', 'crpn', 'birno', 'yird', 'licrn', 'ipyn', 'gwrn', 'ilrna', 'irgen', 'drnd', 'iagrn', 'ijnm', 'drsn', 'zirr', 'irknd', 'ziarn', 'brh', 'iraj', 'inrgn', 'irbon', 'ioxrn', 'ibl', 'irbnk', 'iurny', 'ilrnc', 'qirs', 'zrne', 'inru', 'irlnb', 'jirnq', 'uiun', 'irbp', 'iaqrn', 'irkna', 'wihn', 'irve', 'airkn', 'hign', 'krbn', 'qiry', 'jtirn', 'ighn', 'gxn', 'idrc', 'hvirn', 'itrne', 'iurv', 'pirh', 'ifry', 'ilrnf', 'ija', 'ifx', 'yirns', 'brtn', 'lrx', 'ijrjn', 'irwj', 'sird', 'iugrn', 'ejn', 'imb', 'irvcn', 'irnwk', 'irhg', 'xigrn', 'ivarn', 'itrnm', 'iwqrn', 'irnuy', 'ivbn', 'ietrn', 'izrv', 'irnx', 'innl', 'bibrn', 'urnb', 'lixn', 'irzcn', 'opirn', 'irlqn', 'innh', 'irnsp', 'mrnu', 'irjxn', 'mrkn', 'iokn', 'irknj', 'pirun', 'iqne', 'irnpo', 'lirnu', 'irsd', 'irrf', 'ihrnw', 'irxh', 'iwrgn', 'iprnl', 'izjn', 'jcn', 'irfnq', 'firny', 'irnbk', 'ifne', 'ncn', 'ignl', 'ijrnp', 'kirni', 'irjrn', 'iirng', 'iytrn', 'jvirn', 'iui', 'ignp', 'ilvn', 'sirnx', 'kiern', 'ibrny', 'irnap', 'ijra', 'xru', 'wdn', 'ihny', 'izt', 'irlt', 'prr', 'jdirn', 'iranl', 'irpgn', 'iwrnu', 'riw', 'iyx', 'hkirn', 'ien', 'hzrn', 'irycn', 'igrnx', 'micrn', 'dirw', 'oirnc', 'trzn', 'xirsn', 'rirnn', 'irnzd', 'irnnf', 'wiorn', 'dibn', 'jirs', 'eirns', 'vrvn', 'ginn', 'izfrn', 'airv', 'iarnr', 'nirk', 'firf', 'dwirn', 'ivrcn', 'sirz', 'upirn', 'irxv', 'miru', 'irznr', 'jri', 'iwtn', 'igun', 'ircg', 'brnq', 'irney', 'itrkn', 'irtni', 'irnhd', 'crs', 'nbrn', 'dairn', 'ibrdn', 'iriqn', 'xinrn', 'imrfn', 'wirm', 'iyxrn', 'pnr', 'qire', 'oirbn', 'qvirn', 'itrvn', 'iirf', 'ijprn', 'ibren', 'pigrn', 'vsirn', 'xiron', 'irgnz', 'kpirn', 'ihrnb', 'gicn', 'iiwrn', 'qyn', 'ikrtn', 'zin', 'oro', 'ihyrn', 'aqirn', 'niron', 'irnsg', 'irnnb', 'lisrn', 'irn', 'ngrn', 'iwrfn', 'iav', 'ibrzn', 'apirn', 'ivrnl', 'inne', 'imrd', 'pyirn', 'irinu', 'izfn', 'nirnv', 'iarm', 'ironh', 'kiryn', 'zrtn', 'iqvrn', 'qnrn', 'zrcn', 'wirgn', 'xiri', 'irhng', 'hixn', 'irnof', 'fidrn', 'wri', 'irzvn', 'qihn', 'fiyn', 'rmn', 'irkne', 'ipbn', 'bird', 'inrnl', 'ignx', 'iremn', 'iurl', 'irnvr', 'iani', 'mirnh', 'irxrn', 'ircnk', 'iben', 'isg', 'ihe', 'irnss', 'hrnt', 'mirv', 'wmrn', 'ayrn', 'vrnv', 'bn', 'tirfn', 'iurd', 'is', 'igrnf', 'jirg', 'iwrl', 'hiqn', 'iyrny', 'kisrn', 'iraz', 'irnde', 'wjirn', 'pizn', 'tjirn', 'inprn', 'inwr', 'izrni', 'ier', 'rivn', 'vfirn', 'irtno', 'qrzn', 'irwvn', 'sgn', 'iarnm', 'niryn', 'iqen', 'zrnz', 'igfrn', 'xrc', 'irnwq', 'ierr', 'xivn', 'irnni', 'iz', 'irnco', 'irzs', 'gon', 'crjn', 'irpnp', 'irnfx', 'lir', 'icon', 'mirt', 'iprjn', 'irnjk', 'iarnl', 'irvnr', 'iyrmn', 'nrna', 'izzrn', 'ikrb', 'prb', 'rion', 'virnk', 'iirl', 'qirnr', 'mirq', 'ivrnz', 'iyqrn', 'irpwn', 'zlrn', 'ihrnr', 'irmnz', 'gdirn', 'iwnr', 'nvn', 'xlirn', 'lkn', 'birzn', 'liin', 'shirn', 'iryq', 'irnsu', 'iznx', 'cjirn', 'irne', 'ioryn', 'liran', 'oiqn', 'icrne', 'qrnz', 'imf', 'irnay', 'igdrn', 'xan', 'iecn', 'cimn', 'birna', 'izrz', 'idsn', 'mgirn', 'it', 'irykn', 'iavn', 'qxirn', 'viun', 'crnp', 'iqrn', 'izrmn', 'nrw', 'firxn', 'mrm', 'niqn', 'qrnr', 'irnci', 'jrnj', 'imrbn', 'firun', 'isan', 'ira', 'ixon', 'ortn', 'iusrn', 'irqx', 'jirng', 'itln', 'isi', 'iiri', 'ipnz', 'ipnk', 'irapn', 'mrw', 'kiron', 'rron', 'uinrn', 'qirx', 'wvn', 'trv', 'yfirn', 'irwnt', 'rrnc', 'izrdn', 'iyj', 'ywn', 'irnct', 'iaryn', 'ilkn', 'irtqn', 'iqrrn', 'iun', 'iknw', 'nrsn', 'yian', 'crh', 'irenu', 'cirny', 'irnfp', 'mrd', 'icren', 'mirhn', 'frnn', 'mira', 'ihx', 'ironm', 'prnf', 'frnl', 'hiirn', 'pisrn', 'sigrn', 'isqn', 'dgirn', 'jijrn', 'ikon', 'nrd', 'isw', 'ihra', 'iurnp', 'itrh', 'oyirn', 'srnq', 'iej', 'cnn', 'mrz', 'iyg', 'irjbn', 'hirp', 'irv', 'iruqn', 'arcn', 'lirv', 'irfbn', 'irdzn', 'liyn', 'hirkn', 'nrnb', 'yirnj', 'prq', 'migrn', 'yrj', 'cirjn', 'irnkl', 'iksrn', 'hirnp', 'ihnb', 'wiwn', 'srng', 'ikjn', 'iqrr', 'iinz', 'olrn', 'dirny', 'irzdn', 'ciurn', 'ikrnc', 'kirk', 'ilhrn', 'drnw', 'cirnw', 'hirnq', 'itrnj', 'iqnm', 'rrs', 'yjirn', 'diin', 'jirnz', 'irqnq', 'virwn', 'irzny', 'oirdn', 'irnhx', 'whirn', 'irnuf', 'irhen', 'irnna', 'eikn', 'irnem', 'rzirn', 'virnv', 'eiyrn', 'ctrn', 'irsnu', 'jrnz', 'bairn', 'brbn', 'irkw', 'aiirn', 'onirn', 'irenv', 'grgn', 'siyrn', 'jrne', 'izrnr', 'itan', 'rra', 'ilrm', 'azirn', 'mirnr', 'arnj', 'irfi', 'xian', 'iqnu', 'rhirn', 'irmqn', 'irunh', 'oirnq', 'jirj', 'imqn', 'inorn', 'iil', 'ino', 'wrnu', 'iirnw', 'ninr', 'srr', 'hiron', 'hbrn', 'iqrhn', 'itxrn', 'iwwn', 'kirr', 'ifrns', 'iwh', 'iydn', 'idrm', 'hrnc', 'sxrn', 'irsan', 'bicrn', 'iwe', 'iuen', 'ijorn', 'idrno', 'irnjc', 'irsnb', 'iisn', 'ilru', 'firgn', 'ziurn', 'ibxrn', 'srrn', 'trnu', 'yiprn', 'ibrw', 'inrnv', 'qrng', 'ixrnx', 'rne', 'jon', 'irvr', 'irwnk', 'firni', 'irlrn', 'ierdn', 'rarn', 'irrna', 'irbjn', 'ornr', 'kirkn', 'zinn', 'sirna', 'jrj', 'ibh', 'iesn', 'imyrn', 'pidn', 'ihrrn', 'drs', 'ilrfn', 'iio', 'irkkn', 'irlv', 'irdx', 'ianx', 'irnqo', 'irjni', 'trbn', 'irnns', 'irnbc', 'frnv', 'innw', 'ijna', 'uru', 'igrnm', 'ihprn', 'fgn', 'nrqn', 'iqcrn', 'iornl', 'irlnu', 'icf', 'icrzn', 'tir', 'iryne', 'kgrn', 'nrf', 'ikn', 'eri', 'ircnm', 'rn', 'urgn', 'iernc', 'irrnt', 'icrgn', 'xrsn', 'rrln', 'airgn', 'birs', 'ckrn', 'ief', 'nirnk', 'oirnv', 'dizn', 'ihg', 'sirq', 'ijrq', 'yhirn', 'irkq', 'lwirn', 'izxrn', 'ifd', 'imrx', 'ainn', 'iryk', 'iuhn', 'birc', 'aiyrn', 'irfgn', 'firen', 'iyl', 'airj', 'ilen', 'irnfo', 'oifn', 'irwv', 'ierns', 'nirgn', 'irmln', 'qrnd', 'irvon', 'cirnf', 'irjnl', 'ilrr', 'igern', 'ifwn', 'hiryn', 'yircn', 'cirl', 'prni', 'irjsn', 'dan', 'inny', 'ibhn', 'wirnc', 'airbn', 'izb', 'ihnc', 'irznm', 'inrnk', 'itrnf', 'ibrnz', 'irwwn', 'ijrv', 'vrc', 'iol', 'ivrno', 'vurn', 'iihrn', 'ivm', 'irdnw', 'wirq', 'dmn', 'mrgn', 'zion', 'isrn', 'tirne', 'ipprn', 'irjhn', 'jrmn', 'irngw', 'irlnk', 'irlvn', 'arna', 'ipin', 'orcn', 'aru', 'irunt', 'irqon', 'iqtn', 'zr', 'on', 'itcrn', 'ionr', 'urk', 'nien', 'firan', 'irgm', 'irndh', 'irnlz', 'yiqrn', 'igbn', 'jirnh', 'iurnl', 'isru', 'qln', 'kirrn', 'arpn', 'ivw', 'irss', 'ihrfn', 'ivkrn', 'xird', 'rih', 'idq', 'irdv', 'xrnf', 'irfu', 'aixrn', 'qyirn', 'ihlrn', 'urdn', 'igtrn', 'isyrn', 'iec', 'cirbn', 'irna', 'iju', 'srns', 'iltn', 'ibnr', 'ionx', 'xifrn', 'byn', 'iyi', 'drnq', 'iyb', 'irnbh', 'nirv', 'ibgrn', 'kirnc', 'irlin', 'vrk', 'nirf', 'irqnf', 'iuhrn', 'cqrn', 'nqrn', 'krp', 'irqmn', 'iarnn', 'hrkn', 'jrin', 'wirnz', 'yiorn', 'irzun', 'isrl', 'biqn', 'irpnr', 'ivrpn', 'eprn', 'iqu', 'ikrsn', 'irpf', 'evrn', 'vcn', 'kwrn', 'xirzn', 'iwrd', 'xrnl', 'crnh', 'hirsn', 'hin', 'kjrn', 'tirny', 'irnyv', 'yixrn', 'irnqj', 'kirnv', 'trirn', 'ixzrn', 'viru', 'inf', 'irnux', 'yfrn', 'uyrn', 'yun', 'ifu', 'oirs', 'qrp', 'tzn', 'irani', 'idrnq', 'wirxn', 'gvrn', 'irzc', 'giqrn', 'ipdrn', 'irnlx', 'iranj', 'drnz', 'hrx', 'irkns', 'xrwn', 'ibnp', 'irlk', 'ijvn', 'ibprn', 'iukn', 'zidrn', 'irxnz', 'icrsn', 'iprnx', 'irndf', 'ikryn', 'librn', 'tqn', 'nirqn', 'uorn', 'wiern', 'zkirn', 'idrcn', 'irbm', 'jbrn', 'ibmrn', 'crj', 'ibne', 'irefn', 'irjnz', 'xien', 'irnnr', 'ixrq', 'firnz', 'sixrn', 'irxbn', 'isrxn', 'fdrn', 'frm', 'inrjn', 'imrqn', 'erkn', 'airsn', 'yrni', 'tirh', 'rirx', 'irgpn', 'lian', 'rin', 'ppirn', 'ikri', 'irnea', 'itzn', 'igrnu', 'firnr', 'iranf', 'irnpj', 'irlnv', 'irypn', 'iss', 'wirrn', 'ori', 'inln', 'irr', 'jimrn', 'xirpn', 'iinp', 'wrvn', 'tirs', 'ilprn', 'hfirn', 'ivrnf', 'iryns', 'yiln', 'orgn', 'iront', 'ksirn', 'irhi', 'xrnq', 'ircz', 'iong', 'iehrn', 'iyne', 'inren', 'ierf', 'iarc', 'irtnc', 'isrrn', 'wiron', 'ierln', 'iknf', 'iznk', 'airc', 'kfirn', 'itnn', 'zfirn', 'iunh', 'urg', 'irfo', 'arnl', 'irkny', 'orsn', 'xrzn', 'jvrn', 'iafrn', 'nirhn', 'wiurn', 'irnk', 'ipmrn', 'crnr', 'rirp', 'drzn', 'rs', 'rirb', 'izyrn', 'xro', 'ipc', 'ilyrn', 'nmrn', 'uzn', 'ddn', 'pvirn', 'irnfu', 'iggn', 'uirnp', 'irlsn', 'irnd', 'izrq', 'drnr', 'oirna', 'yirs', 'tyn', 'yirf', 'ojirn', 'xgn', 'jfrn', 'jrk', 'pinr', 'incn', 'wiryn', 'dirnp', 'idrnt', 'drgn', 'ivxrn', 'ryirn', 'ihl', 'inmn', 'iiirn', 'qirno', 'vrdn', 'firx', 'virin', 'brnh', 'imrwn', 'dirnv', 'hrqn', 'itrw', 'imnd', 'iyrm', 'itri', 'ixprn', 'ciprn', 'siran', 'ipg', 'iyrw', 'girbn', 'qrg', 'ahirn', 'frnq', 'iryh', 'idprn', 'qrnn', 'irybn', 'qnn', 'ijrd', 'irru', 'sr', 'ipnv', 'iorp', 'ciron', 'ciirn', 'mrirn', 'urns', 'rrzn', 'ior', 'irjnd', 'dixn', 'ixrnk', 'irngd', 'irnjq', 'sirf', 'irans', 'errn', 'irtvn', 'ifyrn', 'iann', 'irsnl', 'srtn', 'sirxn', 'iovn', 'qirtn', 'ifqn', 'iqrtn', 'rie', 'irnme', 'qirqn', 'tdrn', 'jgrn', 'qqirn', 'jrz', 'ilb', 'igw', 'rirv', 'tdirn', 'irpzn', 'irrxn', 'xizn', 'iasrn', 'jiwn', 'dirnz', 'vrtn', 'izrgn', 'goirn', 'imrz', 'qrq', 'imrnu', 'iranm', 'iyrcn', 'irnud', 'ifrnr', 'iarny', 'nira', 'brgn', 'zvn', 'iarnz', 'ilo', 'vrnd', 'dqrn', 'rro', 'yru', 'iwnc', 'srnr', 'mirun', 'irnst', 'irdnc', 'iiarn', 'ipsrn', 'zirny', 'bfn', 'iprnu', 'iprnq', 'irjne', 'nirt', 'ioro', 'jpirn', 'izrd', 'izp', 'rri', 'isrnc', 'ibryn', 'ijyrn', 'ipcrn', 'ifnf', 'qiln', 'lrbn', 'vdn', 'zoirn', 'mvrn', 'dxirn', 'irnsk', 'ifkrn', 'irvhn', 'nrnk', 'firnk', 'rprn', 'qirj', 'ylirn', 'hirnn', 'igrno', 'isrx', 'rain', 'firt', 'zrnv', 'wirkn', 'krnu', 'irxm', 'erna', 'dirp', 'irghn', 'irgyn', 'nirtn', 'imkrn', 'ijxn', 'qirnf', 'krdn', 'sfn', 'izn', 'vbirn', 'aira', 'iprwn', 'icru', 'sifn', 'hro', 'xrs', 'hon', 'eiprn', 'igrnd', 'iyan', 'drn', 'ivrgn', 'ind', 'prbn', 'igrnk', 'ilj', 'lirun', 'sitn', 'xirnm', 'birn', 'lrcn', 'lrkn', 'ijno', 'tbn', 'kirv', 'inin', 'ircnh', 'irtnm', 'bcn', 'xivrn', 'itun', 'ioo', 'irnsm', 'irsm', 'cihn', 'ornw', 'ihnz', 'ircp', 'iri', 'irbnp', 'hrg', 'icqrn', 'iyrnq', 'cirns', 'miri', 'prdn', 'ijrb', 'cirn', 'inrnm', 'irqqn', 'irsny', 'urnd', 'irenl', 'birnl', 'ijrng', 'rimrn', 'prnq', 'krxn', 'exrn', 'ihron', 'irnkr', 'iawn', 'kpn', 'eitn', 'dirng', 'irdkn', 'iorsn', 'kirnn', 'imrxn', 'idrp', 'drnb', 'srv', 'ivrnh', 'ihnn', 'bqirn', 'jirl', 'arng', 'irfr', 'igb', 'iaxn', 'aro', 'ynn', 'irjpn', 'yrvn', 'irnc', 'yrng', 'izny', 'dirin', 'hren', 'irjt', 'icrpn', 'err', 'rgin', 'firnv', 'trp', 'icrnk', 'itnj', 'irnhn', 'airny', 'iornf', 'irsx', 'iryln', 'kien', 'pirc', 'igmrn', 'ghirn', 'ikbrn', 'hrhn', 'oinn', 'ifnq', 'iue', 'heirn', 'eirnu', 'yirnw', 'imrns', 'eeirn', 'virb', 'grf', 'ikj', 'nrnq', 'iggrn', 'rlrn', 'irdt', 'simn', 'imo', 'woirn', 'irnew', 'itnx', 'cirna', 'fian', 'irir', 'irhnf', 'irono', 'tan', 'oqn', 'barn', 'rirnt', 'rnw', 'isnx', 'tirt', 'irttn', 'fwrn', 'izrtn', 'mir', 'liro', 'irpj', 'ifl', 'irmz', 'erzn', 'kitrn', 'erx', 'igrin', 'virnj', 'irdni', 'ttrn', 'xirnv', 'irnrh', 'irov', 'afn', 'wrrn', 'qijrn', 'ynrn', 'rig', 'iphn', 'iornq', 'jrs', 'ixrni', 'ifdrn', 'riwn', 'idtrn', 'irnn', 'ireen', 'irlyn', 'urnv', 'hirdn', 'rnu', 'iqtrn', 'irnv', 'tirnp', 'iurnj', 'orin', 'prx', 'ring', 'ircnv', 'urnz', 'irjs', 'iarn', 'llrn', 'cirv', 'fivrn', 'qigrn', 'fiqrn', 'xrdn', 'iaf', 'ijrp', 'rp', 'civn', 'iqrt', 'sirns', 'isrdn', 'ircun', 'gairn', 'mprn', 'urc', 'idjn', 'irvnh', 'hrl', 'mrng', 'innv', 'icrc', 'irnbz', 'ignd', 'aimn', 'isa', 'isrw', 'rmirn', 'firin', 'iriq', 'hsrn', 'yrnu', 'bxn', 'itzrn', 'urx', 'firsn', 'iqrcn', 'fjirn', 'xdn', 'tnrn', 'rirny', 'cir', 'sirw', 'ivrnn', 'irxcn', 'rirg', 'girxn', 'itrgn', 'ianq', 'ark', 'zikrn', 'vern', 'ivrdn', 'vrwn', 'rirtn', 'irde', 'ikrnx', 'lryn', 'iqt', 'icu', 'imrnn', 'oarn', 'cpirn', 'iarno', 'lire', 'crirn', 'iyri', 'sln', 'brng', 'irkp', 'krc', 'irvqn', 'irwb', 'ryn', 'hirw', 'icr', 'nirj', 'ipb', 'arnn', 'siqrn', 'iborn', 'vyrn', 'iswn', 'drnn', 'inrxn', 'eiren', 'ifro', 'iprni', 'ibnv', 'ornn', 'irwa', 'girc', 'ixtn', 'ifrnd', 'iruf', 'irtc', 'mrln', 'irqnu', 'ieorn', 'jinrn', 'iravn', 'imnu', 'irax', 'iknk', 'irrd', 'wbn', 'irtr', 'qhirn', 'virnl', 'ifxn', 'birnd', 'brnf', 'irtnp', 'izrnf', 'hrj', 'ilrt', 'linr', 'iarnq', 'iorni', 'xwn', 'hrjn', 'hmirn', 'dirs', 'ifrp', 'vrnp', 'iyy', 'isbn', 'cqn', 'girw', 'inrm', 'iryo', 'iwnrn', 'ierni', 'iornj', 'oinr', 'iwu', 'ilcn', 'mrnv', 'irpnk', 'ircnz', 'iturn', 'dvirn', 'irtyn', 'litn', 'irana', 'oidrn', 'irdng', 'grnj', 'itnl', 'ifrg', 'iwrne', 'igrq', 'ironb', 'ilnd', 'ilfn', 'virnp', 'ifvrn', 'icorn', 'igan', 'irgdn', 'qcn', 'iernj', 'ihrc', 'irvvn', 'cirnj', 'oiirn', 'gxrn', 'biyn', 'urln', 'pwn', 'imnl', 'irqkn', 'brpn', 'wtrn', 'ernt', 'iqnx', 'grne', 'icdn', 'irlun', 'nrjn', 'mrp', 'zhirn', 'irins', 'ijtn', 'irxg', 'ivern', 'sqrn', 'kzn', 'irlen', 'brv', 'ixg', 'ijrmn', 'qirjn', 'rijn', 'ilrw', 'ikng', 'jyn', 'ianp', 'iird', 'iydrn', 'irxna', 'rzin', 'irncx', 'idg', 'irym', 'airxn', 'iernm', 'irnve', 'xirvn', 'irmnw', 'ijo', 'irmnt', 'irhnq', 'irndx', 'irbvn', 'ifrkn', 'dln', 'lrm', 'ijrnx', 'girvn', 'iroan', 'pen', 'ijrnf', 'izrrn', 'eirnb', 'itkrn', 'irlw', 'qirt', 'iiern', 'ijcn', 'irnps', 'hirnm', 'irniz', 'ixhn', 'siern', 'iirnd', 'imrpn', 'iyorn', 'imnn', 'isrkn', 'iruin', 'iink', 'irnfl', 'iirnv', 'kirm', 'iybn', 'ilun', 'qinrn', 'jirp', 'inz', 'ikdn', 'mwrn', 'kian', 'jgn', 'iurm', 'pran', 'grna', 'iirtn', 'htn', 'virz', 'ffrn', 'cirng', 'idrns', 'ixr', 'irnel', 'imrm', 'irnjs', 'iergn', 'pwrn', 'uarn', 'izrne', 'irab', 'jirkn', 'irner', 'eiln', 'lrdn', 'irnsi', 'hrns', 'iyrun', 'ilrdn', 'irnum', 'girjn', 'igrw', 'irdnu', 'sirnr', 'nirz', 'ijrns', 'zirh', 'iaarn', 'uirnu', 'rxn', 'wrm', 'igm', 'ionj', 'irwfn', 'dilrn', 'tkrn'}\n"
          ]
        }
      ],
      "source": [
        "def generate_edits2(token):\n",
        "  \"All edits that are two edits away from `token`.\"\n",
        "  return set(e2 for e1 in generate_edits1(token) for e2 in generate_edits1(e1))\n",
        "\n",
        "print(generate_edits2('irn'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwSJiVJBMhI6"
      },
      "source": [
        "### Candidate tokens\n",
        "\n",
        "The two `generate_edits*` functions produce lots of possible tokens, but I know only a few are actually known tokens. And by known tokens, I mean tokens that I have seen in the Reddit post dataset.\n",
        "\n",
        "**Exercise:** Using the `generate_edits*` functions above, write a function `get_candidate_tokens` that given a token and the unigram counts, returns a **set** of candidate tokens that are within two edit distance and appear in the corpus.\n",
        "\n",
        "Specifically the candidate tokens should be:\n",
        "- Only the input token if it is in the corpus\n",
        "- All the tokens that are 1 or 2 edits away **and** are in the corpus\n",
        "- Only the input token if there are no other candidate tokens\n",
        "\n",
        "**Note:** If the input token is in the corpus, it should only return that token so that I don't try to correct it to something else. And if there are no tokens within two edit distances and appear , it should still return the token so that a spelling corrector is given one option to use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bd4jNiSDZb_h",
        "outputId": "2a3d0d60-da23-4450-d39b-8cd57b2a9eab"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'hello'}"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ANSWER\n",
        "\n",
        "def get_candidate_tokens(token, unigram_counts):\n",
        "  if token in unigram_counts:\n",
        "    return {token}\n",
        "\n",
        "  edits1 = [ e for e in generate_edits1(token) if e in unigram_counts ]\n",
        "  edits2 = [ e for e in generate_edits2(token) if e in unigram_counts ]\n",
        "\n",
        "  edits = edits1 + edits2\n",
        "  if edits:\n",
        "    return set(edits)\n",
        "\n",
        "  return {token}\n",
        "\n",
        "get_candidate_tokens('hellp', {'hello':1,'hi':1,'bye':1,'ahoy':1})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmFHfJxLML86",
        "outputId": "7d159939-d215-47f9-9a47-38af0587ae42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------\n",
            "LABTEST: Running 6 testcases\n",
            "----------------------------\n",
            "Input: ('tey', {'me': 1, 'sun': 3, 'heavy': 1, 'sea': 2, 'her': 1}). Running... \n",
            "Output: {'me', 'her', 'sea'}\n",
            "OK.\n",
            "\n",
            "Input: ('cofee', {'typical': 2, 'will': 2, 'come': 3, 'codes': 1}). Running... \n",
            "Output: {'come', 'codes'}\n",
            "OK.\n",
            "\n",
            "Input: ('coffee', {'spent': 3, 'coffee': 1, 'offer': 1, 'coffees': 2, 'color': 2}). Running... \n",
            "Output: {'coffee'}\n",
            "OK.\n",
            "\n",
            "Input: ('spda', {'pc': 2, 'spin': 1, 'pad': 1}). Running... \n",
            "Output: {'spin', 'pad'}\n",
            "OK.\n",
            "\n",
            "Input: ('brw', {'arm': 1, 'mystery': 2, 'dew': 3, 'filled': 2}). Running... \n",
            "Output: {'arm', 'dew'}\n",
            "OK.\n",
            "\n",
            "Input: ('cofee', {}). Running... \n",
            "Output: {'cofee'}\n",
            "OK.\n",
            "\n",
            "----------------------------\n",
            "6 testcases PASSED\n",
            "----------------------------\n"
          ]
        }
      ],
      "source": [
        "labtest(get_candidate_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMuZg9X1N2TV"
      },
      "source": [
        "Let's see what the candidates are for 'brp' using the Reddit data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFol2PBWjEH6",
        "outputId": "d66cf4bf-9658-436f-b394-2cd147c1988f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'amp',\n",
              " 'ap',\n",
              " 'app',\n",
              " 'are',\n",
              " 'arm',\n",
              " 'art',\n",
              " 'b',\n",
              " 'bad',\n",
              " 'bag',\n",
              " 'ban',\n",
              " 'bao',\n",
              " 'bar',\n",
              " 'bare',\n",
              " 'bark',\n",
              " 'barq',\n",
              " 'bars',\n",
              " 'bat',\n",
              " 'bay',\n",
              " 'bbc',\n",
              " 'bc',\n",
              " 'bd',\n",
              " 'be',\n",
              " 'bed',\n",
              " 'beg',\n",
              " 'bet',\n",
              " 'bf',\n",
              " 'bg',\n",
              " 'big',\n",
              " 'bin',\n",
              " 'bird',\n",
              " 'bit',\n",
              " 'biz',\n",
              " 'bkf',\n",
              " 'bl',\n",
              " 'blu',\n",
              " 'bob',\n",
              " 'bog',\n",
              " 'boo',\n",
              " 'born',\n",
              " 'bot',\n",
              " 'box',\n",
              " 'boy',\n",
              " 'bpm',\n",
              " 'br',\n",
              " 'brew',\n",
              " 'brim',\n",
              " 'brit',\n",
              " 'bros',\n",
              " 'brow',\n",
              " 'bru',\n",
              " 'bs',\n",
              " 'btw',\n",
              " 'bud',\n",
              " 'bug',\n",
              " 'burn',\n",
              " 'burr',\n",
              " 'bury',\n",
              " 'bus',\n",
              " 'but',\n",
              " 'buy',\n",
              " 'bw',\n",
              " 'bww',\n",
              " 'by',\n",
              " 'cap',\n",
              " 'cp',\n",
              " 'crop',\n",
              " 'cry',\n",
              " 'cup',\n",
              " 'dr',\n",
              " 'drip',\n",
              " 'drm',\n",
              " 'drop',\n",
              " 'drs',\n",
              " 'dry',\n",
              " 'earp',\n",
              " 'edp',\n",
              " 'era',\n",
              " 'erh',\n",
              " 'erm',\n",
              " 'fp',\n",
              " 'frc',\n",
              " 'fro',\n",
              " 'fry',\n",
              " 'gr',\n",
              " 'grd',\n",
              " 'grip',\n",
              " 'hop',\n",
              " 'hr',\n",
              " 'hrs',\n",
              " 'ip',\n",
              " 'ir',\n",
              " 'irc',\n",
              " 'irn',\n",
              " 'isp',\n",
              " 'jp',\n",
              " 'lp',\n",
              " 'map',\n",
              " 'mbp',\n",
              " 'mp',\n",
              " 'mr',\n",
              " 'ncp',\n",
              " 'nrs',\n",
              " 'op',\n",
              " 'or',\n",
              " 'ori',\n",
              " 'p',\n",
              " 'pb',\n",
              " 'pbr',\n",
              " 'pop',\n",
              " 'pre',\n",
              " 'pro',\n",
              " 'pry',\n",
              " 'psp',\n",
              " 'pvp',\n",
              " 'qr',\n",
              " 'r',\n",
              " 'rc',\n",
              " 're',\n",
              " 'rep',\n",
              " 'rf',\n",
              " 'rm',\n",
              " 'rn',\n",
              " 'rpg',\n",
              " 'rt',\n",
              " 'rx',\n",
              " 'sip',\n",
              " 'sp',\n",
              " 'sup',\n",
              " 'tap',\n",
              " 'tbsp',\n",
              " 'tip',\n",
              " 'top',\n",
              " 'tp',\n",
              " 'tpp',\n",
              " 'tr',\n",
              " 'trap',\n",
              " 'tri',\n",
              " 'trip',\n",
              " 'try',\n",
              " 'up',\n",
              " 'ur',\n",
              " 'ura',\n",
              " 'vip',\n",
              " 'vr',\n",
              " 'vrr',\n",
              " 'xr',\n",
              " 'yep',\n",
              " 'yr',\n",
              " 'yrs'}"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_candidate_tokens('brp', posts_unigram_counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWMyslE2OALs"
      },
      "source": [
        "### Using a language model for ranking candidates\n",
        "\n",
        "For a given misspelt token, I can now get a list of plausible tokens. I need to rank them to choose the likeliest.\n",
        "\n",
        "Enter the language model! It can give  the probability of a token, potentially taking the context into account. In the case of the unigram model, it ignores previous tokens but I know that a language model can factor in previous tokens. Let's try with the unigram model first.\n",
        "\n",
        "**Exercise:** Write a function `unigram_spelling_correct` that given a misspelled token (and unigram information), gets a list of candidate tokens, calculates their unigram probabilities and returns the candidate with the highest likelihood.\n",
        "\n",
        "You will want to use `get_candidate_tokens` and `unigram_token_prob` from before."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "qzdW5CUBauxi",
        "outputId": "f7098fb0-d8c1-41cf-92a5-1def3239ae5e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'gaming'"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ANSWER\n",
        "\n",
        "def unigram_spelling_correct(token, unigram_counts, unigram_N):\n",
        "  candidate_tokens = get_candidate_tokens(token, unigram_counts)\n",
        "\n",
        "  likeliest = max(candidate_tokens, key=lambda t:unigram_token_prob(t, unigram_counts, unigram_N))\n",
        "\n",
        "  return likeliest\n",
        "\n",
        "unigram_spelling_correct('gmaig', posts_unigram_counts, posts_unigram_N)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mtl0LTwlkwC-",
        "outputId": "a1b5cb7d-b704-4323-fefb-4dac9235989a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------\n",
            "LABTEST: Running 5 testcases\n",
            "----------------------------\n",
            "Input: ('tey', {'heavy': 1, 'sun': 3, 'her': 1, 'sea': 2, 'me': 1}, 8). Running... \n",
            "Output: sea\n",
            "OK.\n",
            "\n",
            "Input: ('cofee', {'will': 2, 'codes': 2, 'come': 3, 'typical': 1}, 8). Running... \n",
            "Output: come\n",
            "OK.\n",
            "\n",
            "Input: ('coffee', {'offer': 3, 'coffee': 1, 'coffees': 1, 'spent': 2, 'color': 2}, 9). Running... \n",
            "Output: coffee\n",
            "OK.\n",
            "\n",
            "Input: ('spda', {'spin': 2, 'pad': 1, 'pc': 1}, 4). Running... \n",
            "Output: spin\n",
            "OK.\n",
            "\n",
            "Input: ('brw', {'mystery': 1, 'filled': 2, 'dew': 3, 'arm': 2}, 8). Running... \n",
            "Output: dew\n",
            "OK.\n",
            "\n",
            "----------------------------\n",
            "5 testcases PASSED\n",
            "----------------------------\n"
          ]
        }
      ],
      "source": [
        "labtest(unigram_spelling_correct)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnLb1hI4cyYi"
      },
      "source": [
        "Excellent, now let's step through how the spelling correction is being done for an example token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRV-SUcO6DJH",
        "outputId": "109a3f34-13bc-475e-c5e7-9a73776ad131"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Spelling candidates for: gmaig\n",
            "gang\t0.0000053\n",
            "grain\t0.0000053\n",
            "gain\t0.0000211\n",
            "email\t0.0000686\n",
            "gtaiv\t0.0000106\n",
            "mail\t0.0001214\n",
            "main\t0.0002376\n",
            "gaming\t0.0005015\n",
            "\n",
            "Selected correction: gaming\n"
          ]
        }
      ],
      "source": [
        "token = \"gmaig\"\n",
        "#token = TRY YOUR WORD\n",
        "\n",
        "candidates = get_candidate_tokens(token, posts_unigram_counts)\n",
        "print(\"Spelling candidates for:\", token)\n",
        "for candidate in candidates:\n",
        "  p = unigram_token_prob(candidate, posts_unigram_counts, posts_unigram_N)\n",
        "  print(f\"{candidate}\\t{p:.7f}\")\n",
        "\n",
        "# The correction takes the token that has the highest probability (occurs most often).\n",
        "correction = unigram_spelling_correct(token, posts_unigram_counts, posts_unigram_N)\n",
        "print(f\"\\nSelected correction: {correction}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7rrpbrcXecGz"
      },
      "source": [
        "Woohoo! I have a very basic reddit spelling corrector.\n",
        "Try it yourself on other words.\n",
        "\n",
        "However, as  see it's not perfect.  Let's look at a few sequences below and see what it does to each token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6fMOvSyCJL6",
        "outputId": "5be310dc-c7c8-4572-c834-74554b8e9c47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "it is amazon ['it', 'is', 'amazon']\n",
            "http www amazin ['help', 'was', 'again']\n"
          ]
        }
      ],
      "source": [
        "strings = [\"it is amazon\", \"http www amazin\"]\n",
        "for s in strings:\n",
        "  tokens = text_pipeline_spacy_special(s)\n",
        "  corrections = []\n",
        "  for t in tokens:\n",
        "    correction = unigram_spelling_correct(t, posts_unigram_counts, posts_unigram_N)\n",
        "    corrections.append(correction)\n",
        "  print(s, corrections)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKbC0-w0et6F"
      },
      "source": [
        "Not so 'amazing'. In both of these cases, I estimated the likelihood of spelling correcting each word on its own,  independently.  This fails in obvious cases where the correct word should be apparent given the sequence.\n",
        "\n",
        "I can do better by taking two factors into account:\n",
        "\n",
        "1. Computing the probability of the whole sequence of token (in case there are multiple spelling mistakes)\n",
        "2. Using token context (bi-grams and trigrams) to improve the token probability estimate\n",
        "\n",
        " look at the second idea in the following sections."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRslwUFqDn_t"
      },
      "source": [
        "## N-Gram Language Models\n",
        "\n",
        "The unigram model isn't a very good one - it doesn't model any previous context. On the other hand, I can't model _all_ of the preceding tokens, because that history will get prohibitively long and extremely sparse. As a compromise, I make a _Markov assumption_ and limit ourselves to a finite history of $n$ tokens.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OpxWsOoFf1F"
      },
      "source": [
        "### Constructing a bigram model\n",
        "\n",
        "For now,  build a bigram model, which considers only the preceding token:\n",
        "\n",
        "$$ P(w_i\\ |\\ w_{0}, ..., w_{i-1}) \\approx P(w_i\\ |\\ w_{i-1}) $$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gC5tanICEigU"
      },
      "source": [
        "\n",
        "I want to calculate the probability of one token following the other using the counts of that bigram $C_{ab}$ and the count of the first token $C_a$.\n",
        "\n",
        "$$  P_{ab} = P(w_i = b\\ |\\ w_{i-1} = a) = \\frac{C_{ab}}{C_{a}} $$\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObV3pvpupK47"
      },
      "source": [
        "Before I can generate probabilities from bigrams, I need to know the frequency that bigrams appear in the data.\n",
        "\n",
        "**Exercise:** Write a function `count_bigrams` that given a flattened list of tokens returns a [Counter](https://docs.python.org/3/library/collections.html#collections.Counter) mapping tuples (pairs of neighbouring tokens) to their count in the tokens.\n",
        "\n",
        "For example `count_bigrams(['a','b','c'])` should give a Counter with values `{ ('a','b'):1, ('b','c'):1 }`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4EmDhxjfAc7",
        "outputId": "e673e56b-8c5b-466b-9842-44ae896d463e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Counter({('<START>', 'irn'): 1,\n",
              "         ('irn', 'bru'): 2,\n",
              "         ('bru', 'is'): 1,\n",
              "         ('is', 'great'): 1,\n",
              "         ('great', '<START>'): 1,\n",
              "         ('<START>', 'i'): 1,\n",
              "         ('i', 'dislike'): 1,\n",
              "         ('dislike', 'irn'): 1})"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ANSWER\n",
        "\n",
        "def count_bigrams(flattened):\n",
        "  bigram_counts = Counter()\n",
        "  for a,b in zip(flattened, flattened[1:]):\n",
        "    bigram_counts[(a,b)] += 1\n",
        "  return bigram_counts\n",
        "\n",
        "count_bigrams(['<START>','irn','bru','is','great','<START>','i','dislike','irn','bru'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDDFIxos7NMy",
        "outputId": "271b99c9-b2bf-46da-d90f-54a298725840"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------\n",
            "LABTEST: Running 5 testcases\n",
            "----------------------------\n",
            "Input: (['accidentally', 'halo', 'halo', 'halo'],). Running... \n",
            "Output: {('accidentally', 'halo'): 1, ('halo', 'halo'): 2}\n",
            "OK.\n",
            "\n",
            "Input: (['teavana', 'teavana', 'order'],). Running... \n",
            "Output: {('teavana', 'teavana'): 1, ('teavana', 'order'): 1}\n",
            "OK.\n",
            "\n",
            "Input: (['started', 'enough', 'enough', 'started', 'enough', 'enough'],). Running... \n",
            "Output: {('started', 'enough'): 2, ('enough', 'enough'): 2, ('enough', 'started'): 1}\n",
            "OK.\n",
            "\n",
            "Input: (['hario', 'hario', 'lead'],). Running... \n",
            "Output: {('hario', 'hario'): 1, ('hario', 'lead'): 1}\n",
            "OK.\n",
            "\n",
            "Input: (['similar', 'college', 'similar'],). Running... \n",
            "Output: {('similar', 'college'): 1, ('college', 'similar'): 1}\n",
            "OK.\n",
            "\n",
            "----------------------------\n",
            "5 testcases PASSED\n",
            "----------------------------\n"
          ]
        }
      ],
      "source": [
        "labtest(count_bigrams)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4yuV3JI7Pko"
      },
      "source": [
        "I can get the bigrams of the mini corpus:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUfyE6K6h-E6",
        "outputId": "a2e17e72-7eef-40ad-b4bd-d4e7c4d7c1cb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Counter({('<START>', 'my'): 1,\n",
              "         ('my', 'favourite'): 1,\n",
              "         ('favourite', 'soft'): 1,\n",
              "         ('soft', 'drink'): 2,\n",
              "         ('drink', 'is'): 1,\n",
              "         ('is', 'apple'): 1,\n",
              "         ('apple', 'tango'): 1,\n",
              "         ('tango', 'but'): 1,\n",
              "         ('but', 'i'): 1,\n",
              "         ('i', 'also'): 1,\n",
              "         ('also', 'love'): 1,\n",
              "         ('love', 'irn'): 1,\n",
              "         ('irn', 'bru'): 5,\n",
              "         ('bru', '<START>'): 1,\n",
              "         ('<START>', 'irn'): 3,\n",
              "         ('bru', 'is'): 3,\n",
              "         ('is', 'a'): 2,\n",
              "         ('a', 'great'): 1,\n",
              "         ('great', 'drink'): 1,\n",
              "         ('drink', '<START>'): 1,\n",
              "         ('<START>', 'i'): 1,\n",
              "         ('i', 'once'): 1,\n",
              "         ('once', 'found'): 1,\n",
              "         ('found', 'a'): 1,\n",
              "         ('a', 'can'): 1,\n",
              "         ('can', 'of'): 1,\n",
              "         ('of', 'irn'): 1,\n",
              "         ('bru', 'in'): 1,\n",
              "         ('in', 'st'): 1,\n",
              "         ('st', 'petersburg'): 1,\n",
              "         ('petersburg', '<START>'): 1,\n",
              "         ('a', 'soft'): 1,\n",
              "         ('drink', 'launched'): 1,\n",
              "         ('launched', 'in'): 1,\n",
              "         ('in', '1901'): 1,\n",
              "         ('1901', 'by'): 1,\n",
              "         ('by', 'ag'): 1,\n",
              "         ('ag', 'barr'): 2,\n",
              "         ('barr', '<START>'): 1,\n",
              "         ('is', 'made'): 1,\n",
              "         ('made', 'at'): 1,\n",
              "         ('at', 'ag'): 1,\n",
              "         ('barr', 'in'): 1,\n",
              "         ('in', 'cumbernauld'): 1})"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count_bigrams(mini_flattened)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXKcWmzG7UL4"
      },
      "source": [
        "Let's calculate the bigrams for the Reddit posts. This will be useful!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UlF914RYkEp4"
      },
      "outputs": [],
      "source": [
        "posts_bigram_counts = count_bigrams(posts_flattened_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbfJQJU27Xrm"
      },
      "source": [
        "Now I have a method for bigram counts, I can calculate the probability of a next word, given the previous token:\n",
        "\n",
        "$$ P(w_i \\ |\\ w_{i-1} ) $$\n",
        "\n",
        "Specifically for the probability for token $b$ following token $a$:\n",
        "\n",
        "$$  P_{ab} = P(w_i = b\\ |\\ w_{i-1} = a) = \\frac{C_{ab}}{C_{a}} $$\n",
        "\n",
        "where $C_{ab}$ is the bigram count of $(a,b)$ and $C_a$ is the unigram count of $a$.\n",
        "\n",
        "**Exercise:** Write a function `bigram_token_prob` that takes in the previous token, the next token and the unigram and bigram counts and calculates the conditional probability of the next token given the previous token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEn6cYwVj9Ou",
        "outputId": "fb97aab6-c64a-4408-c75e-964c567be393"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ANSWER\n",
        "\n",
        "def bigram_token_prob(prev_token, next_token, unigram_counts, bigram_counts):\n",
        "  return bigram_counts[(prev_token,next_token)] / unigram_counts[prev_token]\n",
        "\n",
        "bigram_token_prob('irn', 'bru', posts_unigram_counts, posts_bigram_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DwHbsQOoBnY4",
        "outputId": "59eeef38-2663-49f1-cbda-f5f7a0247528"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------\n",
            "LABTEST: Running 5 testcases\n",
            "----------------------------\n",
            "Input: ('a', 'b', {'a': 8, 'b': 7}, {('a', 'a'): 2, ('a', 'b'): 2, ('b', 'a'): 4, ('b', 'b'): 3}). Running... \n",
            "Output: 0.25\n",
            "OK.\n",
            "\n",
            "Input: ('b', 'b', {'a': 8, 'b': 9}, {('a', 'a'): 1, ('a', 'b'): 2, ('b', 'a'): 1, ('b', 'b'): 4}). Running... \n",
            "Output: 0.44444\n",
            "OK.\n",
            "\n",
            "Input: ('a', 'b', {'a': 7, 'b': 6}, {('a', 'a'): 3, ('a', 'b'): 1, ('b', 'a'): 1, ('b', 'b'): 1}). Running... \n",
            "Output: 0.14286\n",
            "OK.\n",
            "\n",
            "Input: ('a', 'b', {'a': 7, 'b': 6}, {('a', 'a'): 1, ('a', 'b'): 3, ('b', 'a'): 4, ('b', 'b'): 2}). Running... \n",
            "Output: 0.42857\n",
            "OK.\n",
            "\n",
            "Input: ('a', 'b', {'a': 5, 'b': 5}, {('a', 'a'): 1, ('a', 'b'): 2, ('b', 'a'): 2, ('b', 'b'): 1}). Running... \n",
            "Output: 0.4\n",
            "OK.\n",
            "\n",
            "----------------------------\n",
            "5 testcases PASSED\n",
            "----------------------------\n"
          ]
        }
      ],
      "source": [
        "labtest(bigram_token_prob)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Za8mdM5c8xQq"
      },
      "source": [
        "### Using bigrams for spelling correction\n",
        "\n",
        " use the bigram model to improve the spelling correction model. This time it will use the prior token to give some context to the probability calculations.\n",
        "\n",
        "**Exercise:** Write a function `bigram_spelling_correct` that takes in the previous token, the token to be spell-checked, the unigram/bigram counts and uses the bigram probability function (from above) to find the most likely token. Look back at your `unigram_spelling_correct` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "WmZv74ZXl6Tj",
        "outputId": "48d243c8-6aae-4943-d3f5-4b1dfed5e784"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'bru'"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ANSWER\n",
        "\n",
        "def bigram_spelling_correct(prev_token, token, unigram_counts, bigram_counts):\n",
        "  candidate_tokens = get_candidate_tokens(token, unigram_counts)\n",
        "\n",
        "  likeliest = max(candidate_tokens, key=lambda t:bigram_token_prob(prev_token, t, unigram_counts, bigram_counts))\n",
        "\n",
        "  return likeliest\n",
        "\n",
        "bigram_spelling_correct('irn', 'burp', posts_unigram_counts, posts_bigram_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OuipSIjJ-rdU",
        "outputId": "645f4cb0-0590-48a2-b9f4-aebc23ec93fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------\n",
            "LABTEST: Running 5 testcases\n",
            "----------------------------\n",
            "Input: ('i', 'hcacn', Counter({'where': 7, 'i': 6, 'can': 6}), Counter({('i', 'can'): 4, ('where', 'i'): 3})). Running... \n",
            "Output: can\n",
            "OK.\n",
            "\n",
            "Input: ('the', 'owvnyr', Counter({'the': 9, 'and': 8, 'owner': 5}), Counter({('and', 'the'): 2, ('the', 'owner'): 1})). Running... \n",
            "Output: owner\n",
            "OK.\n",
            "\n",
            "Input: ('life', 'gtze', Counter({'life': 7, 'her': 6, 'the': 6}), Counter({('her', 'life'): 3, ('life', 'the'): 1})). Running... \n",
            "Output: the\n",
            "OK.\n",
            "\n",
            "Input: ('it', 's', Counter({'it': 8, 'is': 7, 'says': 5}), Counter({('it', 'is'): 2, ('says', 'it'): 1})). Running... \n",
            "Output: is\n",
            "OK.\n",
            "\n",
            "Input: ('as', 'hmcin', Counter({'main': 9, 'linked': 8, 'as': 6}), Counter({('as', 'main'): 1, ('linked', 'as'): 1})). Running... \n",
            "Output: main\n",
            "OK.\n",
            "\n",
            "----------------------------\n",
            "5 testcases PASSED\n",
            "----------------------------\n"
          ]
        }
      ],
      "source": [
        "labtest(bigram_spelling_correct)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reOHTEDz-sa4"
      },
      "source": [
        "Let's try the 'gmaig' example from before (which previously was corrected to 'gaming'). What if I give it another context. Maybe the token before it is 'e'? How does that change it?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "tKwzswAm-sh4",
        "outputId": "c6341342-ad05-4f15-ba7f-d3a92b697892"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'mail'"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bigram_spelling_correct('e', 'gmaig', posts_unigram_counts, posts_bigram_counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NbFZUbM_C1h"
      },
      "source": [
        "Neat! With a different context, the most likely token changes.\n",
        "\n",
        "A bigram model gave some context. Maybe a trigram model would be better. Well,  going to look at trigrams, but for a different problem!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZbqWAJFJ_qP"
      },
      "source": [
        "## Application: Generating fake Reddit posts\n",
        "\n",
        "Language models are *generative*.  They model the probability of generating a sequence of tokens. The probabilities can be used in interesting ways, for example to score sequences or even to generate made up text sequences iteratively.\n",
        "\n",
        " going to use trigrams to capture a bit more about language and use them to generate some fake Reddit posts. To get started, I need to calculate trigram counts.\n",
        "\n",
        "**Exercise:** Write a function `count_trigrams` that returns a Counter that contains the counts of all trigrams from the input text.\n",
        "\n",
        "For example `count_trigrams(['a','b','c','d'])` should give a Counter with values `{ ('a','b','c'):1, ('b','c','d'):1 }`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ixlhi6djoZZx",
        "outputId": "87fc98e1-0f2a-488e-e0e0-f243844a45b7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Counter({('<START>', 'irn', 'bru'): 1,\n",
              "         ('irn', 'bru', 'is'): 1,\n",
              "         ('bru', 'is', 'great'): 1,\n",
              "         ('is', 'great', '<START>'): 1,\n",
              "         ('great', '<START>', 'i'): 1,\n",
              "         ('<START>', 'i', 'dislike'): 1,\n",
              "         ('i', 'dislike', 'irn'): 1,\n",
              "         ('dislike', 'irn', 'bru'): 1})"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ANSWER\n",
        "\n",
        "def count_trigrams(flattened):\n",
        "  trigram_counts = Counter()\n",
        "  for a,b,c in zip(flattened, flattened[1:],flattened[2:]):\n",
        "    trigram_counts[(a,b,c)] += 1\n",
        "  return trigram_counts\n",
        "\n",
        "count_trigrams(['<START>','irn','bru','is','great','<START>','i','dislike','irn','bru'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTORvdhFFUD0",
        "outputId": "20ae75ad-c2e0-41cb-9877-d39d899da07c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------\n",
            "LABTEST: Running 5 testcases\n",
            "----------------------------\n",
            "Input: (['accidentally', 'halo', 'halo', 'halo'],). Running... \n",
            "Output: {('accidentally', 'halo', 'halo'): 1, ('halo', 'halo', 'halo'): 1}\n",
            "OK.\n",
            "\n",
            "Input: (['teavana', 'teavana', 'order'],). Running... \n",
            "Output: {('teavana', 'teavana', 'order'): 1}\n",
            "OK.\n",
            "\n",
            "Input: (['started', 'enough', 'enough', 'started', 'enough', 'enough'],). Running... \n",
            "Output: {('started', 'enough', 'enough'): 2, ('enough', 'enough', 'started'): 1, ('enough', 'started', 'enough'): 1}\n",
            "OK.\n",
            "\n",
            "Input: (['hario', 'hario', 'lead'],). Running... \n",
            "Output: {('hario', 'hario', 'lead'): 1}\n",
            "OK.\n",
            "\n",
            "Input: (['similar', 'college', 'similar'],). Running... \n",
            "Output: {('similar', 'college', 'similar'): 1}\n",
            "OK.\n",
            "\n",
            "----------------------------\n",
            "5 testcases PASSED\n",
            "----------------------------\n"
          ]
        }
      ],
      "source": [
        "labtest(count_trigrams)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "doh2Tc-8Fc-Z"
      },
      "source": [
        "Let's get the trigrams from the Reddit posts:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xn79VVtzqPDF"
      },
      "outputs": [],
      "source": [
        "posts_trigram_counts = count_trigrams(posts_flattened_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsvdRnxpFiIC"
      },
      "source": [
        "Now, I need a function that gets  the conditional trigram probability. What is the probability of a token given the two previous tokens?\n",
        "\n",
        "$$ P(w_i \\ |\\ w_{i-1}, w_{i-2} ) $$\n",
        "\n",
        "In this case, I want to calculate the probability of a trigram using the trigram count for that triple and the bigram count of the first two tokens.\n",
        "\n",
        "**Exercise:** Write a function `trigram_token_prob` that takes in the two previous tokens, the next token and the bigram & trigram count data. It should output the probability of the next token given the two prior tokens using the bigram and trigram counts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7KuBiHmspmox",
        "outputId": "b275cbc7-291f-426d-f1df-a5cddb3b31ab"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ANSWER\n",
        "def trigram_token_prob(prev_prev_token, prev_token, next_token, bigram_counts, trigram_counts):\n",
        "  return trigram_counts[(prev_prev_token,prev_token,next_token)] / bigram_counts[(prev_prev_token,prev_token)]\n",
        "\n",
        "trigram_token_prob('i', 'walk', 'around', posts_bigram_counts, posts_trigram_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUr1JeDLojR9",
        "outputId": "bb2546a4-8d91-4aa0-d7c3-16ae011da56e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------\n",
            "LABTEST: Running 5 testcases\n",
            "----------------------------\n",
            "Input: ('c', 'a', 'a', Counter({('a', 'a'): 5, ('c', 'a'): 3, ('c', 'c'): 3}), Counter({('c', 'a', 'a'): 1, ('c', 'c', 'a'): 1})). Running... \n",
            "Output: 0.33333\n",
            "OK.\n",
            "\n",
            "Input: ('a', 'c', 'a', Counter({('a', 'a'): 4, ('a', 'c'): 4, ('c', 'a'): 4}), Counter({('a', 'a', 'c'): 1, ('a', 'c', 'a'): 1})). Running... \n",
            "Output: 0.25\n",
            "OK.\n",
            "\n",
            "Input: ('a', 'b', 'c', Counter({('a', 'a'): 5, ('a', 'b'): 4, ('b', 'c'): 4, ('c', 'a'): 4}), Counter({('a', 'b', 'c'): 2, ('c', 'a', 'a'): 2, ('a', 'a', 'b'): 1})). Running... \n",
            "Output: 0.5\n",
            "OK.\n",
            "\n",
            "Input: ('c', 'b', 'b', Counter({('a', 'a'): 5, ('a', 'c'): 4, ('c', 'b'): 4, ('b', 'b'): 3}), Counter({('a', 'c', 'b'): 2, ('c', 'b', 'b'): 2, ('a', 'a', 'c'): 1})). Running... \n",
            "Output: 0.5\n",
            "OK.\n",
            "\n",
            "Input: ('a', 'b', 'b', Counter({('a', 'b'): 5, ('b', 'b'): 3}), Counter({('a', 'b', 'b'): 2})). Running... \n",
            "Output: 0.4\n",
            "OK.\n",
            "\n",
            "----------------------------\n",
            "5 testcases PASSED\n",
            "----------------------------\n"
          ]
        }
      ],
      "source": [
        "labtest(trigram_token_prob)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVpnGeevGFH2"
      },
      "source": [
        "I want to get the probability of all possible tokens after two previous tokens.  store this probability distribution as a dictionary mapping a potential token to its probabilities.\n",
        "\n",
        "The `get_trigram_distribution` below iterates through all the possible tokens (which are all the unigrams) and calculates their conditional trigram probability."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j1taysLdrMVM"
      },
      "outputs": [],
      "source": [
        "def get_trigram_distribution(prev_prev_token, prev_token, unigram_counts, bigram_counts, trigram_counts):\n",
        "  prob_distribution = {}\n",
        "  for token in unigram_counts:\n",
        "    p = trigram_token_prob(prev_prev_token, prev_token, token, bigram_counts, trigram_counts)\n",
        "    prob_distribution[token] = p\n",
        "  return prob_distribution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDDdhGm1HFcc"
      },
      "source": [
        "Let's see what the distribution looks like for a sequence starting \"i like\":"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFp-8T6vGypx",
        "outputId": "1478e227-4834-4654-dc35-d9d1b67bb9f5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'<START>': 0.0,\n",
              " 'anyone': 0.0,\n",
              " 'tried': 0.0,\n",
              " 'irn': 0.0,\n",
              " 'bru': 0.0,\n",
              " 'it': 0.0784313725490196,\n",
              " '’s': 0.0,\n",
              " 'a': 0.058823529411764705,\n",
              " 'scottish': 0.0,\n",
              " 'drink': 0.0,\n",
              " 'and': 0.0,\n",
              " 'banned': 0.0,\n",
              " 'some': 0.0,\n",
              " 'countries': 0.0,\n",
              " 'i': 0.0196078431372549,\n",
              " 'was': 0.0,\n",
              " 'wondering': 0.0,\n",
              " 'if': 0.0,\n",
              " 'here': 0.0,\n",
              " 'has': 0.0,\n",
              " 'quite': 0.0,\n",
              " 'unique': 0.0,\n",
              " 'taste': 0.0,\n",
              " 'not': 0.0,\n",
              " 'something': 0.0,\n",
              " 'you': 0.0,\n",
              " '’d': 0.0,\n",
              " 'forget': 0.0,\n",
              " 'quickly': 0.0,\n",
              " 'either': 0.0,\n",
              " 'love': 0.0,\n",
              " 'or': 0.0,\n",
              " 'hate': 0.0,\n",
              " 'think': 0.0,\n",
              " 'what': 0.0196078431372549,\n",
              " 'is': 0.0,\n",
              " 'the': 0.13725490196078433,\n",
              " 'worst': 0.0,\n",
              " 'of': 0.0,\n",
              " 'sodas': 0.0,\n",
              " 'have': 0.0,\n",
              " 'drunk': 0.0,\n",
              " 'absolute': 0.0,\n",
              " 'soda': 0.0,\n",
              " 've': 0.0,\n",
              " 'ever': 0.0,\n",
              " 'had': 0.0,\n",
              " 'that': 0.0,\n",
              " 'can': 0.0,\n",
              " 'remember': 0.0,\n",
              " 'probaly': 0.0,\n",
              " 'new': 0.0196078431372549,\n",
              " 'mystery': 0.0,\n",
              " 'fanta': 0.0,\n",
              " 'watermelon+strawberry': 0.0,\n",
              " 'tango': 0.0,\n",
              " 'other': 0.0,\n",
              " 'ones': 0.0,\n",
              " 'include': 0.0,\n",
              " 'mango': 0.0,\n",
              " 'coke': 0.0,\n",
              " 'sugar': 0.0,\n",
              " 'free': 0.0,\n",
              " 'but': 0.0,\n",
              " 'xtra': 0.0,\n",
              " 'nice': 0.0,\n",
              " 'once': 0.0,\n",
              " 'box': 0.0,\n",
              " 'tea': 0.0196078431372549,\n",
              " 'believe': 0.0,\n",
              " 'highland': 0.0,\n",
              " 'black': 0.0196078431372549,\n",
              " 'recommend': 0.0,\n",
              " 'me': 0.0,\n",
              " 'along': 0.0,\n",
              " 'those': 0.0,\n",
              " 'lines': 0.0,\n",
              " \"'d\": 0.0,\n",
              " 'like': 0.0,\n",
              " 'to': 0.17647058823529413,\n",
              " 'repurchase': 0.0,\n",
              " 'this': 0.0196078431372549,\n",
              " 'find': 0.0,\n",
              " 'exact': 0.0,\n",
              " 'do': 0.0,\n",
              " \"n't\": 0.0,\n",
              " 'want': 0.0,\n",
              " 'buy': 0.0,\n",
              " 'am': 0.0,\n",
              " 'sure': 0.0,\n",
              " 'will': 0.0,\n",
              " 'be': 0.0,\n",
              " 'good': 0.0,\n",
              " \"ddos'd\": 0.0,\n",
              " 'my': 0.0,\n",
              " 'city': 0.0,\n",
              " 'named': 0.0,\n",
              " 'kicked': 0.0,\n",
              " 'from': 0.0,\n",
              " 'party': 0.0,\n",
              " 'by': 0.0,\n",
              " 'person': 0.0,\n",
              " 'who': 0.0,\n",
              " 'leader': 0.0,\n",
              " 'nor': 0.0,\n",
              " 'he': 0.0,\n",
              " 'in': 0.0,\n",
              " 'hi': 0.0,\n",
              " 'question': 0.0,\n",
              " 'someone': 0.0,\n",
              " 'joined': 0.0,\n",
              " 'our': 0.0,\n",
              " '1': 0.0,\n",
              " 'said': 0.0,\n",
              " 'state': 0.0,\n",
              " 'live': 0.0,\n",
              " 'smaller': 0.0,\n",
              " 'goes': 0.0,\n",
              " 'big': 0.0,\n",
              " 'so': 0.0,\n",
              " 'name': 0.0,\n",
              " 'specific': 0.0,\n",
              " 'scary': 0.0,\n",
              " 'say': 0.0,\n",
              " 'least': 0.0,\n",
              " '2': 0.0,\n",
              " 'kept': 0.0,\n",
              " 'kicking': 0.0,\n",
              " 'us': 0.0,\n",
              " 'out': 0.0,\n",
              " 'despite': 0.0,\n",
              " 'fact': 0.0,\n",
              " 'most': 0.0,\n",
              " 'definitely': 0.0,\n",
              " 'being': 0.0,\n",
              " 'done': 0.0,\n",
              " 'kid': 0.0,\n",
              " 'supposed': 0.0,\n",
              " 'when': 0.0,\n",
              " 'happens': 0.0,\n",
              " 'than': 0.0,\n",
              " 'report': 0.0,\n",
              " 'there': 0.0,\n",
              " 'any': 0.0,\n",
              " 'recourse': 0.0,\n",
              " 'hun': 0.0,\n",
              " 'really': 0.0,\n",
              " 'running': 0.0,\n",
              " 'small': 0.0,\n",
              " 'business': 0.0,\n",
              " 'then': 0.0,\n",
              " 'surely': 0.0,\n",
              " 'they': 0.0,\n",
              " 'comply': 0.0,\n",
              " 'with': 0.0,\n",
              " 'gdpr': 0.0,\n",
              " 'which': 0.0,\n",
              " 'means': 0.0,\n",
              " 'no': 0.0,\n",
              " 'contact': 0.0,\n",
              " 'unless': 0.0,\n",
              " 'previously': 0.0,\n",
              " 'stipulated': 0.0,\n",
              " 'help': 0.0,\n",
              " \"'m\": 0.0,\n",
              " 'super': 0.0196078431372549,\n",
              " 'dehydrated': 0.0,\n",
              " 'ca': 0.0,\n",
              " 'fet': 0.0,\n",
              " 'myself': 0.0,\n",
              " 'more': 0.0,\n",
              " 'used': 0.0,\n",
              " 'specialized': 0.0,\n",
              " 'scale': 0.0,\n",
              " 'only': 0.0,\n",
              " '54': 0.0,\n",
              " 'water': 0.0,\n",
              " 'instead': 0.0,\n",
              " '70': 0.0,\n",
              " 'how': 0.0196078431372549,\n",
              " 'force': 0.0,\n",
              " 'where': 0.0,\n",
              " 'source': 0.0,\n",
              " \"pu'er\": 0.0,\n",
              " 'early': 0.0,\n",
              " '90': 0.0,\n",
              " \"'s\": 0.0,\n",
              " 'found': 0.0,\n",
              " 'lots': 0.0,\n",
              " 'apparently': 0.0,\n",
              " 'online': 0.0,\n",
              " 'however': 0.0,\n",
              " 'know': 0.0,\n",
              " 'sites': 0.0,\n",
              " 'companies': 0.0,\n",
              " 'trust': 0.0,\n",
              " 'looking': 0.0,\n",
              " 'for': 0.0,\n",
              " 'an': 0.0,\n",
              " 'anniversary': 0.0,\n",
              " 'present': 0.0,\n",
              " 'would': 0.0,\n",
              " 'grown': 0.0,\n",
              " 'processed': 0.0,\n",
              " '1991': 0.0,\n",
              " 'as': 0.0,\n",
              " 'close': 0.0,\n",
              " 'possible': 0.0,\n",
              " 'advice': 0.0,\n",
              " 'on': 0.0,\n",
              " 'helpful': 0.0,\n",
              " 'based': 0.0,\n",
              " 'uk': 0.0,\n",
              " 'ship': 0.0,\n",
              " 'without': 0.0,\n",
              " 'too': 0.0,\n",
              " 'much': 0.0,\n",
              " 'trouble': 0.0,\n",
              " 'great': 0.0,\n",
              " 'thanks': 0.0,\n",
              " 'day': 0.0,\n",
              " 'tapping': 0.0,\n",
              " 'tapir': 0.0,\n",
              " '\\u200b': 0.0,\n",
              " '12': 0.0,\n",
              " 'flavours': 0.0,\n",
              " 'sparkling': 0.0,\n",
              " 'tasted': 0.0,\n",
              " 'amazing': 0.0,\n",
              " 'artwork': 0.0,\n",
              " 'design': 0.0,\n",
              " 'these': 0.0196078431372549,\n",
              " 'cans': 0.0,\n",
              " 'are': 0.0,\n",
              " 'did': 0.0,\n",
              " 'opened': 0.0,\n",
              " 'each': 0.0,\n",
              " 'yet': 0.0,\n",
              " 'hibiscus': 0.0,\n",
              " 'lime': 0.0,\n",
              " 'flower': 0.0,\n",
              " 'flavour': 0.0,\n",
              " 'please': 0.0,\n",
              " 'game': 0.0,\n",
              " '10': 0.0,\n",
              " 'years': 0.0,\n",
              " 'ago': 0.0,\n",
              " 'loved': 0.0,\n",
              " 'n’t': 0.0,\n",
              " 'now': 0.0,\n",
              " 'show': 0.0,\n",
              " 'battle': 0.0,\n",
              " 'royale': 0.0,\n",
              " 'thing': 0.0,\n",
              " 'all': 0.0392156862745098,\n",
              " 'contestants': 0.0,\n",
              " 'killed': 0.0,\n",
              " 'prize': 0.0,\n",
              " 'characters': 0.0,\n",
              " 'naked': 0.0,\n",
              " 'lady': 0.0,\n",
              " 'purple': 0.0,\n",
              " 'penguin': 0.0,\n",
              " 'eugene': 0.0,\n",
              " 'little': 0.0,\n",
              " 'rich': 0.0,\n",
              " 'girl': 0.0,\n",
              " 'charity': 0.0,\n",
              " 'just': 0.0,\n",
              " 'need': 0.0,\n",
              " 'thank': 0.0,\n",
              " 'got': 0.0,\n",
              " 'xbox': 0.0,\n",
              " 'series': 0.0,\n",
              " 's': 0.0,\n",
              " 'type': 0.0,\n",
              " 'since': 0.0,\n",
              " '360': 0.0,\n",
              " 'pretty': 0.0,\n",
              " 'make': 0.0,\n",
              " 'account': 0.0,\n",
              " 'before': 0.0,\n",
              " 'even': 0.0,\n",
              " 'turn': 0.0,\n",
              " 'system': 0.0,\n",
              " 'could': 0.0,\n",
              " 'go': 0.0,\n",
              " 'website': 0.0,\n",
              " '’m': 0.0,\n",
              " 'bottle': 0.0,\n",
              " 'get': 0.0,\n",
              " 'mine': 0.0,\n",
              " 'cheap': 0.0,\n",
              " 'broken': 0.0,\n",
              " 'caffeine': 0.0,\n",
              " 'shortage': 0.0,\n",
              " 'nos': 0.0,\n",
              " 'certain': 0.0,\n",
              " 'drinks': 0.0,\n",
              " 'stock': 0.0,\n",
              " 'started': 0.0,\n",
              " 'over': 0.0,\n",
              " 'labor': 0.0,\n",
              " 'holiday': 0.0,\n",
              " 'visiting': 0.0,\n",
              " 'parents': 0.0,\n",
              " 'two': 0.0,\n",
              " 'separate': 0.0,\n",
              " 'royal': 0.0,\n",
              " 'farms': 0.0,\n",
              " 'convenience': 0.0,\n",
              " 'stores': 0.0,\n",
              " 'went': 0.0,\n",
              " 'turbo': 0.0,\n",
              " 'available': 0.0,\n",
              " 'shelves': 0.0,\n",
              " 'flavors': 0.0,\n",
              " 'varieties': 0.0,\n",
              " 'were': 0.0,\n",
              " 'empty': 0.0,\n",
              " 'caused': 0.0,\n",
              " 'look': 0.0,\n",
              " 'notice': 0.0,\n",
              " 'several': 0.0,\n",
              " 'open': 0.0196078431372549,\n",
              " 'slots': 0.0,\n",
              " 'around': 0.0,\n",
              " 'refrigerator': 0.0,\n",
              " 'case': 0.0,\n",
              " 'peninsula': 0.0,\n",
              " 'at': 0.0,\n",
              " 'beach': 0.0,\n",
              " 'chalked': 0.0,\n",
              " 'up': 0.0,\n",
              " 'distribution': 0.0,\n",
              " 'issues': 0.0,\n",
              " 'locally': 0.0,\n",
              " 'back': 0.0,\n",
              " 'home': 0.0,\n",
              " 'still': 0.0,\n",
              " 'seeing': 0.0,\n",
              " 'rows': 0.0,\n",
              " 'local': 0.0,\n",
              " 'sheetz': 0.0,\n",
              " 'longer': 0.0,\n",
              " 'pick': 0.0,\n",
              " '8': 0.0,\n",
              " 'pack': 0.0,\n",
              " 'grocery': 0.0,\n",
              " 'store': 0.0,\n",
              " 'granted': 0.0,\n",
              " 'always': 0.0,\n",
              " 'been': 0.0,\n",
              " 'hit': 0.0,\n",
              " 'miss': 0.0,\n",
              " 'about': 0.0196078431372549,\n",
              " 'keeping': 0.0,\n",
              " 'poor': 0.0,\n",
              " 'inventory': 0.0,\n",
              " 'management': 0.0,\n",
              " 'symptom': 0.0,\n",
              " 'supply': 0.0,\n",
              " 'chain': 0.0,\n",
              " 'issue': 0.0,\n",
              " 'happened': 0.0,\n",
              " 'gsync': 0.0,\n",
              " 'monitors': 0.0,\n",
              " 'going': 0.0,\n",
              " 'released': 0.0,\n",
              " 'seems': 0.0,\n",
              " 'we': 0.0,\n",
              " 'heard': 0.0,\n",
              " 'them': 0.0392156862745098,\n",
              " 'months': 0.0,\n",
              " 'forward': 0.0,\n",
              " 'getting': 0.0,\n",
              " 'one': 0.0,\n",
              " 'dark': 0.0,\n",
              " 'their': 0.0,\n",
              " 'release': 0.0,\n",
              " 'dates': 0.0,\n",
              " 'kit': 0.0,\n",
              " 'because': 0.0,\n",
              " '$': 0.0,\n",
              " '100': 0.0,\n",
              " 'waited': 0.0,\n",
              " 'official': 0.0,\n",
              " 'worth': 0.0,\n",
              " 'scored': 0.0,\n",
              " 'bunch': 0.0,\n",
              " 'syrup': 0.0,\n",
              " 'month': 0.0,\n",
              " 'purchased': 0.0,\n",
              " 'stream': 0.0,\n",
              " 'machine': 0.0,\n",
              " \"'ve\": 0.0,\n",
              " 'having': 0.0,\n",
              " 'fun': 0.0,\n",
              " 'yesterday': 0.0,\n",
              " 'work': 0.0,\n",
              " 'decided': 0.0,\n",
              " 'rid': 0.0,\n",
              " 'fountain': 0.0,\n",
              " 'setup': 0.0,\n",
              " 'leftover': 0.0,\n",
              " 'syrups': 0.0,\n",
              " '5': 0.0,\n",
              " 'gallons': 0.0,\n",
              " 'cherry': 0.0,\n",
              " 'pepsi': 0.0,\n",
              " 'diet': 0.0,\n",
              " 'yuck': 0.0,\n",
              " 'gallon': 0.0,\n",
              " 'mountain': 0.0,\n",
              " 'dew': 0.0,\n",
              " 'sierra': 0.0,\n",
              " 'mist': 0.0,\n",
              " 'figured': 0.0,\n",
              " 'ratio': 0.0,\n",
              " 'liter': 0.0,\n",
              " 'bottles': 0.0,\n",
              " 'seem': 0.0,\n",
              " 'take': 0.0,\n",
              " '1/2': 0.0,\n",
              " '3/4': 0.0,\n",
              " 'cup': 0.0,\n",
              " 'retailers': 0.0,\n",
              " 'put': 0.0,\n",
              " 'queues': 0.0,\n",
              " 'x': 0.0,\n",
              " 'does': 0.0,\n",
              " 'queue': 0.0,\n",
              " 'reason': 0.0,\n",
              " 'unreleastic': 0.0,\n",
              " 'times': 0.0,\n",
              " 'last': 0.0,\n",
              " 'using': 0.0,\n",
              " 'walmart': 0.0,\n",
              " 'plus': 0.0,\n",
              " 'paid': 0.0,\n",
              " 'version': 0.0,\n",
              " 'trial': 0.0,\n",
              " 'best': 0.0,\n",
              " 'brand': 0.0,\n",
              " 'milk': 0.0,\n",
              " 'w/': 0.0,\n",
              " 'boba': 0.0,\n",
              " 'gon': 0.0,\n",
              " 'na': 0.0,\n",
              " 'give': 0.0,\n",
              " 'making': 0.0,\n",
              " 'try': 0.0,\n",
              " 'brands': 0.0,\n",
              " 'breakfast': 0.0,\n",
              " 'use': 0.0,\n",
              " 'preferably': 0.0,\n",
              " 'amazon': 0.0,\n",
              " 'shipping': 0.0,\n",
              " 'tips': 0.0,\n",
              " 'r': 0.0,\n",
              " 'hydrohomies': 0.0,\n",
              " 'community': 0.0,\n",
              " 'fundraiser': 0.0,\n",
              " 'homies': 0.0,\n",
              " 'long': 0.0,\n",
              " 'time': 0.0,\n",
              " '’ve': 0.0,\n",
              " 'asking': 0.0,\n",
              " 'potential': 0.0,\n",
              " 'starting': 0.0,\n",
              " 'your': 0.0,\n",
              " 'own': 0.0,\n",
              " 'posted': 0.0,\n",
              " 'survey': 0.0,\n",
              " 'interest': 0.0,\n",
              " 'amount': 0.0,\n",
              " 'responses': 0.0,\n",
              " 'proud': 0.0,\n",
              " 'announce': 0.0,\n",
              " 'first': 0.0,\n",
              " 'purpose': 0.0,\n",
              " 'bring': 0.0,\n",
              " 'almost': 0.0196078431372549,\n",
              " 'million': 0.0,\n",
              " 'members': 0.0,\n",
              " 'together': 0.0,\n",
              " 'people': 0.0,\n",
              " 'proper': 0.0,\n",
              " 'access': 0.0,\n",
              " 'doing': 0.0,\n",
              " 'through': 0.0,\n",
              " 'water.org': 0.0,\n",
              " 'money': 0.0,\n",
              " 'straight': 0.0,\n",
              " 'also': 0.0,\n",
              " 'launching': 0.0,\n",
              " 'merch': 0.0,\n",
              " 'shop': 0.0,\n",
              " 'profit': 0.0,\n",
              " 'sales': 0.0,\n",
              " 'towards': 0.0,\n",
              " 'run': 0.0,\n",
              " 'until': 0.0,\n",
              " 'july': 0.0,\n",
              " '15th': 0.0,\n",
              " 'initial': 0.0,\n",
              " 'goal': 0.0,\n",
              " '1,000': 0.0,\n",
              " 'raised': 0.0,\n",
              " 'link': 0.0,\n",
              " 'ac': 0.0,\n",
              " 'valhalla': 0.0,\n",
              " 'pc': 0.0,\n",
              " 'performance': 0.0,\n",
              " 'experience': 0.0,\n",
              " 'mods': 0.0,\n",
              " 'auto': 0.0,\n",
              " 'removing': 0.0,\n",
              " 'comments': 0.0,\n",
              " 'regarding': 0.0,\n",
              " 'sub': 0.0,\n",
              " 'share': 0.0,\n",
              " 'concerns': 0.0,\n",
              " 'ubisoft': 0.0,\n",
              " 'customer': 0.0,\n",
              " 'blown': 0.0,\n",
              " 'away': 0.0,\n",
              " '30': 0.0,\n",
              " 'fps': 0.0,\n",
              " 'high': 0.0,\n",
              " 'medium': 0.0,\n",
              " 'settings': 0.0,\n",
              " 'gtx1080': 0.0,\n",
              " 'stuttering': 0.0,\n",
              " 'terrible': 0.0,\n",
              " 'detail': 0.0,\n",
              " 'levels': 0.0,\n",
              " 'bad': 0.0,\n",
              " 'played': 0.0,\n",
              " 'legion': 0.0,\n",
              " 'ran': 0.0,\n",
              " 'better': 0.0,\n",
              " 'thought': 0.0,\n",
              " 'incase': 0.0,\n",
              " 'wanted': 0.0,\n",
              " 'avoid': 0.0,\n",
              " 'launch': 0.0,\n",
              " 'edit': 0.0,\n",
              " 'everyone': 0.0,\n",
              " 'cpu': 0.0,\n",
              " 'resolution': 0.0,\n",
              " 'i7': 0.0,\n",
              " '8700k': 0.0,\n",
              " '3440x1440': 0.0,\n",
              " 'ultrawide': 0.0,\n",
              " 'already': 0.0,\n",
              " 'knew': 0.0,\n",
              " 'end': 0.0,\n",
              " 'coming': 0.0,\n",
              " 'memory': 0.0,\n",
              " 'bottleneck': 0.0,\n",
              " 'add': 0.0,\n",
              " 'fan': 0.0,\n",
              " 'changes': 0.0,\n",
              " 'made': 0.0,\n",
              " 'far': 0.0,\n",
              " 'favorite': 0.0,\n",
              " 'pulled': 0.0,\n",
              " 'into': 0.0,\n",
              " 'insurance': 0.0,\n",
              " 'mlm': 0.0,\n",
              " 'licensed': 0.0,\n",
              " 'producer': 0.0,\n",
              " 'off': 0.0,\n",
              " 'tail': 0.0,\n",
              " 'medicare': 0.0,\n",
              " 'annual': 0.0,\n",
              " 'enrollment': 0.0,\n",
              " 'another': 0.0,\n",
              " 'position': 0.0,\n",
              " 'actively': 0.0,\n",
              " 'applying': 0.0,\n",
              " 'indeed': 0.0,\n",
              " 'contacted': 0.0,\n",
              " 'hart': 0.0,\n",
              " 'group': 0.0,\n",
              " 'dug': 0.0,\n",
              " 'applied': 0.0,\n",
              " 'jobs': 0.0,\n",
              " 'perplexed': 0.0,\n",
              " 'nothing': 0.0,\n",
              " 'under': 0.0,\n",
              " 'uncommon': 0.0,\n",
              " 'receive': 0.0,\n",
              " 'outbound': 0.0,\n",
              " 'contacts': 0.0,\n",
              " 'agencies': 0.0,\n",
              " 'especially': 0.0,\n",
              " 'prior': 0.0,\n",
              " 'accepting': 0.0,\n",
              " 'today': 0.0,\n",
              " 'realized': 0.0,\n",
              " 'mistake': 0.0,\n",
              " 'never': 0.0,\n",
              " 'should': 0.0,\n",
              " 'red': 0.0,\n",
              " 'flag': 0.0,\n",
              " 'logged': 0.0,\n",
              " 'onto': 0.0,\n",
              " 'overview': 0.0,\n",
              " 'zoom': 0.0,\n",
              " 'call': 0.0,\n",
              " 'given': 0.0,\n",
              " 'american': 0.0,\n",
              " 'income': 0.0,\n",
              " 'life': 0.0196078431372549,\n",
              " 'immediately': 0.0,\n",
              " 'set': 0.0,\n",
              " 'alarm': 0.0,\n",
              " 'bells': 0.0,\n",
              " 'head': 0.0,\n",
              " 'research': 0.0,\n",
              " 'pertaining': 0.0,\n",
              " 'accident': 0.0,\n",
              " 'health': 0.0,\n",
              " 'license': 0.0,\n",
              " 'few': 0.0,\n",
              " 'pyramid': 0.0,\n",
              " 'schemes': 0.0,\n",
              " 'deeper': 0.0,\n",
              " 'flags': 0.0,\n",
              " 'promised': 0.0,\n",
              " 'major': 0.0,\n",
              " 'commission': 0.0,\n",
              " '80k+': 0.0,\n",
              " 'year': 0.0,\n",
              " 'vacations': 0.0,\n",
              " 'rewards': 0.0,\n",
              " 'sock': 0.0,\n",
              " 'reviews': 0.0,\n",
              " 'talking': 0.0,\n",
              " 'pay': 0.0,\n",
              " 'boss': 0.0,\n",
              " 'every': 0.0,\n",
              " 'statement': 0.0,\n",
              " 'promise': 0.0,\n",
              " 'textbook': 0.0,\n",
              " 'recruitment': 0.0,\n",
              " 'garbage': 0.0,\n",
              " 'shocked': 0.0,\n",
              " 'recruited': 0.0,\n",
              " 'defeated': 0.0,\n",
              " 'left': 0.0,\n",
              " 'told': 0.0,\n",
              " 'interested': 0.0,\n",
              " 'wholeheartedly': 0.0,\n",
              " 'believed': 0.0,\n",
              " 'fell': 0.0,\n",
              " 'tactics': 0.0,\n",
              " 'let': 0.0,\n",
              " 'foot': 0.0,\n",
              " 'door': 0.0,\n",
              " 'staunch': 0.0,\n",
              " 'roles': 0.0,\n",
              " 'doubt': 0.0,\n",
              " 'sunk': 0.0,\n",
              " 'teeth': 0.0,\n",
              " 'cold': 0.0,\n",
              " 'world': 0.0,\n",
              " 'stay': 0.0,\n",
              " 'alert': 0.0,\n",
              " 'gongfu': 0.0,\n",
              " 'western': 0.0,\n",
              " 'wanna': 0.0,\n",
              " 'maximize': 0.0,\n",
              " 'cups': 0.0,\n",
              " 'buying': 0.0,\n",
              " 'higher': 0.0,\n",
              " 'quality': 0.0,\n",
              " 'loose': 0.0,\n",
              " 'leaf': 0.0,\n",
              " 'teas': 0.0,\n",
              " 'sample': 0.0,\n",
              " 'different': 0.0,\n",
              " 'g': 0.0,\n",
              " 'diff': 0.0,\n",
              " 'kinds': 0.0,\n",
              " 'oolongs': 0.0,\n",
              " 'jin': 0.0,\n",
              " 'xuan': 0.0,\n",
              " 'tgy': 0.0,\n",
              " 'dried': 0.0,\n",
              " 'chamomile': 0.0,\n",
              " 'brew': 0.0,\n",
              " 'style': 0.0,\n",
              " '3': 0.0,\n",
              " 'max': 0.0,\n",
              " 'doctor': 0.0,\n",
              " 'recommendation': 0.0,\n",
              " 'same': 0.0,\n",
              " '+': 0.0,\n",
              " 'save': 0.0,\n",
              " 'leftovers': 0.0,\n",
              " 're': 0.0,\n",
              " 'infusion': 0.0,\n",
              " 'leaves': 0.0,\n",
              " 'stick': 0.0,\n",
              " 'roasted': 0.0,\n",
              " 'oolong': 0.0,\n",
              " 'lasted': 0.0,\n",
              " '4': 0.0,\n",
              " 'infusions': 0.0,\n",
              " 'stored': 0.0,\n",
              " 'bowl': 0.0,\n",
              " 'lined': 0.0,\n",
              " 'paper': 0.0,\n",
              " 'towels': 0.0,\n",
              " 'counter': 0.0,\n",
              " 'top': 0.0,\n",
              " 'idk': 0.0,\n",
              " 'optimal': 0.0,\n",
              " 'request': 0.0,\n",
              " 'flairs': 0.0,\n",
              " 'pre': 0.0,\n",
              " 'orders': 0.0,\n",
              " 'begun': 0.0,\n",
              " 'ordered': 0.0,\n",
              " 'xsx': 0.0,\n",
              " 'india': 0.0,\n",
              " 'xss': 0.0,\n",
              " 'why': 0.0,\n",
              " '60fps': 0.0,\n",
              " 'watching': 0.0,\n",
              " 'youtube': 0.0,\n",
              " '60': 0.0,\n",
              " 'videos': 0.0,\n",
              " 'weird': 0.0,\n",
              " 'smooth': 0.0,\n",
              " 'gta': 0.0,\n",
              " 'v': 0.0,\n",
              " 'video': 0.0,\n",
              " 'looked': 0.0,\n",
              " 'play': 0.0,\n",
              " 'games': 0.0,\n",
              " 'anything': 0.0,\n",
              " 'ideas': 0.0,\n",
              " 'u.s.': 0.0,\n",
              " 'switch': 0.0,\n",
              " 'owners': 0.0,\n",
              " 'minecraft': 0.0,\n",
              " 'u.k.': 0.0,\n",
              " 'eshop': 0.0,\n",
              " 'roughly': 0.0,\n",
              " 'cheaper': 0.0,\n",
              " '£': 0.0,\n",
              " '19.99': 0.0,\n",
              " 'unhappy': 0.0,\n",
              " 'price': 0.0,\n",
              " 'tag': 0.0,\n",
              " 'q': 0.0,\n",
              " 'fruit': 0.0,\n",
              " 'flavored': 0.0,\n",
              " 'strawberry': 0.0,\n",
              " 'lemon': 0.0,\n",
              " 'echinachea': 0.0,\n",
              " 'etc': 0.0,\n",
              " 'advertise': 0.0,\n",
              " 'omit': 0.0,\n",
              " 'chai': 0.0,\n",
              " 'gives': 0.0,\n",
              " 'coffee': 0.0,\n",
              " 'post': 0.0,\n",
              " 'cafe': 0.0,\n",
              " 'stages': 0.0,\n",
              " 'designing': 0.0,\n",
              " 'café': 0.0,\n",
              " 'inspiration': 0.0,\n",
              " ':p': 0.0,\n",
              " 'somewhere': 0.0,\n",
              " 'designs': 0.0,\n",
              " 'browse': 0.0,\n",
              " 'and/or': 0.0,\n",
              " 'recommendations': 0.0,\n",
              " 'gladly': 0.0,\n",
              " 'welcome': 0.0,\n",
              " 'bunn': 0.0,\n",
              " 'sticker': 0.0,\n",
              " 'burr': 0.0,\n",
              " 'upgrade': 0.0,\n",
              " 'noticed': 0.0,\n",
              " 'electrical': 0.0,\n",
              " 'info': 0.0,\n",
              " 'serial': 0.0,\n",
              " 'number': 0.0,\n",
              " 'wh': 0.0,\n",
              " 'numbers': 0.0,\n",
              " 'correlate': 0.0,\n",
              " 'confirm': 0.0,\n",
              " 'way': 0.0,\n",
              " 'many': 0.0,\n",
              " 'stickers': 0.0,\n",
              " 'seen': 0.0,\n",
              " 'gifted': 0.0,\n",
              " 'refurbished': 0.0,\n",
              " 'looks': 0.0,\n",
              " 'says': 0.0,\n",
              " '1117': 0.0,\n",
              " 'nov': 0.0,\n",
              " '2017': 0.0,\n",
              " 'unit': 0.0,\n",
              " 'hot': 0.0,\n",
              " 'dog': 0.0,\n",
              " 'burrs': 0.0,\n",
              " 'nt': 0.0,\n",
              " 'ditting': 0.0,\n",
              " 'wonder': 0.0,\n",
              " 'its': 0.0,\n",
              " '430': 0.0,\n",
              " 'discerning': 0.0,\n",
              " 'plate': 0.0,\n",
              " 'days': 0.0,\n",
              " 'less': 0.0196078431372549,\n",
              " 'ek43': 0.0,\n",
              " 'obvious': 0.0,\n",
              " 'dooo': 0.0,\n",
              " 'gosh': 0.0,\n",
              " 'seriously': 0.0,\n",
              " 'known': 0.0,\n",
              " 'avid': 0.0,\n",
              " 'hater': 0.0,\n",
              " 'visit': 0.0,\n",
              " '2x': 0.0,\n",
              " 'friend': 0.0,\n",
              " 'yl': 0.0,\n",
              " 'shiller': 0.0,\n",
              " 'whose': 0.0,\n",
              " 'fb': 0.0,\n",
              " 'posts': 0.0,\n",
              " 'shared': 0.0,\n",
              " 'sent': 0.0,\n",
              " 'text': 0.0,\n",
              " 'she': 0.0,\n",
              " 'working': 0.0,\n",
              " 'episode': 0.0,\n",
              " 'workaholics': 0.0,\n",
              " 'distracted': 0.0,\n",
              " 'thinking': 0.0,\n",
              " 'invited': 0.0,\n",
              " 'page': 0.0,\n",
              " 'saw': 0.0,\n",
              " 'r+f': 0.0,\n",
              " 'see': 0.0,\n",
              " 'interesting': 0.0,\n",
              " 'leave': 0.0,\n",
              " 'asap': 0.0,\n",
              " 'lol': 0.0,\n",
              " 'dr': 0.0,\n",
              " 'pepper': 0.0,\n",
              " 'cream': 0.0,\n",
              " 'missing': 0.0,\n",
              " 'sold': 0.0,\n",
              " 'pennsylvania': 0.0,\n",
              " 'btw': 0.0,\n",
              " 'egg': 0.0,\n",
              " 'preorder': 0.0,\n",
              " 'start': 0.0,\n",
              " '/r': 0.0,\n",
              " 'teacup': 0.0,\n",
              " 'idea': 0.0,\n",
              " 'might': 0.0,\n",
              " 'guys': 0.0,\n",
              " 'subreddit': 0.0,\n",
              " 'teacups': 0.0,\n",
              " 'heavily': 0.0,\n",
              " 'promoted': 0.0,\n",
              " 'sidebar': 0.0,\n",
              " 'willing': 0.0,\n",
              " 'sell': 0.0,\n",
              " 'revenue': 0.0,\n",
              " 'paying': 0.0,\n",
              " 'coders': 0.0,\n",
              " 'awesome': 0.0,\n",
              " 'contests': 0.0,\n",
              " 'giveaways': 0.0,\n",
              " 'enough': 0.0,\n",
              " 'maybe': 0.0,\n",
              " 'able': 0.0,\n",
              " 'cool': 0.0,\n",
              " 'tldr': 0.0,\n",
              " 'monoprice': 0.0,\n",
              " 'reveals': 0.0,\n",
              " 'ips': 0.0,\n",
              " '11': 0.0,\n",
              " '2013': 0.0,\n",
              " 'listed': 0.0,\n",
              " 'after': 0.0,\n",
              " 'discontinuing': 0.0,\n",
              " 'older': 0.0,\n",
              " 'models': 0.0,\n",
              " 'word': 0.0,\n",
              " 'expect': 0.0,\n",
              " 'http://www.monoprice.com/product?c_id=113&cp_id=11307&cs_id=1130703&p_id=10734&seq=1&format=2': 0.0,\n",
              " 'led': 0.0,\n",
              " 'backlit': 0.0,\n",
              " 'specifically': 0.0,\n",
              " 'actually': 0.0,\n",
              " 'unlike': 0.0,\n",
              " 'complained': 0.0,\n",
              " 'tempted': 0.0,\n",
              " 'order': 0.0,\n",
              " 'display': 0.0,\n",
              " 'knows': 0.0,\n",
              " 'discount': 0.0,\n",
              " 'code': 0.0,\n",
              " 'speak': 0.0,\n",
              " 'forth': 0.0,\n",
              " 'opinions': 0.0,\n",
              " 'normal': 0.0,\n",
              " 'ps4': 0.0,\n",
              " 'trying': 0.0,\n",
              " 'grand': 0.0,\n",
              " 'theft': 0.0,\n",
              " 'playstation': 0.0,\n",
              " 'comes': 0.0,\n",
              " 'premium': 0.0,\n",
              " 'edition': 0.0,\n",
              " 'ons': 0.0,\n",
              " 'matcha': 0.0,\n",
              " 'lattes': 0.0,\n",
              " 'recently': 0.0,\n",
              " 'vanilla': 0.0,\n",
              " 'steamed': 0.0,\n",
              " 'coconut': 0.0,\n",
              " 'almond': 0.0,\n",
              " 'packet': 0.0,\n",
              " 'stevia': 0.0,\n",
              " 'school': 0.0,\n",
              " 'rotation': 0.0,\n",
              " 'read': 0.0,\n",
              " 'meant': 0.0,\n",
              " 'fast': 0.0,\n",
              " 'lot': 0.0,\n",
              " 'yours': 0.0,\n",
              " 'x.': 0.0,\n",
              " 'next': 0.0,\n",
              " 'gen': 0.0,\n",
              " 'point': 0.0,\n",
              " 'update': 0.0,\n",
              " 'specs': 0.0,\n",
              " 'stuff': 0.0,\n",
              " 'full': 0.0,\n",
              " 'consoles': 0.0,\n",
              " '17': 0.0,\n",
              " 'promotional': 0.0,\n",
              " 'posters': 0.0,\n",
              " 'promo': 0.0,\n",
              " 'mua3': 0.0,\n",
              " 'ssbu': 0.0,\n",
              " 'fortnite': 0.0,\n",
              " 'poster': 0.0,\n",
              " 'nintendo': 0.0,\n",
              " 'mall': 0.0,\n",
              " 'event': 0.0,\n",
              " 'summer': 0.0,\n",
              " 'gave': 0.0,\n",
              " 'nephew': 0.0,\n",
              " 'list': 0.0,\n",
              " 'advance': 0.0,\n",
              " 'converter': 0.0,\n",
              " 'between': 0.0,\n",
              " '3.5': 0.0,\n",
              " 'mm': 0.0,\n",
              " 'digital': 0.0,\n",
              " 'audio': 0.0,\n",
              " 'everything': 0.0,\n",
              " 'allows': 0.0,\n",
              " 'plug': 0.0,\n",
              " 'cable': 0.0,\n",
              " 'jack': 0.0,\n",
              " 'pluck': 0.0,\n",
              " 'dac': 0.0,\n",
              " \"y'\": 0.0,\n",
              " 'consignment': 0.0,\n",
              " 'things': 0.0,\n",
              " 'across': 0.0,\n",
              " 'rack': 0.0,\n",
              " 'skirts': 0.0,\n",
              " 'cheesy': 0.0,\n",
              " 'color': 0.0,\n",
              " 'combos': 0.0,\n",
              " 'felt': 0.0,\n",
              " 'tags': 0.0,\n",
              " 'lularoe': 0.0,\n",
              " 'picture': 0.0,\n",
              " 'mind': 0.0,\n",
              " 'hauling': 0.0,\n",
              " 'serious': 0.0,\n",
              " 'tasting': 0.0,\n",
              " 'corner': 0.0,\n",
              " 'apart': 0.0,\n",
              " ...}"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_trigram_distribution('i','like', posts_unigram_counts, posts_bigram_counts, posts_trigram_counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0EGFXCYHKkY"
      },
      "source": [
        "If I wanted to generate text, I could choose the token with the highest probability. But that quickly generates boring text. Instead I are going to sample from this distribution, where tokens with higher probability have a higher chance of being chosen.\n",
        "\n",
        "The `sample_from_distribution` function takes a token distribution (like I've calculated above) and randomly chooses a token based on the probabilities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "CJQBr3DysMOL",
        "outputId": "c2f89ee1-94b8-415e-8036-aa642564ce42"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'b'"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import random\n",
        "def sample_from_distribution(distribution):\n",
        "  population = list(distribution.keys())\n",
        "  probabilities = list(distribution.values())\n",
        "\n",
        "  choice, = random.choices(population, weights=probabilities, k=1)\n",
        "  return choice\n",
        "\n",
        "sample_from_distribution({'a':0.2,'b':0.5,'c':0.3})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WszeCNGiH8qq"
      },
      "source": [
        "Let's join the trigram distribution with the sampling code. This finds the trigram distribution that starts 'i like'. It then randomly picks a token weighted by the probabilities. Try running the cell a few times and you should get different results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "BRWHLDZJti-4",
        "outputId": "10c93849-3394-478f-dac1-e72b552448b2"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'to'"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prev_prev_token, prev_token = 'i', 'like'\n",
        "trigram_distribution = get_trigram_distribution(prev_prev_token, prev_token, posts_unigram_counts, posts_bigram_counts, posts_trigram_counts)\n",
        "sample_from_distribution(trigram_distribution)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vlIBAt0ZIQVU"
      },
      "source": [
        "Now I can put this together to generate a whole sequence of text.\n",
        "\n",
        "**Exercise:** Write a function `hallucinate_text` that takes an initial sequence of tokens, the desired length of the output sequence, and the uni/bi/trigram counts. It should calculate a trigram distribution based on the final two tokens of the sequence, sample from it to pick a new token (using `sample_from_distribution`) and add that to the list. It should then repeat this until the desired length is achieved.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tzedoaDtogX",
        "outputId": "037e7350-5edd-418f-cbec-503d61790d76"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['i',\n",
              " 'like',\n",
              " 'open',\n",
              " 'world',\n",
              " 'was',\n",
              " 'basically',\n",
              " 'nothing',\n",
              " 'you',\n",
              " 'could',\n",
              " 'customize']"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ANSWER\n",
        "\n",
        "def hallucinate_text(sequence, max_length, unigram_counts, bigram_counts, trigram_counts):\n",
        "  sequence = list(sequence)\n",
        "  while len(sequence) < max_length:\n",
        "    trigram_distribution = get_trigram_distribution(sequence[-2],sequence[-1], unigram_counts, bigram_counts, trigram_counts)\n",
        "    choice = sample_from_distribution(trigram_distribution)\n",
        "    sequence.append(choice)\n",
        "  return sequence\n",
        "\n",
        "hallucinate_text(['i','like'], 10, posts_unigram_counts, posts_bigram_counts, posts_trigram_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EEcKbFsMJLLK",
        "outputId": "aac53f5e-277f-4225-f0e7-272a07b2d278"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------\n",
            "LABTEST: Running 1 testcases\n",
            "----------------------------\n",
            "Input: (['i', 'like'], 3, Counter({'potatoes': 5, 'like': 4, 'i': 3}), Counter({('i', 'like'): 5}), Counter({('i', 'like', 'potatoes'): 5})). Running... \n",
            "Output: ['i', 'like', 'potatoes']\n",
            "OK.\n",
            "\n",
            "----------------------------\n",
            "1 testcases PASSED\n",
            "----------------------------\n"
          ]
        }
      ],
      "source": [
        "labtest(hallucinate_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbTpQtCdJGIq"
      },
      "source": [
        "Now I can generate a bunch of hallucinated sentences!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSI2dfh3e3q3",
        "outputId": "be6fe291-8f84-4a23-c717-940867503146"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "i like brisk ice tea and nesquik and soda but it was meant to <START> don't drink water usually a\n",
            "i like the 3ds having said that he has liked so i still need the name of 90 's pc\n",
            "i like to know thanks in advance <START> got a series x. i 'm thinking of picking up a free\n",
            "i like it 's raspberry flavored it was perfect the controls menu if you are forced to buy an electric\n",
            "i like the bitter notes cold brew jameson in the dark home screen to my local farmer 's market in\n"
          ]
        }
      ],
      "source": [
        "# Maximum length of sequence to generate.\n",
        "max_length = 20\n",
        "\n",
        "# Number of sequences to generate\n",
        "num_sequences = 5\n",
        "\n",
        "start = [\"i\", \"like\"] # Needs to be an n-gram that occurs in the collection\n",
        "for _ in range(num_sequences):\n",
        "  sequence = hallucinate_text(start, max_length, posts_unigram_counts, posts_bigram_counts, posts_trigram_counts)\n",
        "  print (\" \".join(sequence))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4TLERMrKXj7"
      },
      "source": [
        "I now have a simple bot that can write reddit-like posts!  It sort-of-almost makes sense. Many naive spam bots work in a similar way by taking sample text and using it to generate made up auto-replies.\n",
        "\n",
        "Have fun with this example by modifying the starting sequence."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buvdn5h1EGnw"
      },
      "source": [
        "## Language Model Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVHBk7zEo49K"
      },
      "source": [
        "the model seems to capture some aspects of language. It often gets the idea of adjectives being before nouns, and subjects before verbs, etc. I know that it's using the probability of the token frequencies to do this. But how can I judge how well it has modelled the language?\n",
        "\n",
        "Let's evaluate the models by seeing how well they can predict real text.\n",
        "\n",
        "At this point, I are going to distinguish how well the model can predict the text it has been trained on (the **training performance**) from how well it can predict new unseen data (the **test performance**)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exYVpaioKURr"
      },
      "source": [
        "### The novel token problem\n",
        "\n",
        "Any unseen data is very likely to have new tokens that I haven't seen before. English has a very large vocabulary, and I'd need to have a huge number of documents to contain every token. And then there are spelling mistakes, etc. So there will always be some new unknown tokens.\n",
        "\n",
        "All the language models (unigram, bigram, trigram) assume that the tokens have been seen before. How do I deal with new tokens so that the probabilities are not always zero for unseen text?\n",
        "\n",
        "For example, what's the unigram probability of 'abracadabra' which never appears in the Reddit posts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4X_e-l4qL_0b",
        "outputId": "135a7b11-963f-4e5d-89a3-ef9aeb106c69"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "unigram_token_prob('abracadabra', posts_unigram_counts, posts_unigram_N)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhJvxFqKMSBb"
      },
      "source": [
        "So any sequence containing that token would have a probability of zero. And that's true for any new token not in the original text data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DyAk8vYEK0il"
      },
      "source": [
        "### Smoothing (Add-K / Laplace)\n",
        "\n",
        "Smoothing a language model gives some probability to unseen words, even if it is very little. This enables unseen text to not automatically have a zero probability.\n",
        "\n",
        "There were a few methods of smoothing mentioned in the lecture.  going to implement Add-K / Laplacian Smoothing to the unigram model.\n",
        "\n",
        "The unigram probability is modified by effectively adding a value $k$ to the count of every possible token.\n",
        "\n",
        "$$ P(t) = \\frac{count(t) + k}{\\sum_{t' \\in V}{count(t') + k}} = \\frac{count(t) + k}{k|V| + \\sum_{t' \\in V}{count(t')}} $$\n",
        "\n",
        "This means that a token with a count of zero (e.g. any novel token) still has a non-zero value as the $k$ raises it up a little.\n",
        "\n",
        "**Exercise:** Write a function `unigram_token_prob_ksmooth` that implements Add-K smoothing for the unigram model. Refer to your `unigram_token_prob` function as it will be a modification of that."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LREfSI8ELyHV",
        "outputId": "ae1ca2f6-e9cf-4e97-ec83-7887da396544"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5.245032167782285e-07"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ANSWER\n",
        "def unigram_token_prob_ksmooth(next_token, unigram_counts, unigram_N, k):\n",
        "  vocab_count = len(unigram_counts)\n",
        "  return (unigram_counts[next_token] + k) / (unigram_N + k*vocab_count)\n",
        "\n",
        "unigram_token_prob_ksmooth('abracadabra', posts_unigram_counts, posts_unigram_N, 0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3IdeSR4OulG",
        "outputId": "49569aef-4769-4ea5-ba41-aa271cc51e8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------\n",
            "LABTEST: Running 5 testcases\n",
            "----------------------------\n",
            "Input: ('cup', {'cup': 2, 'spoon': 2, 'glass': 6, 'fork': 1}, 11, 0.1). Running... \n",
            "Output: 0.18421\n",
            "OK.\n",
            "\n",
            "Input: ('plate', {'plate': 2, 'cup': 2, 'fork': 5, 'spoon': 5}, 14, 0.1). Running... \n",
            "Output: 0.14583\n",
            "OK.\n",
            "\n",
            "Input: ('fork', {'bowl': 4, 'fork': 5, 'plate': 3, 'cup': 1}, 13, 0.1). Running... \n",
            "Output: 0.3806\n",
            "OK.\n",
            "\n",
            "Input: ('cup', {'plate': 2, 'glass': 3, 'fork': 1, 'cup': 1}, 7, 0.1). Running... \n",
            "Output: 0.14865\n",
            "OK.\n",
            "\n",
            "Input: ('glass', {'glass': 5, 'spoon': 3}, 8, 0.1). Running... \n",
            "Output: 0.62195\n",
            "OK.\n",
            "\n",
            "----------------------------\n",
            "5 testcases PASSED\n",
            "----------------------------\n"
          ]
        }
      ],
      "source": [
        "labtest(unigram_token_prob_ksmooth)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIuLPUSIEyJa"
      },
      "source": [
        "### Splitting into training and test data\n",
        "\n",
        "I want to see how good the language model is modelling the language.  work with the Add-K smoothed unigram model.\n",
        "\n",
        " split the data into two parts: train and test. I train the model (using counts) on the training sample of posts. This means that I fixed (or *fit* in sci-kit learn terminology) the vocabulary based on the words in *training* set.  I then evaluate on how well it can predict the new unseen test posts.  \n",
        "\n",
        "Let's first shuffle and split the posts into training and testing posts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcb0HYwKFQ9x",
        "outputId": "8dce106a-cc37-4c3e-b49a-030a355c5f0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set size: 1600\n",
            "Test set size: 400\n"
          ]
        }
      ],
      "source": [
        "random.seed(42)\n",
        "shuffled_posts = random.sample(posts, k=len(posts))\n",
        "\n",
        "# Split the data into 80% train, 20% test posts.\n",
        "train_frac = 0.8\n",
        "split_idx = int(train_frac * len(shuffled_posts))\n",
        "train_posts = shuffled_posts[:split_idx]\n",
        "test_posts = shuffled_posts[split_idx:]\n",
        "\n",
        "print (\"Training set size:\", len(train_posts))\n",
        "print (\"Test set size:\", len(test_posts))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNo0vNASPH7u"
      },
      "source": [
        "And  make the same flattened lists for the training and testing sets.  add `<START>` and `<END>` tokens to mark the start and end of posts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p28M-hLMwR-K",
        "outputId": "31f8eaab-dafa-4750-bd37-1d590215ae8c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "153987"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_flattened_tokens = []\n",
        "for post in train_posts:\n",
        "  train_flattened_tokens += ['<START>'] + post['tokens'] + ['<END>']\n",
        "len(train_flattened_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WhAvbCzq3G18",
        "outputId": "0aa23765-5886-45cd-cd28-15ed13d1444b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "37441"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_flattened_tokens = []\n",
        "for post in test_posts:\n",
        "  test_flattened_tokens += ['<START>'] + post['tokens'] + ['<END>']\n",
        "len(test_flattened_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRoCs64DPPev"
      },
      "source": [
        "Lastly,  calculate the unigram counts **for the training data** so that I can use the Add-K smoothed unigram model. Now recall, that without the smoothing, any new token in the test data with a probability of zero would cause the whole sequence to have a probability of zero."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1RjwEQCM3OTX"
      },
      "outputs": [],
      "source": [
        "train_unigram_counts = Counter(train_flattened_tokens)\n",
        "train_unigram_N = len(train_flattened_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mkVSrNcauh8"
      },
      "source": [
        "To save you some time, here's an implementation of a function that calculates the log transformed probability of a sequence (similar to a method earlier in this project) that uses the smoothed unigram model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnJvk7ktP50y",
        "outputId": "c901977e-00b2-4bc1-9f03-ad03ab62c8a5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "-47.312934943431344"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import math\n",
        "def unigram_sequence_logprob_ksmooth(sequence, unigram_counts, unigram_N, k):\n",
        "  logprob = 0\n",
        "  for t in sequence:\n",
        "    logprob += math.log2(unigram_token_prob_ksmooth(t, unigram_counts, unigram_N, k))\n",
        "\n",
        "  return logprob\n",
        "\n",
        "unigram_sequence_logprob_ksmooth(['i', 'like', 'irn', 'moo'], posts_unigram_counts, posts_unigram_N, 0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJIm9npFP8FN"
      },
      "source": [
        "### Cross-Entropy Loss and Perplexity\n",
        "\n",
        "Now I can calculate the probability of the training data and the test data using a unigram model \"trained\" using the training data.\n",
        "\n",
        " score the model using perplexity. Perplexity measures how \"surprised\" the model was (on average) when it came across a new token in the corpus. A model that has done a good job modelling a language dataset shouldn't be very surprised, so should have lower perplexity.\n",
        "\n",
        "As mentioned in lecture, I take $ 2^H $ (exponentiate it) to get the perplexity score, where $H$ is the cross-entropy. How do I get this?\n",
        "\n",
        "Running the `unigram_sequence_logprob_ksmooth` function computes the log-likelihood of the data:\n",
        "\n",
        "$$ Log P(w_1, ... w_N) = \\sum_{i=1}^N \\log_2 \\hat{p}(w_i) $$\n",
        "\n",
        "Which is very close to the cross-entropy loss:\n",
        "$$ \\text{H}_{\\text{total}}(y, \\hat{y}) = -1 \\sum_{i=1}^N \\frac{1}{N} \\log_2 \\hat{p}(w_i) $$\n",
        "\n",
        "The cross-entropy is equal to $-1$ times the log-likelihood of the data under the model, averaged by the total number of instances (tokens).\n",
        "\n",
        "Let's run it for the training data first.  I compute the probability of the whole collection as a sequence using the model.\n",
        "\n",
        "I've arbitrarily chosen $k = 0.1$ for the smoothing parameter. You could try different values and see how it changes the perplexity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBH_ZOanwrku",
        "outputId": "abe43b92-606c-4c0a-e303-af14b8c4dc69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Cross-entropy Loss:\t9.6211\n",
            "Train Perplexity:\t787.5012\n"
          ]
        }
      ],
      "source": [
        "k = 0.1\n",
        "train_logprob = unigram_sequence_logprob_ksmooth(train_flattened_tokens, train_unigram_counts, train_unigram_N, k)\n",
        "\n",
        "train_cross_entropy_loss = -train_logprob / len(train_flattened_tokens)\n",
        "\n",
        "train_perplexity = 2**train_cross_entropy_loss\n",
        "\n",
        "print(f\"Train Cross-entropy Loss:\\t{train_cross_entropy_loss:.4f}\")\n",
        "print(f\"Train Perplexity:\\t{train_perplexity:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wj5bn5TCUOqq"
      },
      "source": [
        "And now I can calculate the cross entropy loss and perplexity for the test set. Note that I still use the unigram counts from the training set as that's the data that the model has been \"trained\" on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEQZtj-yRojJ",
        "outputId": "fbe2ae55-d6cd-4bbb-d977-6ea415431613"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Cross-entropy Loss:\t9.9392\n",
            "Test Perplexity:\t981.7333\n"
          ]
        }
      ],
      "source": [
        "k = 0.1\n",
        "test_logprob = unigram_sequence_logprob_ksmooth(test_flattened_tokens, train_unigram_counts, train_unigram_N, k)\n",
        "\n",
        "test_cross_entropy_loss = -test_logprob / len(test_flattened_tokens)\n",
        "\n",
        "test_perplexity = 2**test_cross_entropy_loss\n",
        "\n",
        "print(f\"Test Cross-entropy Loss:\\t{test_cross_entropy_loss:.4f}\")\n",
        "print(f\"Test Perplexity:\\t{test_perplexity:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYdlHWc7Uk8n"
      },
      "source": [
        "The cross entropy loss and perplexity should be higher for the test set compared to the training set. This makes sense as the model should have learned patterns about words from the training set that apply to the test set (but marginally not as well)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XE3lWADmU3yr"
      },
      "source": [
        "The perplexity is definitely high for the unigram model. It is constantly surprised by each token (because it's not taking context into account).\n",
        "\n",
        "Would you expect a bi-gram or a tri-gram model to have a higher or lower cross-entropy loss (& perplexity) than the unigram model?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93XMGHE-dCib"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0ZpeD5vd_hc"
      },
      "source": [
        "## Optional Extras\n",
        "\n",
        "- Read about how shopping service Etsy uses language models in [spelling correction in search](https://codeascraft.com/2017/05/01/modeling-spelling-correction-for-search-at-etsy/).\n",
        "- Read more about training cool language systems directly from text data in [Chapter 14](http://norvig.com/ngrams/ch14.pdf) of Peter Norvig's [Natural Language Corpus Data: Beautiful Data](http://norvig.com/ngrams/).\n",
        "- Write a Trigram model for the spelling corrector\n",
        "- Make `sample_from_distribution` more efficient\n",
        "- Calculate perplexity for a bigram or trigram model with Add-K smoothing"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
